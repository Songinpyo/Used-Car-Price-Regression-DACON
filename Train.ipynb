{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This is file for train, prediction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dirpath = 'C:/Python/Used-Car-Price-Regression-DACON/'\n",
    "\n",
    "train = pd.read_csv('data/modified_train.csv')\n",
    "test = pd.read_csv('data/modified_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   title  odometer  location  isimported  engine  transmission  fuel  paint  \\\n0    147     18277         0           0       3             0     0      0   \n1     93        10         0           2       3             0     0     10   \n2     55     83091         0           0       4             0     0      0   \n3    122     91524         0           0       3             0     0      6   \n4    116     94177         0           0       4             0     0      0   \n\n   year  brand    target  \n0  2016     36  13665000  \n1  2019     36  33015000  \n2  2012     31   9915000  \n3  2007      6   3815000  \n4  2010     36   7385000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>odometer</th>\n      <th>location</th>\n      <th>isimported</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>paint</th>\n      <th>year</th>\n      <th>brand</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>147</td>\n      <td>18277</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>36</td>\n      <td>13665000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>36</td>\n      <td>33015000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>83091</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2012</td>\n      <td>31</td>\n      <td>9915000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>122</td>\n      <td>91524</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>6</td>\n      <td>3815000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>94177</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010</td>\n      <td>36</td>\n      <td>7385000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   title  odometer  location  isimported  engine  transmission  fuel  paint  \\\n0     14      1234         1           2       3             0     0     11   \n1     88     29938         1           0       3             0     0     11   \n2     29     87501         0           0       3             0     0     10   \n3     91    180894         0           1       4             0     0      6   \n4     17    104814         0           0       3             0     0     11   \n\n   year  brand  \n0  2017     34  \n1  2013     14  \n2  2012     34  \n3  2001     36  \n4  2000     36  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>odometer</th>\n      <th>location</th>\n      <th>isimported</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>paint</th>\n      <th>year</th>\n      <th>brand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>1234</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2017</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>88</td>\n      <td>29938</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2013</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>87501</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2012</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>91</td>\n      <td>180894</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2001</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>104814</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2000</td>\n      <td>36</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Y = train[ ['target'] ].values\n",
    "X = train[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((1015, 10), (1015, 1))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "\n",
    "scalerY = MinMaxScaler()\n",
    "scalerY.fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':200,\n",
    "    'BATCH_SIZE':16,\n",
    "    'LEARNING_RATE' :3e-4\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(10, 64, bias=False),\n",
    "            nn.BatchNorm1d(64, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64, 128, bias=False),\n",
    "            nn.BatchNorm1d(128, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 256, bias=False),\n",
    "            nn.BatchNorm1d(256, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Linear(256, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loss_ = [] # loss 저장할 리스트\n",
    "val_loss_ = [] # val loss 저장할 리스트\n",
    "\n",
    "def train(model, optimizer, trainloader, valloader):\n",
    "    best_loss = 1000 # to save best model\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, CFG[\"EPOCHS\"]+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, values = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, values)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss))\n",
    "        loss_.append(running_loss)\n",
    "\n",
    "        #validation set evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서.\n",
    "        actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서.\n",
    "\n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for i, data in enumerate(valloader, 0): # enumerate(인자, index)\n",
    "                inputs, values = data\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, values)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print('[%d] Validation loss: %.10f' %(epoch, val_loss))\n",
    "\n",
    "        if val_loss < best_loss :\n",
    "            torch.save(model.state_dict(), dirpath + \"best_model/\" + str(val_loss) + \"best_model.pth\")\n",
    "            best_loss = val_loss\n",
    "            print('model saved')\n",
    "\n",
    "        val_loss_.append(val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 2.4779950343\n",
      "[1] Validation loss: 0.2421447283\n",
      "model saved\n",
      "[2] Train loss: 0.8732593437\n",
      "[2] Validation loss: 0.2074832059\n",
      "model saved\n",
      "[3] Train loss: 0.3857719845\n",
      "[3] Validation loss: 0.1727679451\n",
      "model saved\n",
      "[4] Train loss: 0.2469198151\n",
      "[4] Validation loss: 0.1542146867\n",
      "model saved\n",
      "[5] Train loss: 0.1957379984\n",
      "[5] Validation loss: 0.1581448899\n",
      "[6] Train loss: 0.1738644880\n",
      "[6] Validation loss: 0.1352358945\n",
      "model saved\n",
      "[7] Train loss: 0.2024462336\n",
      "[7] Validation loss: 0.1352433776\n",
      "[8] Train loss: 0.2465958813\n",
      "[8] Validation loss: 0.1582034775\n",
      "[9] Train loss: 0.3477195280\n",
      "[9] Validation loss: 0.3213586500\n",
      "[10] Train loss: 0.6528088413\n",
      "[10] Validation loss: 0.4911676310\n",
      "[11] Train loss: 1.2741788351\n",
      "[11] Validation loss: 0.4654548410\n",
      "[12] Train loss: 1.1040208708\n",
      "[12] Validation loss: 0.3100323984\n",
      "[13] Train loss: 0.7943689786\n",
      "[13] Validation loss: 0.1244694034\n",
      "model saved\n",
      "[14] Train loss: 0.3093651389\n",
      "[14] Validation loss: 0.1489221943\n",
      "[15] Train loss: 0.2118777997\n",
      "[15] Validation loss: 0.1244153809\n",
      "model saved\n",
      "[16] Train loss: 0.1810286395\n",
      "[16] Validation loss: 0.1088749436\n",
      "model saved\n",
      "[17] Train loss: 0.1682503618\n",
      "[17] Validation loss: 0.1199841360\n",
      "[18] Train loss: 0.1531137484\n",
      "[18] Validation loss: 0.1439724709\n",
      "[19] Train loss: 0.1458697825\n",
      "[19] Validation loss: 0.1425220435\n",
      "[20] Train loss: 0.1468344629\n",
      "[20] Validation loss: 0.1257981935\n",
      "[21] Train loss: 0.1426528067\n",
      "[21] Validation loss: 0.1398826260\n",
      "[22] Train loss: 0.1358374531\n",
      "[22] Validation loss: 0.1641999334\n",
      "[23] Train loss: 0.1425657038\n",
      "[23] Validation loss: 0.1454145601\n",
      "[24] Train loss: 0.1465195586\n",
      "[24] Validation loss: 0.1125753704\n",
      "[25] Train loss: 0.1364113018\n",
      "[25] Validation loss: 0.1151620951\n",
      "[26] Train loss: 0.1292063142\n",
      "[26] Validation loss: 0.1114846268\n",
      "[27] Train loss: 0.1339545873\n",
      "[27] Validation loss: 0.0812992430\n",
      "model saved\n",
      "[28] Train loss: 0.1224471008\n",
      "[28] Validation loss: 0.0738560371\n",
      "model saved\n",
      "[29] Train loss: 0.1086765990\n",
      "[29] Validation loss: 0.0820282015\n",
      "[30] Train loss: 0.1032224598\n",
      "[30] Validation loss: 0.0808425797\n",
      "[31] Train loss: 0.0971020511\n",
      "[31] Validation loss: 0.0940437925\n",
      "[32] Train loss: 0.0897029114\n",
      "[32] Validation loss: 0.1217920575\n",
      "[33] Train loss: 0.0904494484\n",
      "[33] Validation loss: 0.1373088425\n",
      "[34] Train loss: 0.0932831964\n",
      "[34] Validation loss: 0.1398167384\n",
      "[35] Train loss: 0.0987326117\n",
      "[35] Validation loss: 0.1483874377\n",
      "[36] Train loss: 0.1089709075\n",
      "[36] Validation loss: 0.1513188267\n",
      "[37] Train loss: 0.1212457100\n",
      "[37] Validation loss: 0.1413321467\n",
      "[38] Train loss: 0.1282696811\n",
      "[38] Validation loss: 0.1278235370\n",
      "[39] Train loss: 0.1293346236\n",
      "[39] Validation loss: 0.1241178694\n",
      "[40] Train loss: 0.1360316845\n",
      "[40] Validation loss: 0.1223280157\n",
      "[41] Train loss: 0.1393632788\n",
      "[41] Validation loss: 0.1219854096\n",
      "[42] Train loss: 0.1388689107\n",
      "[42] Validation loss: 0.1346307977\n",
      "[43] Train loss: 0.1387750583\n",
      "[43] Validation loss: 0.1439594068\n",
      "[44] Train loss: 0.1462763619\n",
      "[44] Validation loss: 0.1335580125\n",
      "[45] Train loss: 0.1573129763\n",
      "[45] Validation loss: 0.1164599033\n",
      "[46] Train loss: 0.1651235790\n",
      "[46] Validation loss: 0.1097976710\n",
      "[47] Train loss: 0.1674270465\n",
      "[47] Validation loss: 0.1078943916\n",
      "[48] Train loss: 0.1624580943\n",
      "[48] Validation loss: 0.1031225210\n",
      "[49] Train loss: 0.1450321713\n",
      "[49] Validation loss: 0.1028514018\n",
      "[50] Train loss: 0.1325185058\n",
      "[50] Validation loss: 0.0946241815\n",
      "[51] Train loss: 0.1129932333\n",
      "[51] Validation loss: 0.0744275185\n",
      "[52] Train loss: 0.0943620749\n",
      "[52] Validation loss: 0.0622444552\n",
      "model saved\n",
      "[53] Train loss: 0.0713463277\n",
      "[53] Validation loss: 0.0612420775\n",
      "model saved\n",
      "[54] Train loss: 0.0531169984\n",
      "[54] Validation loss: 0.0669384635\n",
      "[55] Train loss: 0.0415727806\n",
      "[55] Validation loss: 0.0720198915\n",
      "[56] Train loss: 0.0348577936\n",
      "[56] Validation loss: 0.0732460683\n",
      "[57] Train loss: 0.0325915857\n",
      "[57] Validation loss: 0.0690467996\n",
      "[58] Train loss: 0.0304671864\n",
      "[58] Validation loss: 0.0649972020\n",
      "[59] Train loss: 0.0297288072\n",
      "[59] Validation loss: 0.0634891042\n",
      "[60] Train loss: 0.0308974213\n",
      "[60] Validation loss: 0.0660115995\n",
      "[61] Train loss: 0.0331422391\n",
      "[61] Validation loss: 0.0702240634\n",
      "[62] Train loss: 0.0344334247\n",
      "[62] Validation loss: 0.0752263367\n",
      "[63] Train loss: 0.0352273314\n",
      "[63] Validation loss: 0.0815770059\n",
      "[64] Train loss: 0.0406202999\n",
      "[64] Validation loss: 0.0889827115\n",
      "[65] Train loss: 0.0486397688\n",
      "[65] Validation loss: 0.0906696641\n",
      "[66] Train loss: 0.0556556990\n",
      "[66] Validation loss: 0.0833130777\n",
      "[67] Train loss: 0.0610146120\n",
      "[67] Validation loss: 0.0831926316\n",
      "[68] Train loss: 0.0681077685\n",
      "[68] Validation loss: 0.0969424623\n",
      "[69] Train loss: 0.0881925779\n",
      "[69] Validation loss: 0.1118658693\n",
      "[70] Train loss: 0.1099839208\n",
      "[70] Validation loss: 0.1265546887\n",
      "[71] Train loss: 0.1117461542\n",
      "[71] Validation loss: 0.1284645938\n",
      "[72] Train loss: 0.1230450706\n",
      "[72] Validation loss: 0.0961561115\n",
      "[73] Train loss: 0.1202618665\n",
      "[73] Validation loss: 0.0853264576\n",
      "[74] Train loss: 0.0987298550\n",
      "[74] Validation loss: 0.0784763420\n",
      "[75] Train loss: 0.0847794630\n",
      "[75] Validation loss: 0.0713165565\n",
      "[76] Train loss: 0.0785109689\n",
      "[76] Validation loss: 0.0748814512\n",
      "[77] Train loss: 0.0744135766\n",
      "[77] Validation loss: 0.0699436322\n",
      "[78] Train loss: 0.0789490499\n",
      "[78] Validation loss: 0.0546775591\n",
      "model saved\n",
      "[79] Train loss: 0.0854430834\n",
      "[79] Validation loss: 0.0494821139\n",
      "model saved\n",
      "[80] Train loss: 0.0857998358\n",
      "[80] Validation loss: 0.0584320211\n",
      "[81] Train loss: 0.0875273261\n",
      "[81] Validation loss: 0.0735634655\n",
      "[82] Train loss: 0.0920809998\n",
      "[82] Validation loss: 0.0865850988\n",
      "[83] Train loss: 0.1001917309\n",
      "[83] Validation loss: 0.0936096450\n",
      "[84] Train loss: 0.1023778206\n",
      "[84] Validation loss: 0.0935371813\n",
      "[85] Train loss: 0.0997250158\n",
      "[85] Validation loss: 0.0926481388\n",
      "[86] Train loss: 0.0924471567\n",
      "[86] Validation loss: 0.1000404723\n",
      "[87] Train loss: 0.0820666042\n",
      "[87] Validation loss: 0.1030855326\n",
      "[88] Train loss: 0.0718755331\n",
      "[88] Validation loss: 0.0924117381\n",
      "[89] Train loss: 0.0640200605\n",
      "[89] Validation loss: 0.0738966294\n",
      "[90] Train loss: 0.0576185982\n",
      "[90] Validation loss: 0.0606267300\n",
      "[91] Train loss: 0.0531020811\n",
      "[91] Validation loss: 0.0554062371\n",
      "[92] Train loss: 0.0494473239\n",
      "[92] Validation loss: 0.0551600658\n",
      "[93] Train loss: 0.0435943623\n",
      "[93] Validation loss: 0.0599015186\n",
      "[94] Train loss: 0.0404995368\n",
      "[94] Validation loss: 0.0667133039\n",
      "[95] Train loss: 0.0456050386\n",
      "[95] Validation loss: 0.0643699836\n",
      "[96] Train loss: 0.0522112843\n",
      "[96] Validation loss: 0.0521450315\n",
      "[97] Train loss: 0.0511071401\n",
      "[97] Validation loss: 0.0519290307\n",
      "[98] Train loss: 0.0460561636\n",
      "[98] Validation loss: 0.0623276024\n",
      "[99] Train loss: 0.0451543896\n",
      "[99] Validation loss: 0.0680323523\n",
      "[100] Train loss: 0.0424739270\n",
      "[100] Validation loss: 0.0778539332\n",
      "[101] Train loss: 0.0413565861\n",
      "[101] Validation loss: 0.0783916408\n",
      "[102] Train loss: 0.0405159020\n",
      "[102] Validation loss: 0.0700048843\n",
      "[103] Train loss: 0.0384634880\n",
      "[103] Validation loss: 0.0647473056\n",
      "[104] Train loss: 0.0386083716\n",
      "[104] Validation loss: 0.0629639799\n",
      "[105] Train loss: 0.0384519713\n",
      "[105] Validation loss: 0.0638507532\n",
      "[106] Train loss: 0.0367468575\n",
      "[106] Validation loss: 0.0702356643\n",
      "[107] Train loss: 0.0386088092\n",
      "[107] Validation loss: 0.0756151343\n",
      "[108] Train loss: 0.0413835669\n",
      "[108] Validation loss: 0.0710490088\n",
      "[109] Train loss: 0.0420656423\n",
      "[109] Validation loss: 0.0617965425\n",
      "[110] Train loss: 0.0430974516\n",
      "[110] Validation loss: 0.0640970643\n",
      "[111] Train loss: 0.0490656541\n",
      "[111] Validation loss: 0.0793247976\n",
      "[112] Train loss: 0.0572083304\n",
      "[112] Validation loss: 0.0973884946\n",
      "[113] Train loss: 0.0634676352\n",
      "[113] Validation loss: 0.1073141205\n",
      "[114] Train loss: 0.0742033004\n",
      "[114] Validation loss: 0.0976965057\n",
      "[115] Train loss: 0.0887797467\n",
      "[115] Validation loss: 0.0674497536\n",
      "[116] Train loss: 0.0887471316\n",
      "[116] Validation loss: 0.0563829934\n",
      "[117] Train loss: 0.0874555936\n",
      "[117] Validation loss: 0.0563179969\n",
      "[118] Train loss: 0.0717911765\n",
      "[118] Validation loss: 0.0639404752\n",
      "[119] Train loss: 0.0410686927\n",
      "[119] Validation loss: 0.0597619279\n",
      "[120] Train loss: 0.0310024238\n",
      "[120] Validation loss: 0.0478892017\n",
      "model saved\n",
      "[121] Train loss: 0.0258131332\n",
      "[121] Validation loss: 0.0473791656\n",
      "model saved\n",
      "[122] Train loss: 0.0233033521\n",
      "[122] Validation loss: 0.0528000976\n",
      "[123] Train loss: 0.0221413091\n",
      "[123] Validation loss: 0.0582509729\n",
      "[124] Train loss: 0.0201500998\n",
      "[124] Validation loss: 0.0611925527\n",
      "[125] Train loss: 0.0186643490\n",
      "[125] Validation loss: 0.0642901437\n",
      "[126] Train loss: 0.0172190702\n",
      "[126] Validation loss: 0.0695776040\n",
      "[127] Train loss: 0.0173788629\n",
      "[127] Validation loss: 0.0740273930\n",
      "[128] Train loss: 0.0190687987\n",
      "[128] Validation loss: 0.0731948356\n",
      "[129] Train loss: 0.0215182877\n",
      "[129] Validation loss: 0.0671416854\n",
      "[130] Train loss: 0.0250625160\n",
      "[130] Validation loss: 0.0611097637\n",
      "[131] Train loss: 0.0270241609\n",
      "[131] Validation loss: 0.0600171909\n",
      "[132] Train loss: 0.0285662109\n",
      "[132] Validation loss: 0.0642006304\n",
      "[133] Train loss: 0.0326263426\n",
      "[133] Validation loss: 0.0679735590\n",
      "[134] Train loss: 0.0369106640\n",
      "[134] Validation loss: 0.0788486742\n",
      "[135] Train loss: 0.0457456195\n",
      "[135] Validation loss: 0.0860847384\n",
      "[136] Train loss: 0.0617441648\n",
      "[136] Validation loss: 0.0807977032\n",
      "[137] Train loss: 0.0662509773\n",
      "[137] Validation loss: 0.0992296746\n",
      "[138] Train loss: 0.0770513488\n",
      "[138] Validation loss: 0.1102711146\n",
      "[139] Train loss: 0.0676844809\n",
      "[139] Validation loss: 0.1135011599\n",
      "[140] Train loss: 0.0570117529\n",
      "[140] Validation loss: 0.1046345872\n",
      "[141] Train loss: 0.0556866238\n",
      "[141] Validation loss: 0.0748004583\n",
      "[142] Train loss: 0.0491825143\n",
      "[142] Validation loss: 0.0623197427\n",
      "[143] Train loss: 0.0493306984\n",
      "[143] Validation loss: 0.0662588475\n",
      "[144] Train loss: 0.0479871296\n",
      "[144] Validation loss: 0.0708063456\n",
      "[145] Train loss: 0.0445154860\n",
      "[145] Validation loss: 0.0754110318\n",
      "[146] Train loss: 0.0461421092\n",
      "[146] Validation loss: 0.0604856982\n",
      "[147] Train loss: 0.0465994156\n",
      "[147] Validation loss: 0.0589220251\n",
      "[148] Train loss: 0.0419594776\n",
      "[148] Validation loss: 0.0723772339\n",
      "[149] Train loss: 0.0401162426\n",
      "[149] Validation loss: 0.0725159170\n",
      "[150] Train loss: 0.0352828397\n",
      "[150] Validation loss: 0.0650454636\n",
      "[151] Train loss: 0.0349818355\n",
      "[151] Validation loss: 0.0579376840\n",
      "[152] Train loss: 0.0353058320\n",
      "[152] Validation loss: 0.0565789859\n",
      "[153] Train loss: 0.0367140496\n",
      "[153] Validation loss: 0.0613957518\n",
      "[154] Train loss: 0.0353285039\n",
      "[154] Validation loss: 0.0721100737\n",
      "[155] Train loss: 0.0347127238\n",
      "[155] Validation loss: 0.0775701267\n",
      "[156] Train loss: 0.0385022846\n",
      "[156] Validation loss: 0.0658037650\n",
      "[157] Train loss: 0.0400682234\n",
      "[157] Validation loss: 0.0536404876\n",
      "[158] Train loss: 0.0409650825\n",
      "[158] Validation loss: 0.0612857876\n",
      "[159] Train loss: 0.0424815534\n",
      "[159] Validation loss: 0.0844476700\n",
      "[160] Train loss: 0.0439492852\n",
      "[160] Validation loss: 0.0838199414\n",
      "[161] Train loss: 0.0523116074\n",
      "[161] Validation loss: 0.0589413627\n",
      "[162] Train loss: 0.0626584877\n",
      "[162] Validation loss: 0.0588760847\n",
      "[163] Train loss: 0.0750278545\n",
      "[163] Validation loss: 0.0746580801\n",
      "[164] Train loss: 0.0619759012\n",
      "[164] Validation loss: 0.0912319346\n",
      "[165] Train loss: 0.0607404059\n",
      "[165] Validation loss: 0.0715173730\n",
      "[166] Train loss: 0.0572471139\n",
      "[166] Validation loss: 0.0638926121\n",
      "[167] Train loss: 0.0591393658\n",
      "[167] Validation loss: 0.0720056251\n",
      "[168] Train loss: 0.0564371483\n",
      "[168] Validation loss: 0.0822168584\n",
      "[169] Train loss: 0.0606849992\n",
      "[169] Validation loss: 0.0885748032\n",
      "[170] Train loss: 0.0603145411\n",
      "[170] Validation loss: 0.0959944755\n",
      "[171] Train loss: 0.0683256921\n",
      "[171] Validation loss: 0.1021082832\n",
      "[172] Train loss: 0.0765644673\n",
      "[172] Validation loss: 0.1148156277\n",
      "[173] Train loss: 0.0925529217\n",
      "[173] Validation loss: 0.1255955496\n",
      "[174] Train loss: 0.1092026516\n",
      "[174] Validation loss: 0.1240103827\n",
      "[175] Train loss: 0.1345056673\n",
      "[175] Validation loss: 0.1077821187\n",
      "[176] Train loss: 0.1631190508\n",
      "[176] Validation loss: 0.0921854251\n",
      "[177] Train loss: 0.1874033723\n",
      "[177] Validation loss: 0.0729167166\n",
      "[178] Train loss: 0.1882364620\n",
      "[178] Validation loss: 0.0965599583\n",
      "[179] Train loss: 0.1625695001\n",
      "[179] Validation loss: 0.1336217676\n",
      "[180] Train loss: 0.1199745220\n",
      "[180] Validation loss: 0.1021970103\n",
      "[181] Train loss: 0.0928758730\n",
      "[181] Validation loss: 0.0693666463\n",
      "[182] Train loss: 0.0670395580\n",
      "[182] Validation loss: 0.0620527820\n",
      "[183] Train loss: 0.0476624762\n",
      "[183] Validation loss: 0.0645116921\n",
      "[184] Train loss: 0.0345309128\n",
      "[184] Validation loss: 0.0701929418\n",
      "[185] Train loss: 0.0265679815\n",
      "[185] Validation loss: 0.0747534166\n",
      "[186] Train loss: 0.0231109330\n",
      "[186] Validation loss: 0.0786434599\n",
      "[187] Train loss: 0.0208574501\n",
      "[187] Validation loss: 0.0824617733\n",
      "[188] Train loss: 0.0190088691\n",
      "[188] Validation loss: 0.0855016946\n",
      "[189] Train loss: 0.0183623779\n",
      "[189] Validation loss: 0.0866511433\n",
      "[190] Train loss: 0.0180118261\n",
      "[190] Validation loss: 0.0847568765\n",
      "[191] Train loss: 0.0185975197\n",
      "[191] Validation loss: 0.0820846325\n",
      "[192] Train loss: 0.0179478275\n",
      "[192] Validation loss: 0.0732235111\n",
      "[193] Train loss: 0.0178409262\n",
      "[193] Validation loss: 0.0637959838\n",
      "[194] Train loss: 0.0185279420\n",
      "[194] Validation loss: 0.0561522203\n",
      "[195] Train loss: 0.0185733366\n",
      "[195] Validation loss: 0.0509663394\n",
      "[196] Train loss: 0.0205377971\n",
      "[196] Validation loss: 0.0524050623\n",
      "[197] Train loss: 0.0227100060\n",
      "[197] Validation loss: 0.0558229986\n",
      "[198] Train loss: 0.0253450623\n",
      "[198] Validation loss: 0.0584332084\n",
      "[199] Train loss: 0.0276254854\n",
      "[199] Validation loss: 0.0596288815\n",
      "[200] Train loss: 0.0288896713\n",
      "[200] Validation loss: 0.0625174560\n",
      "1 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.2509118267\n",
      "[1] Validation loss: 0.0659524149\n",
      "model saved\n",
      "[2] Train loss: 0.1385567070\n",
      "[2] Validation loss: 0.0405066343\n",
      "model saved\n",
      "[3] Train loss: 0.0839908116\n",
      "[3] Validation loss: 0.0402593716\n",
      "model saved\n",
      "[4] Train loss: 0.0565404916\n",
      "[4] Validation loss: 0.0379786639\n",
      "model saved\n",
      "[5] Train loss: 0.0398607108\n",
      "[5] Validation loss: 0.0400488717\n",
      "[6] Train loss: 0.0306835466\n",
      "[6] Validation loss: 0.0421428354\n",
      "[7] Train loss: 0.0261363904\n",
      "[7] Validation loss: 0.0423317398\n",
      "[8] Train loss: 0.0232924795\n",
      "[8] Validation loss: 0.0452349589\n",
      "[9] Train loss: 0.0222336510\n",
      "[9] Validation loss: 0.0478858408\n",
      "[10] Train loss: 0.0228355893\n",
      "[10] Validation loss: 0.0496648967\n",
      "[11] Train loss: 0.0250658641\n",
      "[11] Validation loss: 0.0570014206\n",
      "[12] Train loss: 0.0366988140\n",
      "[12] Validation loss: 0.0582648063\n",
      "[13] Train loss: 0.0531842517\n",
      "[13] Validation loss: 0.0591799242\n",
      "[14] Train loss: 0.0750228310\n",
      "[14] Validation loss: 0.0543629134\n",
      "[15] Train loss: 0.0780728954\n",
      "[15] Validation loss: 0.0559027622\n",
      "[16] Train loss: 0.0860952434\n",
      "[16] Validation loss: 0.0450466782\n",
      "[17] Train loss: 0.0659200641\n",
      "[17] Validation loss: 0.0466243364\n",
      "[18] Train loss: 0.0414190199\n",
      "[18] Validation loss: 0.0417181453\n",
      "[19] Train loss: 0.0274425042\n",
      "[19] Validation loss: 0.0431865411\n",
      "[20] Train loss: 0.0215528541\n",
      "[20] Validation loss: 0.0433090206\n",
      "[21] Train loss: 0.0174566517\n",
      "[21] Validation loss: 0.0425909975\n",
      "[22] Train loss: 0.0146378192\n",
      "[22] Validation loss: 0.0448291141\n",
      "[23] Train loss: 0.0127779605\n",
      "[23] Validation loss: 0.0477100037\n",
      "[24] Train loss: 0.0120866171\n",
      "[24] Validation loss: 0.0439762626\n",
      "[25] Train loss: 0.0128534412\n",
      "[25] Validation loss: 0.0376198955\n",
      "model saved\n",
      "[26] Train loss: 0.0132403536\n",
      "[26] Validation loss: 0.0350305089\n",
      "model saved\n",
      "[27] Train loss: 0.0130094038\n",
      "[27] Validation loss: 0.0349747928\n",
      "model saved\n",
      "[28] Train loss: 0.0136843926\n",
      "[28] Validation loss: 0.0354106972\n",
      "[29] Train loss: 0.0146183642\n",
      "[29] Validation loss: 0.0351382243\n",
      "[30] Train loss: 0.0157336202\n",
      "[30] Validation loss: 0.0373441434\n",
      "[31] Train loss: 0.0172591023\n",
      "[31] Validation loss: 0.0403539289\n",
      "[32] Train loss: 0.0191777601\n",
      "[32] Validation loss: 0.0391057724\n",
      "[33] Train loss: 0.0213270936\n",
      "[33] Validation loss: 0.0390878473\n",
      "[34] Train loss: 0.0237326265\n",
      "[34] Validation loss: 0.0408143864\n",
      "[35] Train loss: 0.0263569150\n",
      "[35] Validation loss: 0.0452353592\n",
      "[36] Train loss: 0.0292224787\n",
      "[36] Validation loss: 0.0543200475\n",
      "[37] Train loss: 0.0358048685\n",
      "[37] Validation loss: 0.0558364810\n",
      "[38] Train loss: 0.0415803671\n",
      "[38] Validation loss: 0.0528102720\n",
      "[39] Train loss: 0.0421947162\n",
      "[39] Validation loss: 0.0627529593\n",
      "[40] Train loss: 0.0407512989\n",
      "[40] Validation loss: 0.0542900473\n",
      "[41] Train loss: 0.0439867248\n",
      "[41] Validation loss: 0.0373107751\n",
      "[42] Train loss: 0.0392149202\n",
      "[42] Validation loss: 0.0355638545\n",
      "[43] Train loss: 0.0355944887\n",
      "[43] Validation loss: 0.0410432384\n",
      "[44] Train loss: 0.0339747235\n",
      "[44] Validation loss: 0.0433028825\n",
      "[45] Train loss: 0.0343294540\n",
      "[45] Validation loss: 0.0372478471\n",
      "[46] Train loss: 0.0329647781\n",
      "[46] Validation loss: 0.0354955221\n",
      "[47] Train loss: 0.0321217703\n",
      "[47] Validation loss: 0.0402750416\n",
      "[48] Train loss: 0.0269356716\n",
      "[48] Validation loss: 0.0502845860\n",
      "[49] Train loss: 0.0271699221\n",
      "[49] Validation loss: 0.0568041857\n",
      "[50] Train loss: 0.0273565934\n",
      "[50] Validation loss: 0.0414394434\n",
      "[51] Train loss: 0.0267846594\n",
      "[51] Validation loss: 0.0429219321\n",
      "[52] Train loss: 0.0264904429\n",
      "[52] Validation loss: 0.0436958614\n",
      "[53] Train loss: 0.0260482423\n",
      "[53] Validation loss: 0.0431194898\n",
      "[54] Train loss: 0.0270902051\n",
      "[54] Validation loss: 0.0505043899\n",
      "[55] Train loss: 0.0308545003\n",
      "[55] Validation loss: 0.0725839001\n",
      "[56] Train loss: 0.0358538967\n",
      "[56] Validation loss: 0.0870041172\n",
      "[57] Train loss: 0.0398043406\n",
      "[57] Validation loss: 0.0732924070\n",
      "[58] Train loss: 0.0449786050\n",
      "[58] Validation loss: 0.0592312962\n",
      "[59] Train loss: 0.0602360760\n",
      "[59] Validation loss: 0.0544816784\n",
      "[60] Train loss: 0.0823384021\n",
      "[60] Validation loss: 0.0491656816\n",
      "[61] Train loss: 0.1027284153\n",
      "[61] Validation loss: 0.0412238992\n",
      "[62] Train loss: 0.1190141256\n",
      "[62] Validation loss: 0.0619976457\n",
      "[63] Train loss: 0.1053005241\n",
      "[63] Validation loss: 0.0887063402\n",
      "[64] Train loss: 0.0832949028\n",
      "[64] Validation loss: 0.0629232454\n",
      "[65] Train loss: 0.0655617404\n",
      "[65] Validation loss: 0.0543769069\n",
      "[66] Train loss: 0.0462207436\n",
      "[66] Validation loss: 0.0653692361\n",
      "[67] Train loss: 0.0309585954\n",
      "[67] Validation loss: 0.0582506941\n",
      "[68] Train loss: 0.0197110422\n",
      "[68] Validation loss: 0.0466561079\n",
      "[69] Train loss: 0.0139227252\n",
      "[69] Validation loss: 0.0481618289\n",
      "[70] Train loss: 0.0118116079\n",
      "[70] Validation loss: 0.0543722122\n",
      "[71] Train loss: 0.0108176790\n",
      "[71] Validation loss: 0.0457310128\n",
      "[72] Train loss: 0.0110623096\n",
      "[72] Validation loss: 0.0387464226\n",
      "[73] Train loss: 0.0112010382\n",
      "[73] Validation loss: 0.0376506677\n",
      "[74] Train loss: 0.0116481788\n",
      "[74] Validation loss: 0.0380987885\n",
      "[75] Train loss: 0.0128317588\n",
      "[75] Validation loss: 0.0365379558\n",
      "[76] Train loss: 0.0142115320\n",
      "[76] Validation loss: 0.0333777023\n",
      "model saved\n",
      "[77] Train loss: 0.0155120281\n",
      "[77] Validation loss: 0.0333064554\n",
      "model saved\n",
      "[78] Train loss: 0.0170878797\n",
      "[78] Validation loss: 0.0372113464\n",
      "[79] Train loss: 0.0177684309\n",
      "[79] Validation loss: 0.0424933430\n",
      "[80] Train loss: 0.0194653774\n",
      "[80] Validation loss: 0.0442856788\n",
      "[81] Train loss: 0.0217395283\n",
      "[81] Validation loss: 0.0473252236\n",
      "[82] Train loss: 0.0221939270\n",
      "[82] Validation loss: 0.0553102314\n",
      "[83] Train loss: 0.0229479046\n",
      "[83] Validation loss: 0.0800568706\n",
      "[84] Train loss: 0.0260071334\n",
      "[84] Validation loss: 0.0781989333\n",
      "[85] Train loss: 0.0274851975\n",
      "[85] Validation loss: 0.0528427028\n",
      "[86] Train loss: 0.0246402543\n",
      "[86] Validation loss: 0.0456075094\n",
      "[87] Train loss: 0.0240109317\n",
      "[87] Validation loss: 0.0664502491\n",
      "[88] Train loss: 0.0218154224\n",
      "[88] Validation loss: 0.0967140348\n",
      "[89] Train loss: 0.0180949847\n",
      "[89] Validation loss: 0.0941169460\n",
      "[90] Train loss: 0.0205704263\n",
      "[90] Validation loss: 0.0699807470\n",
      "[91] Train loss: 0.0234345171\n",
      "[91] Validation loss: 0.0967470650\n",
      "[92] Train loss: 0.0202710605\n",
      "[92] Validation loss: 0.1384753512\n",
      "[93] Train loss: 0.0191944917\n",
      "[93] Validation loss: 0.1252200000\n",
      "[94] Train loss: 0.0208682448\n",
      "[94] Validation loss: 0.0790411674\n",
      "[95] Train loss: 0.0216621291\n",
      "[95] Validation loss: 0.0747466845\n",
      "[96] Train loss: 0.0210621479\n",
      "[96] Validation loss: 0.0992530412\n",
      "[97] Train loss: 0.0195049903\n",
      "[97] Validation loss: 0.0809257871\n",
      "[98] Train loss: 0.0190800724\n",
      "[98] Validation loss: 0.0512881745\n",
      "[99] Train loss: 0.0191889264\n",
      "[99] Validation loss: 0.0400929821\n",
      "[100] Train loss: 0.0212248097\n",
      "[100] Validation loss: 0.0414765127\n",
      "[101] Train loss: 0.0217732862\n",
      "[101] Validation loss: 0.0343100886\n",
      "[102] Train loss: 0.0230920659\n",
      "[102] Validation loss: 0.0330415760\n",
      "model saved\n",
      "[103] Train loss: 0.0259152476\n",
      "[103] Validation loss: 0.0362140011\n",
      "[104] Train loss: 0.0320503944\n",
      "[104] Validation loss: 0.0375501622\n",
      "[105] Train loss: 0.0352128776\n",
      "[105] Validation loss: 0.0344942322\n",
      "[106] Train loss: 0.0383423927\n",
      "[106] Validation loss: 0.0338917874\n",
      "[107] Train loss: 0.0420756584\n",
      "[107] Validation loss: 0.0371026658\n",
      "[108] Train loss: 0.0443864213\n",
      "[108] Validation loss: 0.0533768573\n",
      "[109] Train loss: 0.0431988493\n",
      "[109] Validation loss: 0.0788532965\n",
      "[110] Train loss: 0.0416613285\n",
      "[110] Validation loss: 0.1114758602\n",
      "[111] Train loss: 0.0365172157\n",
      "[111] Validation loss: 0.1177527817\n",
      "[112] Train loss: 0.0333858491\n",
      "[112] Validation loss: 0.1098256942\n",
      "[113] Train loss: 0.0306294073\n",
      "[113] Validation loss: 0.0820510632\n",
      "[114] Train loss: 0.0224591963\n",
      "[114] Validation loss: 0.0688978392\n",
      "[115] Train loss: 0.0192115233\n",
      "[115] Validation loss: 0.0569957327\n",
      "[116] Train loss: 0.0183487223\n",
      "[116] Validation loss: 0.0471814611\n",
      "[117] Train loss: 0.0178531356\n",
      "[117] Validation loss: 0.0404278738\n",
      "[118] Train loss: 0.0174439395\n",
      "[118] Validation loss: 0.0345692082\n",
      "[119] Train loss: 0.0165688770\n",
      "[119] Validation loss: 0.0313427754\n",
      "model saved\n",
      "[120] Train loss: 0.0154958948\n",
      "[120] Validation loss: 0.0312783127\n",
      "model saved\n",
      "[121] Train loss: 0.0157920905\n",
      "[121] Validation loss: 0.0306136584\n",
      "model saved\n",
      "[122] Train loss: 0.0167236338\n",
      "[122] Validation loss: 0.0293128356\n",
      "model saved\n",
      "[123] Train loss: 0.0172452754\n",
      "[123] Validation loss: 0.0290972057\n",
      "model saved\n",
      "[124] Train loss: 0.0172736872\n",
      "[124] Validation loss: 0.0320175226\n",
      "[125] Train loss: 0.0186659450\n",
      "[125] Validation loss: 0.0399005914\n",
      "[126] Train loss: 0.0194461184\n",
      "[126] Validation loss: 0.0534831663\n",
      "[127] Train loss: 0.0201076813\n",
      "[127] Validation loss: 0.0659934522\n",
      "[128] Train loss: 0.0222975386\n",
      "[128] Validation loss: 0.0728771855\n",
      "[129] Train loss: 0.0246393335\n",
      "[129] Validation loss: 0.0895105804\n",
      "[130] Train loss: 0.0239625463\n",
      "[130] Validation loss: 0.0789346965\n",
      "[131] Train loss: 0.0214854003\n",
      "[131] Validation loss: 0.0510196993\n",
      "[132] Train loss: 0.0202872048\n",
      "[132] Validation loss: 0.0347569629\n",
      "[133] Train loss: 0.0193940307\n",
      "[133] Validation loss: 0.0338597472\n",
      "[134] Train loss: 0.0177286061\n",
      "[134] Validation loss: 0.0415227697\n",
      "[135] Train loss: 0.0182450043\n",
      "[135] Validation loss: 0.0413986777\n",
      "[136] Train loss: 0.0200204042\n",
      "[136] Validation loss: 0.0363011958\n",
      "[137] Train loss: 0.0226268337\n",
      "[137] Validation loss: 0.0330857508\n",
      "[138] Train loss: 0.0210071227\n",
      "[138] Validation loss: 0.0359469996\n",
      "[139] Train loss: 0.0210156296\n",
      "[139] Validation loss: 0.0408187237\n",
      "[140] Train loss: 0.0237401458\n",
      "[140] Validation loss: 0.0403609416\n",
      "[141] Train loss: 0.0207254870\n",
      "[141] Validation loss: 0.0408955636\n",
      "[142] Train loss: 0.0198478936\n",
      "[142] Validation loss: 0.0421237486\n",
      "[143] Train loss: 0.0185031219\n",
      "[143] Validation loss: 0.0374861151\n",
      "[144] Train loss: 0.0168215395\n",
      "[144] Validation loss: 0.0346696592\n",
      "[145] Train loss: 0.0153112693\n",
      "[145] Validation loss: 0.0371409510\n",
      "[146] Train loss: 0.0128809494\n",
      "[146] Validation loss: 0.0402189539\n",
      "[147] Train loss: 0.0116519409\n",
      "[147] Validation loss: 0.0416394381\n",
      "[148] Train loss: 0.0112095740\n",
      "[148] Validation loss: 0.0467257372\n",
      "[149] Train loss: 0.0105418870\n",
      "[149] Validation loss: 0.0452432111\n",
      "[150] Train loss: 0.0103247687\n",
      "[150] Validation loss: 0.0401407202\n",
      "[151] Train loss: 0.0104292718\n",
      "[151] Validation loss: 0.0360316863\n",
      "[152] Train loss: 0.0104159365\n",
      "[152] Validation loss: 0.0356126885\n",
      "[153] Train loss: 0.0107018002\n",
      "[153] Validation loss: 0.0373877579\n",
      "[154] Train loss: 0.0117769062\n",
      "[154] Validation loss: 0.0429294746\n",
      "[155] Train loss: 0.0121434407\n",
      "[155] Validation loss: 0.0553308427\n",
      "[156] Train loss: 0.0134200345\n",
      "[156] Validation loss: 0.0560891915\n",
      "[157] Train loss: 0.0139280582\n",
      "[157] Validation loss: 0.0452451936\n",
      "[158] Train loss: 0.0154639671\n",
      "[158] Validation loss: 0.0399431622\n",
      "[159] Train loss: 0.0156679224\n",
      "[159] Validation loss: 0.0337296032\n",
      "[160] Train loss: 0.0160988755\n",
      "[160] Validation loss: 0.0315697587\n",
      "[161] Train loss: 0.0196438262\n",
      "[161] Validation loss: 0.0320592132\n",
      "[162] Train loss: 0.0217469628\n",
      "[162] Validation loss: 0.0408806230\n",
      "[163] Train loss: 0.0229451369\n",
      "[163] Validation loss: 0.0397617773\n",
      "[164] Train loss: 0.0231527030\n",
      "[164] Validation loss: 0.0336043151\n",
      "[165] Train loss: 0.0212269912\n",
      "[165] Validation loss: 0.0327015667\n",
      "[166] Train loss: 0.0188688799\n",
      "[166] Validation loss: 0.0315401784\n",
      "[167] Train loss: 0.0197325284\n",
      "[167] Validation loss: 0.0320796046\n",
      "[168] Train loss: 0.0214176435\n",
      "[168] Validation loss: 0.0324517128\n",
      "[169] Train loss: 0.0237379234\n",
      "[169] Validation loss: 0.0398476431\n",
      "[170] Train loss: 0.0242981884\n",
      "[170] Validation loss: 0.0376498306\n",
      "[171] Train loss: 0.0239705428\n",
      "[171] Validation loss: 0.0432738736\n",
      "[172] Train loss: 0.0210503155\n",
      "[172] Validation loss: 0.0460834113\n",
      "[173] Train loss: 0.0229614261\n",
      "[173] Validation loss: 0.0500683927\n",
      "[174] Train loss: 0.0274120390\n",
      "[174] Validation loss: 0.0491926267\n",
      "[175] Train loss: 0.0288398080\n",
      "[175] Validation loss: 0.0614898396\n",
      "[176] Train loss: 0.0311578974\n",
      "[176] Validation loss: 0.0850812530\n",
      "[177] Train loss: 0.0309319810\n",
      "[177] Validation loss: 0.1124785218\n",
      "[178] Train loss: 0.0345574940\n",
      "[178] Validation loss: 0.1181173752\n",
      "[179] Train loss: 0.0412559221\n",
      "[179] Validation loss: 0.1066632720\n",
      "[180] Train loss: 0.0453770324\n",
      "[180] Validation loss: 0.1282100952\n",
      "[181] Train loss: 0.0443948893\n",
      "[181] Validation loss: 0.0926419478\n",
      "[182] Train loss: 0.0427865270\n",
      "[182] Validation loss: 0.0624687201\n",
      "[183] Train loss: 0.0385853187\n",
      "[183] Validation loss: 0.0465096486\n",
      "[184] Train loss: 0.0338316659\n",
      "[184] Validation loss: 0.0358722276\n",
      "[185] Train loss: 0.0292160531\n",
      "[185] Validation loss: 0.0317185220\n",
      "[186] Train loss: 0.0236569768\n",
      "[186] Validation loss: 0.0340439320\n",
      "[187] Train loss: 0.0188019153\n",
      "[187] Validation loss: 0.0366057702\n",
      "[188] Train loss: 0.0154317026\n",
      "[188] Validation loss: 0.0353645065\n",
      "[189] Train loss: 0.0136262980\n",
      "[189] Validation loss: 0.0345085509\n",
      "[190] Train loss: 0.0114284667\n",
      "[190] Validation loss: 0.0354393022\n",
      "[191] Train loss: 0.0110831704\n",
      "[191] Validation loss: 0.0351910113\n",
      "[192] Train loss: 0.0121963319\n",
      "[192] Validation loss: 0.0332119834\n",
      "[193] Train loss: 0.0135016842\n",
      "[193] Validation loss: 0.0313160173\n",
      "[194] Train loss: 0.0147940986\n",
      "[194] Validation loss: 0.0292645947\n",
      "[195] Train loss: 0.0151051630\n",
      "[195] Validation loss: 0.0272913553\n",
      "model saved\n",
      "[196] Train loss: 0.0149886849\n",
      "[196] Validation loss: 0.0260105227\n",
      "model saved\n",
      "[197] Train loss: 0.0144633682\n",
      "[197] Validation loss: 0.0249639651\n",
      "model saved\n",
      "[198] Train loss: 0.0144235241\n",
      "[198] Validation loss: 0.0259949726\n",
      "[199] Train loss: 0.0140974804\n",
      "[199] Validation loss: 0.0273935248\n",
      "[200] Train loss: 0.0151539812\n",
      "[200] Validation loss: 0.0364061559\n",
      "2 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.2273678645\n",
      "[1] Validation loss: 0.0312230772\n",
      "model saved\n",
      "[2] Train loss: 0.1292032548\n",
      "[2] Validation loss: 0.0266058663\n",
      "model saved\n",
      "[3] Train loss: 0.0814573037\n",
      "[3] Validation loss: 0.0264167133\n",
      "model saved\n",
      "[4] Train loss: 0.0621188717\n",
      "[4] Validation loss: 0.0265200918\n",
      "[5] Train loss: 0.0476638035\n",
      "[5] Validation loss: 0.0260821099\n",
      "model saved\n",
      "[6] Train loss: 0.0372796073\n",
      "[6] Validation loss: 0.0261377996\n",
      "[7] Train loss: 0.0281940296\n",
      "[7] Validation loss: 0.0256574682\n",
      "model saved\n",
      "[8] Train loss: 0.0215427615\n",
      "[8] Validation loss: 0.0279345195\n",
      "[9] Train loss: 0.0179275924\n",
      "[9] Validation loss: 0.0290306617\n",
      "[10] Train loss: 0.0140648140\n",
      "[10] Validation loss: 0.0297683164\n",
      "[11] Train loss: 0.0121309892\n",
      "[11] Validation loss: 0.0294284828\n",
      "[12] Train loss: 0.0097252114\n",
      "[12] Validation loss: 0.0271876853\n",
      "[13] Train loss: 0.0098416021\n",
      "[13] Validation loss: 0.0281418344\n",
      "[14] Train loss: 0.0083572472\n",
      "[14] Validation loss: 0.0261195207\n",
      "[15] Train loss: 0.0082387252\n",
      "[15] Validation loss: 0.0273137583\n",
      "[16] Train loss: 0.0090640506\n",
      "[16] Validation loss: 0.0291471772\n",
      "[17] Train loss: 0.0101898452\n",
      "[17] Validation loss: 0.0295654989\n",
      "[18] Train loss: 0.0111649751\n",
      "[18] Validation loss: 0.0307130340\n",
      "[19] Train loss: 0.0145222051\n",
      "[19] Validation loss: 0.0314578384\n",
      "[20] Train loss: 0.0144160284\n",
      "[20] Validation loss: 0.0370835216\n",
      "[21] Train loss: 0.0146590843\n",
      "[21] Validation loss: 0.0307337097\n",
      "[22] Train loss: 0.0141423632\n",
      "[22] Validation loss: 0.0306787742\n",
      "[23] Train loss: 0.0127166196\n",
      "[23] Validation loss: 0.0288549013\n",
      "[24] Train loss: 0.0108286695\n",
      "[24] Validation loss: 0.0246036844\n",
      "model saved\n",
      "[25] Train loss: 0.0108191769\n",
      "[25] Validation loss: 0.0232216323\n",
      "model saved\n",
      "[26] Train loss: 0.0105124386\n",
      "[26] Validation loss: 0.0236835740\n",
      "[27] Train loss: 0.0094387713\n",
      "[27] Validation loss: 0.0255298376\n",
      "[28] Train loss: 0.0092075331\n",
      "[28] Validation loss: 0.0294860832\n",
      "[29] Train loss: 0.0085269126\n",
      "[29] Validation loss: 0.0301541510\n",
      "[30] Train loss: 0.0082665426\n",
      "[30] Validation loss: 0.0302611716\n",
      "[31] Train loss: 0.0095330970\n",
      "[31] Validation loss: 0.0255222142\n",
      "[32] Train loss: 0.0085453395\n",
      "[32] Validation loss: 0.0259803419\n",
      "[33] Train loss: 0.0079049983\n",
      "[33] Validation loss: 0.0285045692\n",
      "[34] Train loss: 0.0071657687\n",
      "[34] Validation loss: 0.0264473121\n",
      "[35] Train loss: 0.0063229299\n",
      "[35] Validation loss: 0.0279470186\n",
      "[36] Train loss: 0.0055666337\n",
      "[36] Validation loss: 0.0273166325\n",
      "[37] Train loss: 0.0050337108\n",
      "[37] Validation loss: 0.0262978594\n",
      "[38] Train loss: 0.0047229462\n",
      "[38] Validation loss: 0.0285721684\n",
      "[39] Train loss: 0.0050732137\n",
      "[39] Validation loss: 0.0287629173\n",
      "[40] Train loss: 0.0041057291\n",
      "[40] Validation loss: 0.0263354060\n",
      "[41] Train loss: 0.0044894919\n",
      "[41] Validation loss: 0.0267125104\n",
      "[42] Train loss: 0.0044856830\n",
      "[42] Validation loss: 0.0252109990\n",
      "[43] Train loss: 0.0046128016\n",
      "[43] Validation loss: 0.0243631127\n",
      "[44] Train loss: 0.0053342772\n",
      "[44] Validation loss: 0.0275841584\n",
      "[45] Train loss: 0.0056646178\n",
      "[45] Validation loss: 0.0249765529\n",
      "[46] Train loss: 0.0050676537\n",
      "[46] Validation loss: 0.0244080883\n",
      "[47] Train loss: 0.0066468600\n",
      "[47] Validation loss: 0.0306652938\n",
      "[48] Train loss: 0.0067480943\n",
      "[48] Validation loss: 0.0241852166\n",
      "[49] Train loss: 0.0058690944\n",
      "[49] Validation loss: 0.0235451327\n",
      "[50] Train loss: 0.0080309233\n",
      "[50] Validation loss: 0.0256469762\n",
      "[51] Train loss: 0.0086404303\n",
      "[51] Validation loss: 0.0225929749\n",
      "model saved\n",
      "[52] Train loss: 0.0094415644\n",
      "[52] Validation loss: 0.0241652848\n",
      "[53] Train loss: 0.0125125679\n",
      "[53] Validation loss: 0.0272773629\n",
      "[54] Train loss: 0.0102240015\n",
      "[54] Validation loss: 0.0256287159\n",
      "[55] Train loss: 0.0136542389\n",
      "[55] Validation loss: 0.0222270355\n",
      "model saved\n",
      "[56] Train loss: 0.0131264417\n",
      "[56] Validation loss: 0.0244612673\n",
      "[57] Train loss: 0.0133381978\n",
      "[57] Validation loss: 0.0250458185\n",
      "[58] Train loss: 0.0132075906\n",
      "[58] Validation loss: 0.0274368286\n",
      "[59] Train loss: 0.0121769761\n",
      "[59] Validation loss: 0.0232974406\n",
      "[60] Train loss: 0.0069418891\n",
      "[60] Validation loss: 0.0237402573\n",
      "[61] Train loss: 0.0068505346\n",
      "[61] Validation loss: 0.0242384193\n",
      "[62] Train loss: 0.0060702096\n",
      "[62] Validation loss: 0.0259117752\n",
      "[63] Train loss: 0.0063371383\n",
      "[63] Validation loss: 0.0271811450\n",
      "[64] Train loss: 0.0073288763\n",
      "[64] Validation loss: 0.0256355247\n",
      "[65] Train loss: 0.0075138934\n",
      "[65] Validation loss: 0.0275279638\n",
      "[66] Train loss: 0.0060562286\n",
      "[66] Validation loss: 0.0264835205\n",
      "[67] Train loss: 0.0054749190\n",
      "[67] Validation loss: 0.0245041797\n",
      "[68] Train loss: 0.0054407849\n",
      "[68] Validation loss: 0.0251859729\n",
      "[69] Train loss: 0.0057910556\n",
      "[69] Validation loss: 0.0244215679\n",
      "[70] Train loss: 0.0046006535\n",
      "[70] Validation loss: 0.0290275993\n",
      "[71] Train loss: 0.0043515552\n",
      "[71] Validation loss: 0.0282267283\n",
      "[72] Train loss: 0.0035951998\n",
      "[72] Validation loss: 0.0259148729\n",
      "[73] Train loss: 0.0039519958\n",
      "[73] Validation loss: 0.0265592698\n",
      "[74] Train loss: 0.0042537691\n",
      "[74] Validation loss: 0.0278692465\n",
      "[75] Train loss: 0.0037535894\n",
      "[75] Validation loss: 0.0282455184\n",
      "[76] Train loss: 0.0041772134\n",
      "[76] Validation loss: 0.0280901487\n",
      "[77] Train loss: 0.0042576630\n",
      "[77] Validation loss: 0.0278513907\n",
      "[78] Train loss: 0.0043215639\n",
      "[78] Validation loss: 0.0259869228\n",
      "[79] Train loss: 0.0049984540\n",
      "[79] Validation loss: 0.0286150737\n",
      "[80] Train loss: 0.0058902929\n",
      "[80] Validation loss: 0.0290462662\n",
      "[81] Train loss: 0.0066660071\n",
      "[81] Validation loss: 0.0234978275\n",
      "[82] Train loss: 0.0068620465\n",
      "[82] Validation loss: 0.0262981362\n",
      "[83] Train loss: 0.0061100405\n",
      "[83] Validation loss: 0.0266932486\n",
      "[84] Train loss: 0.0057782388\n",
      "[84] Validation loss: 0.0222008459\n",
      "model saved\n",
      "[85] Train loss: 0.0069770915\n",
      "[85] Validation loss: 0.0268736571\n",
      "[86] Train loss: 0.0072496919\n",
      "[86] Validation loss: 0.0195033103\n",
      "model saved\n",
      "[87] Train loss: 0.0068862281\n",
      "[87] Validation loss: 0.0212504775\n",
      "[88] Train loss: 0.0086454809\n",
      "[88] Validation loss: 0.0256334165\n",
      "[89] Train loss: 0.0095886357\n",
      "[89] Validation loss: 0.0244696604\n",
      "[90] Train loss: 0.0090344499\n",
      "[90] Validation loss: 0.0216419426\n",
      "[91] Train loss: 0.0118685140\n",
      "[91] Validation loss: 0.0242337185\n",
      "[92] Train loss: 0.0110122239\n",
      "[92] Validation loss: 0.0257894776\n",
      "[93] Train loss: 0.0129821194\n",
      "[93] Validation loss: 0.0248784341\n",
      "[94] Train loss: 0.0109880675\n",
      "[94] Validation loss: 0.0249731535\n",
      "[95] Train loss: 0.0099394948\n",
      "[95] Validation loss: 0.0284984020\n",
      "[96] Train loss: 0.0089783307\n",
      "[96] Validation loss: 0.0303653157\n",
      "[97] Train loss: 0.0103338386\n",
      "[97] Validation loss: 0.0282792309\n",
      "[98] Train loss: 0.0114480747\n",
      "[98] Validation loss: 0.0299605120\n",
      "[99] Train loss: 0.0103831986\n",
      "[99] Validation loss: 0.0320662722\n",
      "[100] Train loss: 0.0104613772\n",
      "[100] Validation loss: 0.0283731690\n",
      "[101] Train loss: 0.0121508024\n",
      "[101] Validation loss: 0.0289515129\n",
      "[102] Train loss: 0.0109629449\n",
      "[102] Validation loss: 0.0278700283\n",
      "[103] Train loss: 0.0108963376\n",
      "[103] Validation loss: 0.0293997094\n",
      "[104] Train loss: 0.0112092963\n",
      "[104] Validation loss: 0.0357818044\n",
      "[105] Train loss: 0.0108739950\n",
      "[105] Validation loss: 0.0296855093\n",
      "[106] Train loss: 0.0101296521\n",
      "[106] Validation loss: 0.0317366960\n",
      "[107] Train loss: 0.0087745563\n",
      "[107] Validation loss: 0.0320019844\n",
      "[108] Train loss: 0.0077100928\n",
      "[108] Validation loss: 0.0274105060\n",
      "[109] Train loss: 0.0066791427\n",
      "[109] Validation loss: 0.0280407859\n",
      "[110] Train loss: 0.0066456859\n",
      "[110] Validation loss: 0.0266642026\n",
      "[111] Train loss: 0.0061927101\n",
      "[111] Validation loss: 0.0242212986\n",
      "[112] Train loss: 0.0061220051\n",
      "[112] Validation loss: 0.0238171784\n",
      "[113] Train loss: 0.0067032856\n",
      "[113] Validation loss: 0.0233248814\n",
      "[114] Train loss: 0.0073911211\n",
      "[114] Validation loss: 0.0216014885\n",
      "[115] Train loss: 0.0084018026\n",
      "[115] Validation loss: 0.0213597637\n",
      "[116] Train loss: 0.0095495383\n",
      "[116] Validation loss: 0.0224092972\n",
      "[117] Train loss: 0.0107164588\n",
      "[117] Validation loss: 0.0265547099\n",
      "[118] Train loss: 0.0112806877\n",
      "[118] Validation loss: 0.0328813468\n",
      "[119] Train loss: 0.0110628403\n",
      "[119] Validation loss: 0.0307531730\n",
      "[120] Train loss: 0.0143761801\n",
      "[120] Validation loss: 0.0310575767\n",
      "[121] Train loss: 0.0120180935\n",
      "[121] Validation loss: 0.0291815761\n",
      "[122] Train loss: 0.0115662757\n",
      "[122] Validation loss: 0.0318257507\n",
      "[123] Train loss: 0.0082953692\n",
      "[123] Validation loss: 0.0273689200\n",
      "[124] Train loss: 0.0056668947\n",
      "[124] Validation loss: 0.0288810325\n",
      "[125] Train loss: 0.0036764177\n",
      "[125] Validation loss: 0.0235895985\n",
      "[126] Train loss: 0.0025291373\n",
      "[126] Validation loss: 0.0228153040\n",
      "[127] Train loss: 0.0024221348\n",
      "[127] Validation loss: 0.0233552322\n",
      "[128] Train loss: 0.0022815831\n",
      "[128] Validation loss: 0.0232865322\n",
      "[129] Train loss: 0.0016281727\n",
      "[129] Validation loss: 0.0251386113\n",
      "[130] Train loss: 0.0015534992\n",
      "[130] Validation loss: 0.0234770485\n",
      "[131] Train loss: 0.0014101471\n",
      "[131] Validation loss: 0.0240925685\n",
      "[132] Train loss: 0.0014360869\n",
      "[132] Validation loss: 0.0217246322\n",
      "[133] Train loss: 0.0014321313\n",
      "[133] Validation loss: 0.0201425110\n",
      "[134] Train loss: 0.0015843529\n",
      "[134] Validation loss: 0.0222568709\n",
      "[135] Train loss: 0.0020177785\n",
      "[135] Validation loss: 0.0218651552\n",
      "[136] Train loss: 0.0014687334\n",
      "[136] Validation loss: 0.0252919084\n",
      "[137] Train loss: 0.0019523081\n",
      "[137] Validation loss: 0.0245738636\n",
      "[138] Train loss: 0.0020835251\n",
      "[138] Validation loss: 0.0269211804\n",
      "[139] Train loss: 0.0020234683\n",
      "[139] Validation loss: 0.0249763542\n",
      "[140] Train loss: 0.0019381121\n",
      "[140] Validation loss: 0.0230546742\n",
      "[141] Train loss: 0.0020123895\n",
      "[141] Validation loss: 0.0241513186\n",
      "[142] Train loss: 0.0024664809\n",
      "[142] Validation loss: 0.0240391035\n",
      "[143] Train loss: 0.0025063332\n",
      "[143] Validation loss: 0.0278003507\n",
      "[144] Train loss: 0.0030252710\n",
      "[144] Validation loss: 0.0274983505\n",
      "[145] Train loss: 0.0048342019\n",
      "[145] Validation loss: 0.0302043154\n",
      "[146] Train loss: 0.0058244157\n",
      "[146] Validation loss: 0.0294504284\n",
      "[147] Train loss: 0.0051940968\n",
      "[147] Validation loss: 0.0256409897\n",
      "[148] Train loss: 0.0060912923\n",
      "[148] Validation loss: 0.0252435179\n",
      "[149] Train loss: 0.0063912360\n",
      "[149] Validation loss: 0.0214192235\n",
      "[150] Train loss: 0.0056008339\n",
      "[150] Validation loss: 0.0258595206\n",
      "[151] Train loss: 0.0042870128\n",
      "[151] Validation loss: 0.0250856020\n",
      "[152] Train loss: 0.0032635367\n",
      "[152] Validation loss: 0.0275141335\n",
      "[153] Train loss: 0.0033366329\n",
      "[153] Validation loss: 0.0238592624\n",
      "[154] Train loss: 0.0025889479\n",
      "[154] Validation loss: 0.0237920515\n",
      "[155] Train loss: 0.0033392967\n",
      "[155] Validation loss: 0.0229955816\n",
      "[156] Train loss: 0.0036388452\n",
      "[156] Validation loss: 0.0218675860\n",
      "[157] Train loss: 0.0032351443\n",
      "[157] Validation loss: 0.0242595833\n",
      "[158] Train loss: 0.0035764368\n",
      "[158] Validation loss: 0.0250192439\n",
      "[159] Train loss: 0.0030484644\n",
      "[159] Validation loss: 0.0268072989\n",
      "[160] Train loss: 0.0032222381\n",
      "[160] Validation loss: 0.0273680580\n",
      "[161] Train loss: 0.0047414383\n",
      "[161] Validation loss: 0.0251662414\n",
      "[162] Train loss: 0.0066418093\n",
      "[162] Validation loss: 0.0295762973\n",
      "[163] Train loss: 0.0062287643\n",
      "[163] Validation loss: 0.0261217085\n",
      "[164] Train loss: 0.0048317937\n",
      "[164] Validation loss: 0.0251980664\n",
      "[165] Train loss: 0.0033420695\n",
      "[165] Validation loss: 0.0263909951\n",
      "[166] Train loss: 0.0034728269\n",
      "[166] Validation loss: 0.0268941225\n",
      "[167] Train loss: 0.0026057613\n",
      "[167] Validation loss: 0.0299015128\n",
      "[168] Train loss: 0.0023476398\n",
      "[168] Validation loss: 0.0279368482\n",
      "[169] Train loss: 0.0020975764\n",
      "[169] Validation loss: 0.0283675713\n",
      "[170] Train loss: 0.0019491795\n",
      "[170] Validation loss: 0.0264064925\n",
      "[171] Train loss: 0.0019331118\n",
      "[171] Validation loss: 0.0254236776\n",
      "[172] Train loss: 0.0019456018\n",
      "[172] Validation loss: 0.0246180475\n",
      "[173] Train loss: 0.0020848108\n",
      "[173] Validation loss: 0.0238560104\n",
      "[174] Train loss: 0.0019976644\n",
      "[174] Validation loss: 0.0240096383\n",
      "[175] Train loss: 0.0021160920\n",
      "[175] Validation loss: 0.0233606755\n",
      "[176] Train loss: 0.0024393476\n",
      "[176] Validation loss: 0.0246872895\n",
      "[177] Train loss: 0.0029321368\n",
      "[177] Validation loss: 0.0262986353\n",
      "[178] Train loss: 0.0041024104\n",
      "[178] Validation loss: 0.0210744121\n",
      "[179] Train loss: 0.0035867746\n",
      "[179] Validation loss: 0.0255041942\n",
      "[180] Train loss: 0.0033741750\n",
      "[180] Validation loss: 0.0256555810\n",
      "[181] Train loss: 0.0036284098\n",
      "[181] Validation loss: 0.0263409779\n",
      "[182] Train loss: 0.0032494700\n",
      "[182] Validation loss: 0.0274411287\n",
      "[183] Train loss: 0.0042663756\n",
      "[183] Validation loss: 0.0261880181\n",
      "[184] Train loss: 0.0039737782\n",
      "[184] Validation loss: 0.0260774753\n",
      "[185] Train loss: 0.0036376867\n",
      "[185] Validation loss: 0.0267039649\n",
      "[186] Train loss: 0.0041284619\n",
      "[186] Validation loss: 0.0234280797\n",
      "[187] Train loss: 0.0041556417\n",
      "[187] Validation loss: 0.0288442656\n",
      "[188] Train loss: 0.0030942393\n",
      "[188] Validation loss: 0.0291156202\n",
      "[189] Train loss: 0.0027311348\n",
      "[189] Validation loss: 0.0258328407\n",
      "[190] Train loss: 0.0042946445\n",
      "[190] Validation loss: 0.0224762614\n",
      "[191] Train loss: 0.0033778843\n",
      "[191] Validation loss: 0.0253926773\n",
      "[192] Train loss: 0.0046560680\n",
      "[192] Validation loss: 0.0300054217\n",
      "[193] Train loss: 0.0038166166\n",
      "[193] Validation loss: 0.0240171120\n",
      "[194] Train loss: 0.0032347277\n",
      "[194] Validation loss: 0.0226781863\n",
      "[195] Train loss: 0.0029510997\n",
      "[195] Validation loss: 0.0276008657\n",
      "[196] Train loss: 0.0023079778\n",
      "[196] Validation loss: 0.0270003943\n",
      "[197] Train loss: 0.0025273945\n",
      "[197] Validation loss: 0.0264563037\n",
      "[198] Train loss: 0.0028750373\n",
      "[198] Validation loss: 0.0229044877\n",
      "[199] Train loss: 0.0033378740\n",
      "[199] Validation loss: 0.0243551504\n",
      "[200] Train loss: 0.0033622396\n",
      "[200] Validation loss: 0.0258765822\n",
      "3 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.0960526579\n",
      "[1] Validation loss: 0.0777639845\n",
      "model saved\n",
      "[2] Train loss: 0.0543812150\n",
      "[2] Validation loss: 0.0805178536\n",
      "[3] Train loss: 0.0255898634\n",
      "[3] Validation loss: 0.0812859685\n",
      "[4] Train loss: 0.0159726278\n",
      "[4] Validation loss: 0.0793550049\n",
      "[5] Train loss: 0.0118515211\n",
      "[5] Validation loss: 0.0811899941\n",
      "[6] Train loss: 0.0088681025\n",
      "[6] Validation loss: 0.0798721760\n",
      "[7] Train loss: 0.0084370256\n",
      "[7] Validation loss: 0.0784493891\n",
      "[8] Train loss: 0.0068431460\n",
      "[8] Validation loss: 0.0814458543\n",
      "[9] Train loss: 0.0066898879\n",
      "[9] Validation loss: 0.0823345842\n",
      "[10] Train loss: 0.0066060763\n",
      "[10] Validation loss: 0.0844083664\n",
      "[11] Train loss: 0.0057245447\n",
      "[11] Validation loss: 0.0843505910\n",
      "[12] Train loss: 0.0054193327\n",
      "[12] Validation loss: 0.0855124956\n",
      "[13] Train loss: 0.0050302000\n",
      "[13] Validation loss: 0.0860982746\n",
      "[14] Train loss: 0.0058593353\n",
      "[14] Validation loss: 0.0872180306\n",
      "[15] Train loss: 0.0058260920\n",
      "[15] Validation loss: 0.0951669318\n",
      "[16] Train loss: 0.0061574268\n",
      "[16] Validation loss: 0.0996176816\n",
      "[17] Train loss: 0.0061546563\n",
      "[17] Validation loss: 0.0943629227\n",
      "[18] Train loss: 0.0055038447\n",
      "[18] Validation loss: 0.0891598148\n",
      "[19] Train loss: 0.0045367487\n",
      "[19] Validation loss: 0.0915056945\n",
      "[20] Train loss: 0.0036423951\n",
      "[20] Validation loss: 0.0867967586\n",
      "[21] Train loss: 0.0036467344\n",
      "[21] Validation loss: 0.0877381922\n",
      "[22] Train loss: 0.0032037294\n",
      "[22] Validation loss: 0.0904111476\n",
      "[23] Train loss: 0.0029032491\n",
      "[23] Validation loss: 0.0873473283\n",
      "[24] Train loss: 0.0025423387\n",
      "[24] Validation loss: 0.0858372160\n",
      "[25] Train loss: 0.0021186526\n",
      "[25] Validation loss: 0.0849012864\n",
      "[26] Train loss: 0.0019556202\n",
      "[26] Validation loss: 0.0839352281\n",
      "[27] Train loss: 0.0019563700\n",
      "[27] Validation loss: 0.0847877419\n",
      "[28] Train loss: 0.0017717316\n",
      "[28] Validation loss: 0.0854484366\n",
      "[29] Train loss: 0.0018979164\n",
      "[29] Validation loss: 0.0855999403\n",
      "[30] Train loss: 0.0020105393\n",
      "[30] Validation loss: 0.0870896626\n",
      "[31] Train loss: 0.0019922313\n",
      "[31] Validation loss: 0.0861483814\n",
      "[32] Train loss: 0.0023822701\n",
      "[32] Validation loss: 0.0858048563\n",
      "[33] Train loss: 0.0024789882\n",
      "[33] Validation loss: 0.0887665869\n",
      "[34] Train loss: 0.0027525809\n",
      "[34] Validation loss: 0.0908088500\n",
      "[35] Train loss: 0.0042554007\n",
      "[35] Validation loss: 0.0927979344\n",
      "[36] Train loss: 0.0060256729\n",
      "[36] Validation loss: 0.0898258789\n",
      "[37] Train loss: 0.0061579447\n",
      "[37] Validation loss: 0.0974102315\n",
      "[38] Train loss: 0.0049511907\n",
      "[38] Validation loss: 0.0883208374\n",
      "[39] Train loss: 0.0037157628\n",
      "[39] Validation loss: 0.0926866946\n",
      "[40] Train loss: 0.0040463261\n",
      "[40] Validation loss: 0.0994890369\n",
      "[41] Train loss: 0.0038195966\n",
      "[41] Validation loss: 0.0979308172\n",
      "[42] Train loss: 0.0036356407\n",
      "[42] Validation loss: 0.0899896833\n",
      "[43] Train loss: 0.0033956900\n",
      "[43] Validation loss: 0.0899146177\n",
      "[44] Train loss: 0.0028393006\n",
      "[44] Validation loss: 0.0855944600\n",
      "[45] Train loss: 0.0027150513\n",
      "[45] Validation loss: 0.0851588099\n",
      "[46] Train loss: 0.0022512487\n",
      "[46] Validation loss: 0.0862672534\n",
      "[47] Train loss: 0.0025181677\n",
      "[47] Validation loss: 0.0873049625\n",
      "[48] Train loss: 0.0022743624\n",
      "[48] Validation loss: 0.0863065107\n",
      "[49] Train loss: 0.0019166522\n",
      "[49] Validation loss: 0.0850432387\n",
      "[50] Train loss: 0.0023637683\n",
      "[50] Validation loss: 0.0866532553\n",
      "[51] Train loss: 0.0036275104\n",
      "[51] Validation loss: 0.0866106386\n",
      "[52] Train loss: 0.0047378055\n",
      "[52] Validation loss: 0.0845104374\n",
      "[53] Train loss: 0.0047164665\n",
      "[53] Validation loss: 0.0885309946\n",
      "[54] Train loss: 0.0048209862\n",
      "[54] Validation loss: 0.0904724958\n",
      "[55] Train loss: 0.0045421311\n",
      "[55] Validation loss: 0.0874437504\n",
      "[56] Train loss: 0.0047761098\n",
      "[56] Validation loss: 0.0903410614\n",
      "[57] Train loss: 0.0038970471\n",
      "[57] Validation loss: 0.0920186943\n",
      "[58] Train loss: 0.0036542706\n",
      "[58] Validation loss: 0.0966795810\n",
      "[59] Train loss: 0.0043679477\n",
      "[59] Validation loss: 0.0934181127\n",
      "[60] Train loss: 0.0038319417\n",
      "[60] Validation loss: 0.1028404837\n",
      "[61] Train loss: 0.0045145170\n",
      "[61] Validation loss: 0.1036913787\n",
      "[62] Train loss: 0.0038569259\n",
      "[62] Validation loss: 0.0909750397\n",
      "[63] Train loss: 0.0037268561\n",
      "[63] Validation loss: 0.0931578911\n",
      "[64] Train loss: 0.0031172523\n",
      "[64] Validation loss: 0.0943884246\n",
      "[65] Train loss: 0.0023931263\n",
      "[65] Validation loss: 0.0912064130\n",
      "[66] Train loss: 0.0021772420\n",
      "[66] Validation loss: 0.0895374683\n",
      "[67] Train loss: 0.0021737860\n",
      "[67] Validation loss: 0.0888024506\n",
      "[68] Train loss: 0.0023637126\n",
      "[68] Validation loss: 0.0873286915\n",
      "[69] Train loss: 0.0031599110\n",
      "[69] Validation loss: 0.0846405378\n",
      "[70] Train loss: 0.0028755445\n",
      "[70] Validation loss: 0.0835395585\n",
      "[71] Train loss: 0.0039827731\n",
      "[71] Validation loss: 0.0853547553\n",
      "[72] Train loss: 0.0043344971\n",
      "[72] Validation loss: 0.0923221647\n",
      "[73] Train loss: 0.0049811690\n",
      "[73] Validation loss: 0.0882567434\n",
      "[74] Train loss: 0.0048903522\n",
      "[74] Validation loss: 0.0865524569\n",
      "[75] Train loss: 0.0044937094\n",
      "[75] Validation loss: 0.0871476000\n",
      "[76] Train loss: 0.0057497528\n",
      "[76] Validation loss: 0.0849647294\n",
      "[77] Train loss: 0.0070144807\n",
      "[77] Validation loss: 0.0917582606\n",
      "[78] Train loss: 0.0071258019\n",
      "[78] Validation loss: 0.1101383260\n",
      "[79] Train loss: 0.0093500923\n",
      "[79] Validation loss: 0.1016969054\n",
      "[80] Train loss: 0.0072152909\n",
      "[80] Validation loss: 0.0998070630\n",
      "[81] Train loss: 0.0057637686\n",
      "[81] Validation loss: 0.1060684715\n",
      "[82] Train loss: 0.0051954974\n",
      "[82] Validation loss: 0.0945558840\n",
      "[83] Train loss: 0.0045424154\n",
      "[83] Validation loss: 0.0947077071\n",
      "[84] Train loss: 0.0042722348\n",
      "[84] Validation loss: 0.0873509793\n",
      "[85] Train loss: 0.0037694555\n",
      "[85] Validation loss: 0.0863251592\n",
      "[86] Train loss: 0.0035252798\n",
      "[86] Validation loss: 0.0854976134\n",
      "[87] Train loss: 0.0036691082\n",
      "[87] Validation loss: 0.0879140902\n",
      "[88] Train loss: 0.0041295279\n",
      "[88] Validation loss: 0.0885918626\n",
      "[89] Train loss: 0.0056911431\n",
      "[89] Validation loss: 0.0881988155\n",
      "[90] Train loss: 0.0050267638\n",
      "[90] Validation loss: 0.0875923263\n",
      "[91] Train loss: 0.0054398118\n",
      "[91] Validation loss: 0.0912977994\n",
      "[92] Train loss: 0.0059114037\n",
      "[92] Validation loss: 0.1005339334\n",
      "[93] Train loss: 0.0061778720\n",
      "[93] Validation loss: 0.1093129397\n",
      "[94] Train loss: 0.0068146185\n",
      "[94] Validation loss: 0.1044613069\n",
      "[95] Train loss: 0.0057155868\n",
      "[95] Validation loss: 0.0960842584\n",
      "[96] Train loss: 0.0036450702\n",
      "[96] Validation loss: 0.0887483891\n",
      "[97] Train loss: 0.0029024878\n",
      "[97] Validation loss: 0.0845389352\n",
      "[98] Train loss: 0.0031138108\n",
      "[98] Validation loss: 0.0836783514\n",
      "[99] Train loss: 0.0025509231\n",
      "[99] Validation loss: 0.0835289785\n",
      "[100] Train loss: 0.0025037981\n",
      "[100] Validation loss: 0.0860550189\n",
      "[101] Train loss: 0.0031981654\n",
      "[101] Validation loss: 0.0863228225\n",
      "[102] Train loss: 0.0034215217\n",
      "[102] Validation loss: 0.0884450866\n",
      "[103] Train loss: 0.0034342618\n",
      "[103] Validation loss: 0.0978492899\n",
      "[104] Train loss: 0.0042959511\n",
      "[104] Validation loss: 0.1034903263\n",
      "[105] Train loss: 0.0050017516\n",
      "[105] Validation loss: 0.1050510537\n",
      "[106] Train loss: 0.0047068625\n",
      "[106] Validation loss: 0.0973532465\n",
      "[107] Train loss: 0.0039986752\n",
      "[107] Validation loss: 0.0874351160\n",
      "[108] Train loss: 0.0040251029\n",
      "[108] Validation loss: 0.0856095569\n",
      "[109] Train loss: 0.0033569547\n",
      "[109] Validation loss: 0.0857941196\n",
      "[110] Train loss: 0.0033460207\n",
      "[110] Validation loss: 0.0857884829\n",
      "[111] Train loss: 0.0030471326\n",
      "[111] Validation loss: 0.0869232120\n",
      "[112] Train loss: 0.0028286084\n",
      "[112] Validation loss: 0.0930610970\n",
      "[113] Train loss: 0.0026348534\n",
      "[113] Validation loss: 0.0957734405\n",
      "[114] Train loss: 0.0027556785\n",
      "[114] Validation loss: 0.1043637106\n",
      "[115] Train loss: 0.0034955522\n",
      "[115] Validation loss: 0.0969493122\n",
      "[116] Train loss: 0.0031830003\n",
      "[116] Validation loss: 0.0943355073\n",
      "[117] Train loss: 0.0027601181\n",
      "[117] Validation loss: 0.0874073920\n",
      "[118] Train loss: 0.0027792700\n",
      "[118] Validation loss: 0.0868798518\n",
      "[119] Train loss: 0.0022398875\n",
      "[119] Validation loss: 0.0870180972\n",
      "[120] Train loss: 0.0023595912\n",
      "[120] Validation loss: 0.0870361830\n",
      "[121] Train loss: 0.0028419506\n",
      "[121] Validation loss: 0.0881782051\n",
      "[122] Train loss: 0.0025892977\n",
      "[122] Validation loss: 0.0915513183\n",
      "[123] Train loss: 0.0027031191\n",
      "[123] Validation loss: 0.1001060318\n",
      "[124] Train loss: 0.0036011387\n",
      "[124] Validation loss: 0.1025980484\n",
      "[125] Train loss: 0.0038451857\n",
      "[125] Validation loss: 0.1016484934\n",
      "[126] Train loss: 0.0034762462\n",
      "[126] Validation loss: 0.0907373168\n",
      "[127] Train loss: 0.0031369385\n",
      "[127] Validation loss: 0.0900097861\n",
      "[128] Train loss: 0.0021911867\n",
      "[128] Validation loss: 0.0864460542\n",
      "[129] Train loss: 0.0027233204\n",
      "[129] Validation loss: 0.0884451578\n",
      "[130] Train loss: 0.0025039043\n",
      "[130] Validation loss: 0.0870436399\n",
      "[131] Train loss: 0.0024228166\n",
      "[131] Validation loss: 0.0885713247\n",
      "[132] Train loss: 0.0025832519\n",
      "[132] Validation loss: 0.0929317244\n",
      "[133] Train loss: 0.0036381664\n",
      "[133] Validation loss: 0.0957170632\n",
      "[134] Train loss: 0.0033788271\n",
      "[134] Validation loss: 0.1024410609\n",
      "[135] Train loss: 0.0036254966\n",
      "[135] Validation loss: 0.1016400933\n",
      "[136] Train loss: 0.0037137070\n",
      "[136] Validation loss: 0.0936478347\n",
      "[137] Train loss: 0.0031565165\n",
      "[137] Validation loss: 0.0895899374\n",
      "[138] Train loss: 0.0023359394\n",
      "[138] Validation loss: 0.0847130055\n",
      "[139] Train loss: 0.0020741737\n",
      "[139] Validation loss: 0.0863893140\n",
      "[140] Train loss: 0.0022807529\n",
      "[140] Validation loss: 0.0860701845\n",
      "[141] Train loss: 0.0022515454\n",
      "[141] Validation loss: 0.0890835224\n",
      "[142] Train loss: 0.0023946117\n",
      "[142] Validation loss: 0.0911584435\n",
      "[143] Train loss: 0.0026372637\n",
      "[143] Validation loss: 0.0954102491\n",
      "[144] Train loss: 0.0029232055\n",
      "[144] Validation loss: 0.0988366015\n",
      "[145] Train loss: 0.0030031959\n",
      "[145] Validation loss: 0.1035559617\n",
      "[146] Train loss: 0.0032998399\n",
      "[146] Validation loss: 0.0936448034\n",
      "[147] Train loss: 0.0025174185\n",
      "[147] Validation loss: 0.0894270378\n",
      "[148] Train loss: 0.0021849311\n",
      "[148] Validation loss: 0.0868858605\n",
      "[149] Train loss: 0.0017717693\n",
      "[149] Validation loss: 0.0846107572\n",
      "[150] Train loss: 0.0018690928\n",
      "[150] Validation loss: 0.0859566218\n",
      "[151] Train loss: 0.0019419937\n",
      "[151] Validation loss: 0.0883779963\n",
      "[152] Train loss: 0.0014824968\n",
      "[152] Validation loss: 0.0919225236\n",
      "[153] Train loss: 0.0020077812\n",
      "[153] Validation loss: 0.0954439796\n",
      "[154] Train loss: 0.0020769222\n",
      "[154] Validation loss: 0.1002735645\n",
      "[155] Train loss: 0.0022693447\n",
      "[155] Validation loss: 0.0982010861\n",
      "[156] Train loss: 0.0025446627\n",
      "[156] Validation loss: 0.0924961034\n",
      "[157] Train loss: 0.0024164702\n",
      "[157] Validation loss: 0.0896422331\n",
      "[158] Train loss: 0.0023794630\n",
      "[158] Validation loss: 0.0853568660\n",
      "[159] Train loss: 0.0026472568\n",
      "[159] Validation loss: 0.0862945092\n",
      "[160] Train loss: 0.0027397355\n",
      "[160] Validation loss: 0.0878268780\n",
      "[161] Train loss: 0.0028404436\n",
      "[161] Validation loss: 0.0889346152\n",
      "[162] Train loss: 0.0034091300\n",
      "[162] Validation loss: 0.0889324796\n",
      "[163] Train loss: 0.0040828896\n",
      "[163] Validation loss: 0.0903491063\n",
      "[164] Train loss: 0.0036033961\n",
      "[164] Validation loss: 0.0960144774\n",
      "[165] Train loss: 0.0037632036\n",
      "[165] Validation loss: 0.1006470825\n",
      "[166] Train loss: 0.0042558557\n",
      "[166] Validation loss: 0.0965495483\n",
      "[167] Train loss: 0.0035939275\n",
      "[167] Validation loss: 0.0945902009\n",
      "[168] Train loss: 0.0030050709\n",
      "[168] Validation loss: 0.0861307853\n",
      "[169] Train loss: 0.0023554588\n",
      "[169] Validation loss: 0.0883783326\n",
      "[170] Train loss: 0.0020619621\n",
      "[170] Validation loss: 0.0867495697\n",
      "[171] Train loss: 0.0018811813\n",
      "[171] Validation loss: 0.0870366143\n",
      "[172] Train loss: 0.0018298723\n",
      "[172] Validation loss: 0.0906216086\n",
      "[173] Train loss: 0.0020631069\n",
      "[173] Validation loss: 0.0926387124\n",
      "[174] Train loss: 0.0019438949\n",
      "[174] Validation loss: 0.1005775764\n",
      "[175] Train loss: 0.0022370175\n",
      "[175] Validation loss: 0.0969622293\n",
      "[176] Train loss: 0.0022834187\n",
      "[176] Validation loss: 0.0918624878\n",
      "[177] Train loss: 0.0020879019\n",
      "[177] Validation loss: 0.0897803122\n",
      "[178] Train loss: 0.0018668289\n",
      "[178] Validation loss: 0.0860744742\n",
      "[179] Train loss: 0.0018861672\n",
      "[179] Validation loss: 0.0863891924\n",
      "[180] Train loss: 0.0020336410\n",
      "[180] Validation loss: 0.0866322315\n",
      "[181] Train loss: 0.0021511924\n",
      "[181] Validation loss: 0.0884881583\n",
      "[182] Train loss: 0.0017449410\n",
      "[182] Validation loss: 0.0918336798\n",
      "[183] Train loss: 0.0022554426\n",
      "[183] Validation loss: 0.0941078070\n",
      "[184] Train loss: 0.0024606142\n",
      "[184] Validation loss: 0.1020245915\n",
      "[185] Train loss: 0.0027443821\n",
      "[185] Validation loss: 0.0993840952\n",
      "[186] Train loss: 0.0029414885\n",
      "[186] Validation loss: 0.0917715039\n",
      "[187] Train loss: 0.0028885107\n",
      "[187] Validation loss: 0.0885936311\n",
      "[188] Train loss: 0.0024485444\n",
      "[188] Validation loss: 0.0872335265\n",
      "[189] Train loss: 0.0025336991\n",
      "[189] Validation loss: 0.0883795418\n",
      "[190] Train loss: 0.0023946048\n",
      "[190] Validation loss: 0.0863165545\n",
      "[191] Train loss: 0.0022358081\n",
      "[191] Validation loss: 0.0892719775\n",
      "[192] Train loss: 0.0021645989\n",
      "[192] Validation loss: 0.0928036359\n",
      "[193] Train loss: 0.0027145351\n",
      "[193] Validation loss: 0.0986366059\n",
      "[194] Train loss: 0.0030482560\n",
      "[194] Validation loss: 0.1039444245\n",
      "[195] Train loss: 0.0035539195\n",
      "[195] Validation loss: 0.0997618596\n",
      "[196] Train loss: 0.0032099513\n",
      "[196] Validation loss: 0.0913015246\n",
      "[197] Train loss: 0.0031870709\n",
      "[197] Validation loss: 0.0866707651\n",
      "[198] Train loss: 0.0026085765\n",
      "[198] Validation loss: 0.0864921281\n",
      "[199] Train loss: 0.0029019953\n",
      "[199] Validation loss: 0.0880058673\n",
      "[200] Train loss: 0.0030470519\n",
      "[200] Validation loss: 0.0856348296\n",
      "4 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.1490113486\n",
      "[1] Validation loss: 0.0342084577\n",
      "model saved\n",
      "[2] Train loss: 0.0760724790\n",
      "[2] Validation loss: 0.0365702230\n",
      "[3] Train loss: 0.0450318440\n",
      "[3] Validation loss: 0.0409553124\n",
      "[4] Train loss: 0.0293184370\n",
      "[4] Validation loss: 0.0396792135\n",
      "[5] Train loss: 0.0190422991\n",
      "[5] Validation loss: 0.0346420012\n",
      "[6] Train loss: 0.0120891940\n",
      "[6] Validation loss: 0.0297881189\n",
      "model saved\n",
      "[7] Train loss: 0.0085130244\n",
      "[7] Validation loss: 0.0299822999\n",
      "[8] Train loss: 0.0068619360\n",
      "[8] Validation loss: 0.0318762745\n",
      "[9] Train loss: 0.0050520207\n",
      "[9] Validation loss: 0.0311396707\n",
      "[10] Train loss: 0.0043865474\n",
      "[10] Validation loss: 0.0297651926\n",
      "model saved\n",
      "[11] Train loss: 0.0035986396\n",
      "[11] Validation loss: 0.0291360341\n",
      "model saved\n",
      "[12] Train loss: 0.0024775837\n",
      "[12] Validation loss: 0.0298703402\n",
      "[13] Train loss: 0.0018370854\n",
      "[13] Validation loss: 0.0300569834\n",
      "[14] Train loss: 0.0014471401\n",
      "[14] Validation loss: 0.0294099879\n",
      "[15] Train loss: 0.0012329101\n",
      "[15] Validation loss: 0.0295409385\n",
      "[16] Train loss: 0.0010590140\n",
      "[16] Validation loss: 0.0292509663\n",
      "[17] Train loss: 0.0010540768\n",
      "[17] Validation loss: 0.0294321165\n",
      "[18] Train loss: 0.0010572400\n",
      "[18] Validation loss: 0.0289064320\n",
      "model saved\n",
      "[19] Train loss: 0.0010041919\n",
      "[19] Validation loss: 0.0295796336\n",
      "[20] Train loss: 0.0009419372\n",
      "[20] Validation loss: 0.0293145414\n",
      "[21] Train loss: 0.0010026010\n",
      "[21] Validation loss: 0.0298192208\n",
      "[22] Train loss: 0.0012201904\n",
      "[22] Validation loss: 0.0292823408\n",
      "[23] Train loss: 0.0014605330\n",
      "[23] Validation loss: 0.0301011723\n",
      "[24] Train loss: 0.0019821323\n",
      "[24] Validation loss: 0.0305835138\n",
      "[25] Train loss: 0.0020997116\n",
      "[25] Validation loss: 0.0303874477\n",
      "[26] Train loss: 0.0019951747\n",
      "[26] Validation loss: 0.0302092898\n",
      "[27] Train loss: 0.0020891015\n",
      "[27] Validation loss: 0.0310847679\n",
      "[28] Train loss: 0.0020252159\n",
      "[28] Validation loss: 0.0307271244\n",
      "[29] Train loss: 0.0020999982\n",
      "[29] Validation loss: 0.0317744117\n",
      "[30] Train loss: 0.0019159753\n",
      "[30] Validation loss: 0.0306854910\n",
      "[31] Train loss: 0.0022006614\n",
      "[31] Validation loss: 0.0314404487\n",
      "[32] Train loss: 0.0023523072\n",
      "[32] Validation loss: 0.0303520645\n",
      "[33] Train loss: 0.0023445081\n",
      "[33] Validation loss: 0.0315498910\n",
      "[34] Train loss: 0.0023101525\n",
      "[34] Validation loss: 0.0308884700\n",
      "[35] Train loss: 0.0024562987\n",
      "[35] Validation loss: 0.0323393618\n",
      "[36] Train loss: 0.0031533337\n",
      "[36] Validation loss: 0.0307220913\n",
      "[37] Train loss: 0.0028473172\n",
      "[37] Validation loss: 0.0312649494\n",
      "[38] Train loss: 0.0032736027\n",
      "[38] Validation loss: 0.0312430098\n",
      "[39] Train loss: 0.0030515911\n",
      "[39] Validation loss: 0.0320410986\n",
      "[40] Train loss: 0.0030271987\n",
      "[40] Validation loss: 0.0331505665\n",
      "[41] Train loss: 0.0033684157\n",
      "[41] Validation loss: 0.0335216302\n",
      "[42] Train loss: 0.0033557637\n",
      "[42] Validation loss: 0.0331938899\n",
      "[43] Train loss: 0.0038005766\n",
      "[43] Validation loss: 0.0330078368\n",
      "[44] Train loss: 0.0045440287\n",
      "[44] Validation loss: 0.0315475763\n",
      "[45] Train loss: 0.0046197780\n",
      "[45] Validation loss: 0.0347591906\n",
      "[46] Train loss: 0.0049002657\n",
      "[46] Validation loss: 0.0332060533\n",
      "[47] Train loss: 0.0040869492\n",
      "[47] Validation loss: 0.0322638126\n",
      "[48] Train loss: 0.0042526719\n",
      "[48] Validation loss: 0.0338050973\n",
      "[49] Train loss: 0.0031450187\n",
      "[49] Validation loss: 0.0323631389\n",
      "[50] Train loss: 0.0032427630\n",
      "[50] Validation loss: 0.0326501765\n",
      "[51] Train loss: 0.0030481882\n",
      "[51] Validation loss: 0.0319914268\n",
      "[52] Train loss: 0.0036830702\n",
      "[52] Validation loss: 0.0318494949\n",
      "[53] Train loss: 0.0033078267\n",
      "[53] Validation loss: 0.0323235850\n",
      "[54] Train loss: 0.0028459301\n",
      "[54] Validation loss: 0.0351367116\n",
      "[55] Train loss: 0.0035352427\n",
      "[55] Validation loss: 0.0347929734\n",
      "[56] Train loss: 0.0040856187\n",
      "[56] Validation loss: 0.0331269949\n",
      "[57] Train loss: 0.0042193228\n",
      "[57] Validation loss: 0.0296820975\n",
      "[58] Train loss: 0.0037695631\n",
      "[58] Validation loss: 0.0329747720\n",
      "[59] Train loss: 0.0037141437\n",
      "[59] Validation loss: 0.0362013262\n",
      "[60] Train loss: 0.0037548175\n",
      "[60] Validation loss: 0.0407437263\n",
      "[61] Train loss: 0.0043634006\n",
      "[61] Validation loss: 0.0372922624\n",
      "[62] Train loss: 0.0047643186\n",
      "[62] Validation loss: 0.0333818887\n",
      "[63] Train loss: 0.0047670624\n",
      "[63] Validation loss: 0.0369669822\n",
      "[64] Train loss: 0.0079767334\n",
      "[64] Validation loss: 0.0393201466\n",
      "[65] Train loss: 0.0083868106\n",
      "[65] Validation loss: 0.0358797119\n",
      "[66] Train loss: 0.0073636014\n",
      "[66] Validation loss: 0.0359415599\n",
      "[67] Train loss: 0.0062126692\n",
      "[67] Validation loss: 0.0343215107\n",
      "[68] Train loss: 0.0053420726\n",
      "[68] Validation loss: 0.0330034114\n",
      "[69] Train loss: 0.0048145618\n",
      "[69] Validation loss: 0.0343262485\n",
      "[70] Train loss: 0.0040027699\n",
      "[70] Validation loss: 0.0359754260\n",
      "[71] Train loss: 0.0027567037\n",
      "[71] Validation loss: 0.0366714509\n",
      "[72] Train loss: 0.0032728865\n",
      "[72] Validation loss: 0.0370563667\n",
      "[73] Train loss: 0.0031599900\n",
      "[73] Validation loss: 0.0317984618\n",
      "[74] Train loss: 0.0023516737\n",
      "[74] Validation loss: 0.0325617675\n",
      "[75] Train loss: 0.0021116169\n",
      "[75] Validation loss: 0.0347543420\n",
      "[76] Train loss: 0.0021297056\n",
      "[76] Validation loss: 0.0351336031\n",
      "[77] Train loss: 0.0025251715\n",
      "[77] Validation loss: 0.0342013036\n",
      "[78] Train loss: 0.0024503472\n",
      "[78] Validation loss: 0.0346177355\n",
      "[79] Train loss: 0.0023175379\n",
      "[79] Validation loss: 0.0360565249\n",
      "[80] Train loss: 0.0027717483\n",
      "[80] Validation loss: 0.0343065173\n",
      "[81] Train loss: 0.0027709738\n",
      "[81] Validation loss: 0.0324247972\n",
      "[82] Train loss: 0.0019927678\n",
      "[82] Validation loss: 0.0336341286\n",
      "[83] Train loss: 0.0024034309\n",
      "[83] Validation loss: 0.0342467039\n",
      "[84] Train loss: 0.0028964586\n",
      "[84] Validation loss: 0.0350289198\n",
      "[85] Train loss: 0.0027164454\n",
      "[85] Validation loss: 0.0341161087\n",
      "[86] Train loss: 0.0025084250\n",
      "[86] Validation loss: 0.0356277387\n",
      "[87] Train loss: 0.0035494173\n",
      "[87] Validation loss: 0.0371219819\n",
      "[88] Train loss: 0.0035940812\n",
      "[88] Validation loss: 0.0337822305\n",
      "[89] Train loss: 0.0033431374\n",
      "[89] Validation loss: 0.0325799691\n",
      "[90] Train loss: 0.0032343619\n",
      "[90] Validation loss: 0.0343234684\n",
      "[91] Train loss: 0.0031757937\n",
      "[91] Validation loss: 0.0364327974\n",
      "[92] Train loss: 0.0037449206\n",
      "[92] Validation loss: 0.0357792805\n",
      "[93] Train loss: 0.0038609900\n",
      "[93] Validation loss: 0.0362035875\n",
      "[94] Train loss: 0.0030104047\n",
      "[94] Validation loss: 0.0374761506\n",
      "[95] Train loss: 0.0037576211\n",
      "[95] Validation loss: 0.0368531342\n",
      "[96] Train loss: 0.0042056770\n",
      "[96] Validation loss: 0.0349767616\n",
      "[97] Train loss: 0.0037991672\n",
      "[97] Validation loss: 0.0323248540\n",
      "[98] Train loss: 0.0032548170\n",
      "[98] Validation loss: 0.0348952590\n",
      "[99] Train loss: 0.0036023117\n",
      "[99] Validation loss: 0.0370520144\n",
      "[100] Train loss: 0.0037941917\n",
      "[100] Validation loss: 0.0356245166\n",
      "[101] Train loss: 0.0037163535\n",
      "[101] Validation loss: 0.0367603101\n",
      "[102] Train loss: 0.0038651572\n",
      "[102] Validation loss: 0.0384595239\n",
      "[103] Train loss: 0.0049474767\n",
      "[103] Validation loss: 0.0368826381\n",
      "[104] Train loss: 0.0045475765\n",
      "[104] Validation loss: 0.0330404408\n",
      "[105] Train loss: 0.0033830146\n",
      "[105] Validation loss: 0.0354621678\n",
      "[106] Train loss: 0.0030953096\n",
      "[106] Validation loss: 0.0364921989\n",
      "[107] Train loss: 0.0034555419\n",
      "[107] Validation loss: 0.0370247429\n",
      "[108] Train loss: 0.0041733381\n",
      "[108] Validation loss: 0.0374350814\n",
      "[109] Train loss: 0.0040960254\n",
      "[109] Validation loss: 0.0406600943\n",
      "[110] Train loss: 0.0049718274\n",
      "[110] Validation loss: 0.0403451451\n",
      "[111] Train loss: 0.0049722860\n",
      "[111] Validation loss: 0.0349281472\n",
      "[112] Train loss: 0.0032926389\n",
      "[112] Validation loss: 0.0358703712\n",
      "[113] Train loss: 0.0030504568\n",
      "[113] Validation loss: 0.0364172603\n",
      "[114] Train loss: 0.0032126185\n",
      "[114] Validation loss: 0.0378832912\n",
      "[115] Train loss: 0.0033033392\n",
      "[115] Validation loss: 0.0385911798\n",
      "[116] Train loss: 0.0033519237\n",
      "[116] Validation loss: 0.0409130266\n",
      "[117] Train loss: 0.0038690361\n",
      "[117] Validation loss: 0.0383903060\n",
      "[118] Train loss: 0.0038944752\n",
      "[118] Validation loss: 0.0342977660\n",
      "[119] Train loss: 0.0026723242\n",
      "[119] Validation loss: 0.0357353371\n",
      "[120] Train loss: 0.0028677022\n",
      "[120] Validation loss: 0.0368377397\n",
      "[121] Train loss: 0.0027108262\n",
      "[121] Validation loss: 0.0377741390\n",
      "[122] Train loss: 0.0029284372\n",
      "[122] Validation loss: 0.0392450836\n",
      "[123] Train loss: 0.0029700592\n",
      "[123] Validation loss: 0.0402630723\n",
      "[124] Train loss: 0.0032694496\n",
      "[124] Validation loss: 0.0368623653\n",
      "[125] Train loss: 0.0027524971\n",
      "[125] Validation loss: 0.0349044615\n",
      "[126] Train loss: 0.0022237544\n",
      "[126] Validation loss: 0.0359741955\n",
      "[127] Train loss: 0.0023349050\n",
      "[127] Validation loss: 0.0374990293\n",
      "[128] Train loss: 0.0024020582\n",
      "[128] Validation loss: 0.0385284441\n",
      "[129] Train loss: 0.0027789040\n",
      "[129] Validation loss: 0.0394489310\n",
      "[130] Train loss: 0.0027723182\n",
      "[130] Validation loss: 0.0395576148\n",
      "[131] Train loss: 0.0031555469\n",
      "[131] Validation loss: 0.0360432923\n",
      "[132] Train loss: 0.0021835006\n",
      "[132] Validation loss: 0.0347761522\n",
      "[133] Train loss: 0.0021508002\n",
      "[133] Validation loss: 0.0378156548\n",
      "[134] Train loss: 0.0023179068\n",
      "[134] Validation loss: 0.0380443242\n",
      "[135] Train loss: 0.0025925267\n",
      "[135] Validation loss: 0.0392249100\n",
      "[136] Train loss: 0.0025651849\n",
      "[136] Validation loss: 0.0390495570\n",
      "[137] Train loss: 0.0028253699\n",
      "[137] Validation loss: 0.0394207414\n",
      "[138] Train loss: 0.0032897847\n",
      "[138] Validation loss: 0.0367466733\n",
      "[139] Train loss: 0.0029928572\n",
      "[139] Validation loss: 0.0354725359\n",
      "[140] Train loss: 0.0026547794\n",
      "[140] Validation loss: 0.0368737814\n",
      "[141] Train loss: 0.0026494369\n",
      "[141] Validation loss: 0.0380675278\n",
      "[142] Train loss: 0.0031771158\n",
      "[142] Validation loss: 0.0395588108\n",
      "[143] Train loss: 0.0029679844\n",
      "[143] Validation loss: 0.0402387653\n",
      "[144] Train loss: 0.0027981685\n",
      "[144] Validation loss: 0.0405508679\n",
      "[145] Train loss: 0.0036335075\n",
      "[145] Validation loss: 0.0375339477\n",
      "[146] Train loss: 0.0030814481\n",
      "[146] Validation loss: 0.0372132700\n",
      "[147] Train loss: 0.0028464806\n",
      "[147] Validation loss: 0.0369187601\n",
      "[148] Train loss: 0.0026559402\n",
      "[148] Validation loss: 0.0382683962\n",
      "[149] Train loss: 0.0035144645\n",
      "[149] Validation loss: 0.0399891565\n",
      "[150] Train loss: 0.0041058498\n",
      "[150] Validation loss: 0.0398889194\n",
      "[151] Train loss: 0.0029537159\n",
      "[151] Validation loss: 0.0406642400\n",
      "[152] Train loss: 0.0034014767\n",
      "[152] Validation loss: 0.0391751978\n",
      "[153] Train loss: 0.0034337642\n",
      "[153] Validation loss: 0.0366035803\n",
      "[154] Train loss: 0.0024429469\n",
      "[154] Validation loss: 0.0376406607\n",
      "[155] Train loss: 0.0022829953\n",
      "[155] Validation loss: 0.0390670760\n",
      "[156] Train loss: 0.0025785720\n",
      "[156] Validation loss: 0.0401760187\n",
      "[157] Train loss: 0.0018483544\n",
      "[157] Validation loss: 0.0413081445\n",
      "[158] Train loss: 0.0022832200\n",
      "[158] Validation loss: 0.0413897569\n",
      "[159] Train loss: 0.0026354296\n",
      "[159] Validation loss: 0.0395117947\n",
      "[160] Train loss: 0.0023092265\n",
      "[160] Validation loss: 0.0370024382\n",
      "[161] Train loss: 0.0019644008\n",
      "[161] Validation loss: 0.0379477506\n",
      "[162] Train loss: 0.0018940084\n",
      "[162] Validation loss: 0.0396646454\n",
      "[163] Train loss: 0.0019961792\n",
      "[163] Validation loss: 0.0402120220\n",
      "[164] Train loss: 0.0018861447\n",
      "[164] Validation loss: 0.0413558969\n",
      "[165] Train loss: 0.0021138743\n",
      "[165] Validation loss: 0.0420826879\n",
      "[166] Train loss: 0.0024529620\n",
      "[166] Validation loss: 0.0395213337\n",
      "[167] Train loss: 0.0024234094\n",
      "[167] Validation loss: 0.0369612443\n",
      "[168] Train loss: 0.0021745063\n",
      "[168] Validation loss: 0.0383622983\n",
      "[169] Train loss: 0.0020905615\n",
      "[169] Validation loss: 0.0396811628\n",
      "[170] Train loss: 0.0021490658\n",
      "[170] Validation loss: 0.0404271981\n",
      "[171] Train loss: 0.0024130517\n",
      "[171] Validation loss: 0.0409442139\n",
      "[172] Train loss: 0.0028528515\n",
      "[172] Validation loss: 0.0425160587\n",
      "[173] Train loss: 0.0029135430\n",
      "[173] Validation loss: 0.0407820202\n",
      "[174] Train loss: 0.0031628722\n",
      "[174] Validation loss: 0.0370553155\n",
      "[175] Train loss: 0.0025374716\n",
      "[175] Validation loss: 0.0370604512\n",
      "[176] Train loss: 0.0024746487\n",
      "[176] Validation loss: 0.0397738236\n",
      "[177] Train loss: 0.0026012110\n",
      "[177] Validation loss: 0.0399806693\n",
      "[178] Train loss: 0.0026938786\n",
      "[178] Validation loss: 0.0424254551\n",
      "[179] Train loss: 0.0033338037\n",
      "[179] Validation loss: 0.0427360075\n",
      "[180] Train loss: 0.0033151341\n",
      "[180] Validation loss: 0.0416659314\n",
      "[181] Train loss: 0.0035513055\n",
      "[181] Validation loss: 0.0383839849\n",
      "[182] Train loss: 0.0031499759\n",
      "[182] Validation loss: 0.0365383334\n",
      "[183] Train loss: 0.0028623806\n",
      "[183] Validation loss: 0.0390277076\n",
      "[184] Train loss: 0.0033351083\n",
      "[184] Validation loss: 0.0407434870\n",
      "[185] Train loss: 0.0039247478\n",
      "[185] Validation loss: 0.0421956361\n",
      "[186] Train loss: 0.0037445756\n",
      "[186] Validation loss: 0.0414554765\n",
      "[187] Train loss: 0.0036487383\n",
      "[187] Validation loss: 0.0422399564\n",
      "[188] Train loss: 0.0039406908\n",
      "[188] Validation loss: 0.0383715940\n",
      "[189] Train loss: 0.0026078810\n",
      "[189] Validation loss: 0.0371033030\n",
      "[190] Train loss: 0.0022860212\n",
      "[190] Validation loss: 0.0398164624\n",
      "[191] Train loss: 0.0024340871\n",
      "[191] Validation loss: 0.0409255767\n",
      "[192] Train loss: 0.0018536779\n",
      "[192] Validation loss: 0.0418169202\n",
      "[193] Train loss: 0.0019073478\n",
      "[193] Validation loss: 0.0425533491\n",
      "[194] Train loss: 0.0023332364\n",
      "[194] Validation loss: 0.0411430640\n",
      "[195] Train loss: 0.0021112141\n",
      "[195] Validation loss: 0.0380556029\n",
      "[196] Train loss: 0.0018913935\n",
      "[196] Validation loss: 0.0377043436\n",
      "[197] Train loss: 0.0016321704\n",
      "[197] Validation loss: 0.0389560488\n",
      "[198] Train loss: 0.0016434885\n",
      "[198] Validation loss: 0.0402678791\n",
      "[199] Train loss: 0.0021332490\n",
      "[199] Validation loss: 0.0422447905\n",
      "[200] Train loss: 0.0018479306\n",
      "[200] Validation loss: 0.0429196378\n",
      "5 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=41)\n",
    "model = Regressor()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=1e-7)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "\n",
    "    trainsets = TensorData(X_train, Y_train)\n",
    "    valsets = TensorData(X_val, Y_val)\n",
    "\n",
    "    trainloader = DataLoader(trainsets, batch_size=CFG[\"BATCH_SIZE\"])\n",
    "    valloader = DataLoader(valsets, batch_size=CFG[\"BATCH_SIZE\"])\n",
    "\n",
    "    train(model, optimizer, trainloader, valloader)\n",
    "\n",
    "    n_iter += 1\n",
    "    torch.save(model.state_dict(), dirpath + \"best_model/\" + str(n_iter) +\"last_model.pth\")\n",
    "    print('{} 번째, 학습데이터 크기 : {}, 검증데이터 크기 : {}'.format(n_iter, X_train.shape[0], X_val.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 6400x4800 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "plt.clf()\n",
    "# plt.plot(loss_,'ro',label='training loss')\n",
    "plt.plot(val_loss_,'g',label='validation loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}