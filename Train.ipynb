{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This is file for train, prediction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dirpath = 'C:/Python/Used-Car-Price-Regression-DACON/'\n",
    "\n",
    "train = pd.read_csv('data/modified_train.csv')\n",
    "test = pd.read_csv('data/modified_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   title  odometer  location  isimported  engine  transmission  fuel  paint  \\\n0    147     18277         0           0       3             0     0      0   \n1     93        10         0           2       3             0     0     10   \n2     55     83091         0           0       4             0     0      0   \n3    122     91524         0           0       3             0     0      6   \n4    116     94177         0           0       4             0     0      0   \n\n   year  brand    target  \n0  2016     36  13665000  \n1  2019     36  33015000  \n2  2012     31   9915000  \n3  2007      6   3815000  \n4  2010     36   7385000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>odometer</th>\n      <th>location</th>\n      <th>isimported</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>paint</th>\n      <th>year</th>\n      <th>brand</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>147</td>\n      <td>18277</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>36</td>\n      <td>13665000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>36</td>\n      <td>33015000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>83091</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2012</td>\n      <td>31</td>\n      <td>9915000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>122</td>\n      <td>91524</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>6</td>\n      <td>3815000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>94177</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010</td>\n      <td>36</td>\n      <td>7385000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   title  odometer  location  isimported  engine  transmission  fuel  paint  \\\n0     14      1234         1           2       3             0     0     11   \n1     88     29938         1           0       3             0     0     11   \n2     29     87501         0           0       3             0     0     10   \n3     91    180894         0           1       4             0     0      6   \n4     17    104814         0           0       3             0     0     11   \n\n   year  brand  \n0  2017     34  \n1  2013     14  \n2  2012     34  \n3  2001     36  \n4  2000     36  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>odometer</th>\n      <th>location</th>\n      <th>isimported</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>paint</th>\n      <th>year</th>\n      <th>brand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>1234</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2017</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>88</td>\n      <td>29938</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2013</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>87501</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2012</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>91</td>\n      <td>180894</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2001</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>104814</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2000</td>\n      <td>36</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Y = train[ ['target'] ].values\n",
    "X = train[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((1015, 10), (1015, 1))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "\n",
    "scalerY = MinMaxScaler()\n",
    "scalerY.fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':200,\n",
    "    'BATCH_SIZE':16,\n",
    "    'LEARNING_RATE' :3e-4\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(10, 64, bias=False),\n",
    "            nn.BatchNorm1d(64, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64, 128, bias=False),\n",
    "            nn.BatchNorm1d(128, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 256, bias=False),\n",
    "            nn.BatchNorm1d(256, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Linear(256, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loss_ = [] # loss 저장할 리스트\n",
    "val_loss_ = [] # val loss 저장할 리스트\n",
    "\n",
    "def train(model, optimizer, trainloader, valloader):\n",
    "    best_loss = 1000 # to save best model\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, CFG[\"EPOCHS\"]+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, values = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, values)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss))\n",
    "        loss_.append(running_loss)\n",
    "\n",
    "        #validation set evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서.\n",
    "        actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서.\n",
    "\n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for i, data in enumerate(valloader, 0): # enumerate(인자, index)\n",
    "                inputs, values = data\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, values)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print('[%d] Validation loss: %.10f' %(epoch, val_loss))\n",
    "\n",
    "        if val_loss < best_loss :\n",
    "            torch.save(model.state_dict(), dirpath + \"best_model/\" + \"_best_model.pth\")\n",
    "            best_loss = val_loss\n",
    "            print('model saved')\n",
    "\n",
    "        val_loss_.append(val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 2.1858375948\n",
      "[1] Validation loss: 0.1965110777\n",
      "model saved\n",
      "[2] Train loss: 0.9544692915\n",
      "[2] Validation loss: 0.2199875461\n",
      "[3] Train loss: 0.4433083537\n",
      "[3] Validation loss: 0.1684901617\n",
      "model saved\n",
      "[4] Train loss: 0.3704112247\n",
      "[4] Validation loss: 0.1345394873\n",
      "model saved\n",
      "[5] Train loss: 0.2367011613\n",
      "[5] Validation loss: 0.1426953766\n",
      "[6] Train loss: 0.1940325538\n",
      "[6] Validation loss: 0.1426241691\n",
      "[7] Train loss: 0.1876212067\n",
      "[7] Validation loss: 0.1768968226\n",
      "[8] Train loss: 0.2742535162\n",
      "[8] Validation loss: 0.2337790034\n",
      "[9] Train loss: 0.3820363521\n",
      "[9] Validation loss: 0.2287889356\n",
      "[10] Train loss: 0.4969261736\n",
      "[10] Validation loss: 0.2633638736\n",
      "[11] Train loss: 0.7891421663\n",
      "[11] Validation loss: 0.3426388809\n",
      "[12] Train loss: 0.6029846179\n",
      "[12] Validation loss: 0.2616918441\n",
      "[13] Train loss: 0.5120119490\n",
      "[13] Validation loss: 0.2180970928\n",
      "[14] Train loss: 0.3908123334\n",
      "[14] Validation loss: 0.1578231805\n",
      "[15] Train loss: 0.3527913899\n",
      "[15] Validation loss: 0.1867991453\n",
      "[16] Train loss: 0.3180894562\n",
      "[16] Validation loss: 0.2393249022\n",
      "[17] Train loss: 0.3155494769\n",
      "[17] Validation loss: 0.1456848364\n",
      "[18] Train loss: 0.2745046632\n",
      "[18] Validation loss: 0.1295325538\n",
      "model saved\n",
      "[19] Train loss: 0.2155810964\n",
      "[19] Validation loss: 0.1395938295\n",
      "[20] Train loss: 0.1814325555\n",
      "[20] Validation loss: 0.1133728218\n",
      "model saved\n",
      "[21] Train loss: 0.1040816602\n",
      "[21] Validation loss: 0.1135443321\n",
      "[22] Train loss: 0.0923148298\n",
      "[22] Validation loss: 0.1017468120\n",
      "model saved\n",
      "[23] Train loss: 0.0806824942\n",
      "[23] Validation loss: 0.0840641656\n",
      "model saved\n",
      "[24] Train loss: 0.0657663501\n",
      "[24] Validation loss: 0.0828751329\n",
      "model saved\n",
      "[25] Train loss: 0.0667393063\n",
      "[25] Validation loss: 0.0893133038\n",
      "[26] Train loss: 0.0657817173\n",
      "[26] Validation loss: 0.0971397692\n",
      "[27] Train loss: 0.0658217709\n",
      "[27] Validation loss: 0.1103202282\n",
      "[28] Train loss: 0.0706305135\n",
      "[28] Validation loss: 0.1178540634\n",
      "[29] Train loss: 0.0766065039\n",
      "[29] Validation loss: 0.1159116207\n",
      "[30] Train loss: 0.0839692514\n",
      "[30] Validation loss: 0.1109612593\n",
      "[31] Train loss: 0.0923036415\n",
      "[31] Validation loss: 0.1129419943\n",
      "[32] Train loss: 0.1063920809\n",
      "[32] Validation loss: 0.1142258535\n",
      "[33] Train loss: 0.1187618806\n",
      "[33] Validation loss: 0.1238932924\n",
      "[34] Train loss: 0.1241417999\n",
      "[34] Validation loss: 0.1598966983\n",
      "[35] Train loss: 0.1316002353\n",
      "[35] Validation loss: 0.2104196055\n",
      "[36] Train loss: 0.1469690743\n",
      "[36] Validation loss: 0.2437387169\n",
      "[37] Train loss: 0.1737581831\n",
      "[37] Validation loss: 0.2389971255\n",
      "[38] Train loss: 0.2030226757\n",
      "[38] Validation loss: 0.2115861918\n",
      "[39] Train loss: 0.2399861469\n",
      "[39] Validation loss: 0.1717762745\n",
      "[40] Train loss: 0.2773702270\n",
      "[40] Validation loss: 0.1282091688\n",
      "[41] Train loss: 0.2701867995\n",
      "[41] Validation loss: 0.1074749825\n",
      "[42] Train loss: 0.2649190028\n",
      "[42] Validation loss: 0.1115152864\n",
      "[43] Train loss: 0.2319196719\n",
      "[43] Validation loss: 0.1102246959\n",
      "[44] Train loss: 0.1610183272\n",
      "[44] Validation loss: 0.0948734031\n",
      "[45] Train loss: 0.1121031444\n",
      "[45] Validation loss: 0.0996687432\n",
      "[46] Train loss: 0.0895978904\n",
      "[46] Validation loss: 0.1103566302\n",
      "[47] Train loss: 0.0811914878\n",
      "[47] Validation loss: 0.1118148455\n",
      "[48] Train loss: 0.0766539486\n",
      "[48] Validation loss: 0.1096986969\n",
      "[49] Train loss: 0.0718650705\n",
      "[49] Validation loss: 0.1080837123\n",
      "[50] Train loss: 0.0706812709\n",
      "[50] Validation loss: 0.1039564151\n",
      "[51] Train loss: 0.0689426431\n",
      "[51] Validation loss: 0.1011972891\n",
      "[52] Train loss: 0.0655016908\n",
      "[52] Validation loss: 0.1061216804\n",
      "[53] Train loss: 0.0673982529\n",
      "[53] Validation loss: 0.1031526371\n",
      "[54] Train loss: 0.0675943770\n",
      "[54] Validation loss: 0.0946583829\n",
      "[55] Train loss: 0.0669623209\n",
      "[55] Validation loss: 0.0825666961\n",
      "model saved\n",
      "[56] Train loss: 0.0654933581\n",
      "[56] Validation loss: 0.0760550972\n",
      "model saved\n",
      "[57] Train loss: 0.0705083788\n",
      "[57] Validation loss: 0.0761942135\n",
      "[58] Train loss: 0.0752786800\n",
      "[58] Validation loss: 0.0826402658\n",
      "[59] Train loss: 0.0792608123\n",
      "[59] Validation loss: 0.0949888225\n",
      "[60] Train loss: 0.0805864755\n",
      "[60] Validation loss: 0.1052548282\n",
      "[61] Train loss: 0.0849731374\n",
      "[61] Validation loss: 0.0978132570\n",
      "[62] Train loss: 0.0842934336\n",
      "[62] Validation loss: 0.0784183324\n",
      "[63] Train loss: 0.0854629062\n",
      "[63] Validation loss: 0.0689245756\n",
      "model saved\n",
      "[64] Train loss: 0.0900496275\n",
      "[64] Validation loss: 0.0743649740\n",
      "[65] Train loss: 0.0973261815\n",
      "[65] Validation loss: 0.0799064181\n",
      "[66] Train loss: 0.0991013870\n",
      "[66] Validation loss: 0.0846253172\n",
      "[67] Train loss: 0.0870840307\n",
      "[67] Validation loss: 0.0934307841\n",
      "[68] Train loss: 0.0828496065\n",
      "[68] Validation loss: 0.0865416892\n",
      "[69] Train loss: 0.0796697490\n",
      "[69] Validation loss: 0.0687879128\n",
      "model saved\n",
      "[70] Train loss: 0.0623568877\n",
      "[70] Validation loss: 0.0648772985\n",
      "model saved\n",
      "[71] Train loss: 0.0534967051\n",
      "[71] Validation loss: 0.0680902936\n",
      "[72] Train loss: 0.0573575270\n",
      "[72] Validation loss: 0.0607844333\n",
      "model saved\n",
      "[73] Train loss: 0.0597326989\n",
      "[73] Validation loss: 0.0545433293\n",
      "model saved\n",
      "[74] Train loss: 0.0600235651\n",
      "[74] Validation loss: 0.0578949910\n",
      "[75] Train loss: 0.0679086322\n",
      "[75] Validation loss: 0.0645343618\n",
      "[76] Train loss: 0.0648537122\n",
      "[76] Validation loss: 0.0786233477\n",
      "[77] Train loss: 0.0594793933\n",
      "[77] Validation loss: 0.0810119179\n",
      "[78] Train loss: 0.0605732024\n",
      "[78] Validation loss: 0.0715959568\n",
      "[79] Train loss: 0.0545974376\n",
      "[79] Validation loss: 0.0676013522\n",
      "[80] Train loss: 0.0529316259\n",
      "[80] Validation loss: 0.0700518705\n",
      "[81] Train loss: 0.0558601136\n",
      "[81] Validation loss: 0.0761500987\n",
      "[82] Train loss: 0.0567331637\n",
      "[82] Validation loss: 0.0834046926\n",
      "[83] Train loss: 0.0576838630\n",
      "[83] Validation loss: 0.0849229402\n",
      "[84] Train loss: 0.0685003264\n",
      "[84] Validation loss: 0.0748105700\n",
      "[85] Train loss: 0.0820270651\n",
      "[85] Validation loss: 0.0827763074\n",
      "[86] Train loss: 0.0799704070\n",
      "[86] Validation loss: 0.1174476258\n",
      "[87] Train loss: 0.0962362117\n",
      "[87] Validation loss: 0.1177807644\n",
      "[88] Train loss: 0.1101978861\n",
      "[88] Validation loss: 0.0777381535\n",
      "[89] Train loss: 0.1152813842\n",
      "[89] Validation loss: 0.0746841333\n",
      "[90] Train loss: 0.1246000117\n",
      "[90] Validation loss: 0.0790676783\n",
      "[91] Train loss: 0.0851948705\n",
      "[91] Validation loss: 0.1054244157\n",
      "[92] Train loss: 0.0729654848\n",
      "[92] Validation loss: 0.0943631061\n",
      "[93] Train loss: 0.0646727590\n",
      "[93] Validation loss: 0.0786375434\n",
      "[94] Train loss: 0.0666422467\n",
      "[94] Validation loss: 0.0887890267\n",
      "[95] Train loss: 0.0708475749\n",
      "[95] Validation loss: 0.1221517553\n",
      "[96] Train loss: 0.0573945100\n",
      "[96] Validation loss: 0.1381000523\n",
      "[97] Train loss: 0.0596488049\n",
      "[97] Validation loss: 0.1146273502\n",
      "[98] Train loss: 0.0646946632\n",
      "[98] Validation loss: 0.0945874566\n",
      "[99] Train loss: 0.0736483007\n",
      "[99] Validation loss: 0.0882288238\n",
      "[100] Train loss: 0.0800172999\n",
      "[100] Validation loss: 0.1002770956\n",
      "[101] Train loss: 0.0844695539\n",
      "[101] Validation loss: 0.1040666522\n",
      "[102] Train loss: 0.0925586193\n",
      "[102] Validation loss: 0.0929922515\n",
      "[103] Train loss: 0.0976540008\n",
      "[103] Validation loss: 0.0962516307\n",
      "[104] Train loss: 0.1253164277\n",
      "[104] Validation loss: 0.0942768140\n",
      "[105] Train loss: 0.1176411034\n",
      "[105] Validation loss: 0.0859478002\n",
      "[106] Train loss: 0.1093638252\n",
      "[106] Validation loss: 0.0843925441\n",
      "[107] Train loss: 0.1020590645\n",
      "[107] Validation loss: 0.0931176924\n",
      "[108] Train loss: 0.0995701795\n",
      "[108] Validation loss: 0.0883229653\n",
      "[109] Train loss: 0.0913659522\n",
      "[109] Validation loss: 0.0878003098\n",
      "[110] Train loss: 0.0825892111\n",
      "[110] Validation loss: 0.0982252116\n",
      "[111] Train loss: 0.0806893494\n",
      "[111] Validation loss: 0.1040120275\n",
      "[112] Train loss: 0.0812123636\n",
      "[112] Validation loss: 0.0954740966\n",
      "[113] Train loss: 0.0746907559\n",
      "[113] Validation loss: 0.0908769101\n",
      "[114] Train loss: 0.0697998098\n",
      "[114] Validation loss: 0.0950506373\n",
      "[115] Train loss: 0.0669857248\n",
      "[115] Validation loss: 0.0919018025\n",
      "[116] Train loss: 0.0660351008\n",
      "[116] Validation loss: 0.0875934276\n",
      "[117] Train loss: 0.0616594311\n",
      "[117] Validation loss: 0.0883999022\n",
      "[118] Train loss: 0.0584005458\n",
      "[118] Validation loss: 0.0940400795\n",
      "[119] Train loss: 0.0603115338\n",
      "[119] Validation loss: 0.1021583265\n",
      "[120] Train loss: 0.0611222177\n",
      "[120] Validation loss: 0.1086210160\n",
      "[121] Train loss: 0.0648869078\n",
      "[121] Validation loss: 0.1083077828\n",
      "[122] Train loss: 0.0668989540\n",
      "[122] Validation loss: 0.1024148556\n",
      "[123] Train loss: 0.0692459500\n",
      "[123] Validation loss: 0.0949586987\n",
      "[124] Train loss: 0.0676583050\n",
      "[124] Validation loss: 0.0923858255\n",
      "[125] Train loss: 0.0624135081\n",
      "[125] Validation loss: 0.0941769884\n",
      "[126] Train loss: 0.0588673043\n",
      "[126] Validation loss: 0.0995208097\n",
      "[127] Train loss: 0.0566208669\n",
      "[127] Validation loss: 0.1063691927\n",
      "[128] Train loss: 0.0568274462\n",
      "[128] Validation loss: 0.1136419023\n",
      "[129] Train loss: 0.0589882383\n",
      "[129] Validation loss: 0.1177848289\n",
      "[130] Train loss: 0.0640158683\n",
      "[130] Validation loss: 0.1206204128\n",
      "[131] Train loss: 0.0719298422\n",
      "[131] Validation loss: 0.1084432472\n",
      "[132] Train loss: 0.0846757980\n",
      "[132] Validation loss: 0.0956256662\n",
      "[133] Train loss: 0.0942027872\n",
      "[133] Validation loss: 0.0823331085\n",
      "[134] Train loss: 0.1057330057\n",
      "[134] Validation loss: 0.0753014614\n",
      "[135] Train loss: 0.1206216773\n",
      "[135] Validation loss: 0.0744623891\n",
      "[136] Train loss: 0.1402753397\n",
      "[136] Validation loss: 0.0740591407\n",
      "[137] Train loss: 0.1737005944\n",
      "[137] Validation loss: 0.1103802907\n",
      "[138] Train loss: 0.1898402268\n",
      "[138] Validation loss: 0.1674160897\n",
      "[139] Train loss: 0.2164904641\n",
      "[139] Validation loss: 0.1269345612\n",
      "[140] Train loss: 0.1759242138\n",
      "[140] Validation loss: 0.0973827664\n",
      "[141] Train loss: 0.1237408526\n",
      "[141] Validation loss: 0.0926431942\n",
      "[142] Train loss: 0.0822429658\n",
      "[142] Validation loss: 0.0906779677\n",
      "[143] Train loss: 0.0740926755\n",
      "[143] Validation loss: 0.0717474266\n",
      "[144] Train loss: 0.0635874984\n",
      "[144] Validation loss: 0.0640643244\n",
      "[145] Train loss: 0.0485068461\n",
      "[145] Validation loss: 0.0627421504\n",
      "[146] Train loss: 0.0376298623\n",
      "[146] Validation loss: 0.0608548448\n",
      "[147] Train loss: 0.0310048232\n",
      "[147] Validation loss: 0.0609671445\n",
      "[148] Train loss: 0.0262822183\n",
      "[148] Validation loss: 0.0616042184\n",
      "[149] Train loss: 0.0227550493\n",
      "[149] Validation loss: 0.0623237998\n",
      "[150] Train loss: 0.0207573572\n",
      "[150] Validation loss: 0.0623944453\n",
      "[151] Train loss: 0.0188919610\n",
      "[151] Validation loss: 0.0625282002\n",
      "[152] Train loss: 0.0183360933\n",
      "[152] Validation loss: 0.0628570202\n",
      "[153] Train loss: 0.0186366946\n",
      "[153] Validation loss: 0.0624663000\n",
      "[154] Train loss: 0.0188427077\n",
      "[154] Validation loss: 0.0640499191\n",
      "[155] Train loss: 0.0190054263\n",
      "[155] Validation loss: 0.0669692933\n",
      "[156] Train loss: 0.0190528435\n",
      "[156] Validation loss: 0.0696616729\n",
      "[157] Train loss: 0.0198667729\n",
      "[157] Validation loss: 0.0715334073\n",
      "[158] Train loss: 0.0215557538\n",
      "[158] Validation loss: 0.0726401809\n",
      "[159] Train loss: 0.0239538146\n",
      "[159] Validation loss: 0.0719377745\n",
      "[160] Train loss: 0.0264681539\n",
      "[160] Validation loss: 0.0697615962\n",
      "[161] Train loss: 0.0296036204\n",
      "[161] Validation loss: 0.0675891060\n",
      "[162] Train loss: 0.0318923420\n",
      "[162] Validation loss: 0.0668586240\n",
      "[163] Train loss: 0.0339171985\n",
      "[163] Validation loss: 0.0698308708\n",
      "[164] Train loss: 0.0354417020\n",
      "[164] Validation loss: 0.0766330038\n",
      "[165] Train loss: 0.0395127306\n",
      "[165] Validation loss: 0.0832076599\n",
      "[166] Train loss: 0.0448198841\n",
      "[166] Validation loss: 0.0881226477\n",
      "[167] Train loss: 0.0521801686\n",
      "[167] Validation loss: 0.0797869453\n",
      "[168] Train loss: 0.0552318502\n",
      "[168] Validation loss: 0.0728059406\n",
      "[169] Train loss: 0.0512397483\n",
      "[169] Validation loss: 0.0719782974\n",
      "[170] Train loss: 0.0514987474\n",
      "[170] Validation loss: 0.0683402143\n",
      "[171] Train loss: 0.0470659503\n",
      "[171] Validation loss: 0.0788152872\n",
      "[172] Train loss: 0.0435886736\n",
      "[172] Validation loss: 0.0841274570\n",
      "[173] Train loss: 0.0409144639\n",
      "[173] Validation loss: 0.0816400901\n",
      "[174] Train loss: 0.0344962774\n",
      "[174] Validation loss: 0.0862778806\n",
      "[175] Train loss: 0.0325702106\n",
      "[175] Validation loss: 0.0830659425\n",
      "[176] Train loss: 0.0321352551\n",
      "[176] Validation loss: 0.0793852303\n",
      "[177] Train loss: 0.0357555149\n",
      "[177] Validation loss: 0.0870383825\n",
      "[178] Train loss: 0.0389757152\n",
      "[178] Validation loss: 0.0927354749\n",
      "[179] Train loss: 0.0412605744\n",
      "[179] Validation loss: 0.0844524080\n",
      "[180] Train loss: 0.0454834181\n",
      "[180] Validation loss: 0.0742279303\n",
      "[181] Train loss: 0.0465983295\n",
      "[181] Validation loss: 0.0756562109\n",
      "[182] Train loss: 0.0450743487\n",
      "[182] Validation loss: 0.0819426373\n",
      "[183] Train loss: 0.0467117979\n",
      "[183] Validation loss: 0.0854946484\n",
      "[184] Train loss: 0.0537227442\n",
      "[184] Validation loss: 0.0774537850\n",
      "[185] Train loss: 0.0563632784\n",
      "[185] Validation loss: 0.0701217027\n",
      "[186] Train loss: 0.0578907994\n",
      "[186] Validation loss: 0.0638884781\n",
      "[187] Train loss: 0.0559317062\n",
      "[187] Validation loss: 0.0614999915\n",
      "[188] Train loss: 0.0487674295\n",
      "[188] Validation loss: 0.0619969878\n",
      "[189] Train loss: 0.0446624405\n",
      "[189] Validation loss: 0.0584278010\n",
      "[190] Train loss: 0.0435284864\n",
      "[190] Validation loss: 0.0576794749\n",
      "[191] Train loss: 0.0405067493\n",
      "[191] Validation loss: 0.0597626003\n",
      "[192] Train loss: 0.0380525932\n",
      "[192] Validation loss: 0.0677220186\n",
      "[193] Train loss: 0.0394657733\n",
      "[193] Validation loss: 0.0882306342\n",
      "[194] Train loss: 0.0392084526\n",
      "[194] Validation loss: 0.0983075469\n",
      "[195] Train loss: 0.0356091096\n",
      "[195] Validation loss: 0.0927240745\n",
      "[196] Train loss: 0.0339594207\n",
      "[196] Validation loss: 0.0836002636\n",
      "[197] Train loss: 0.0347232604\n",
      "[197] Validation loss: 0.0745204777\n",
      "[198] Train loss: 0.0360110983\n",
      "[198] Validation loss: 0.0700766555\n",
      "[199] Train loss: 0.0383690021\n",
      "[199] Validation loss: 0.0662133861\n",
      "[200] Train loss: 0.0431283212\n",
      "[200] Validation loss: 0.0611885769\n",
      "1 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 2.6387437955\n",
      "[1] Validation loss: 0.3146795910\n",
      "model saved\n",
      "[2] Train loss: 0.7672804398\n",
      "[2] Validation loss: 0.2103026747\n",
      "model saved\n",
      "[3] Train loss: 0.4529821018\n",
      "[3] Validation loss: 0.2670361269\n",
      "[4] Train loss: 0.3133494332\n",
      "[4] Validation loss: 0.1716143875\n",
      "model saved\n",
      "[5] Train loss: 0.2484808692\n",
      "[5] Validation loss: 0.1442539007\n",
      "model saved\n",
      "[6] Train loss: 0.2016473296\n",
      "[6] Validation loss: 0.2229559347\n",
      "[7] Train loss: 0.2122027551\n",
      "[7] Validation loss: 0.5108519988\n",
      "[8] Train loss: 0.3055650531\n",
      "[8] Validation loss: 0.7281442676\n",
      "[9] Train loss: 0.3506276980\n",
      "[9] Validation loss: 0.5881121662\n",
      "[10] Train loss: 0.5040496725\n",
      "[10] Validation loss: 0.2289315416\n",
      "[11] Train loss: 0.5645396025\n",
      "[11] Validation loss: 0.2575440034\n",
      "[12] Train loss: 0.5810893560\n",
      "[12] Validation loss: 0.2667421848\n",
      "[13] Train loss: 0.5513197717\n",
      "[13] Validation loss: 0.3323234739\n",
      "[14] Train loss: 0.4725307147\n",
      "[14] Validation loss: 0.3680183673\n",
      "[15] Train loss: 0.4606857719\n",
      "[15] Validation loss: 0.4143391456\n",
      "[16] Train loss: 0.5425423749\n",
      "[16] Validation loss: 0.1948418072\n",
      "[17] Train loss: 0.4520487771\n",
      "[17] Validation loss: 0.1881710235\n",
      "[18] Train loss: 0.3616363842\n",
      "[18] Validation loss: 0.1440094220\n",
      "model saved\n",
      "[19] Train loss: 0.2544365084\n",
      "[19] Validation loss: 0.1085033037\n",
      "model saved\n",
      "[20] Train loss: 0.1654146621\n",
      "[20] Validation loss: 0.1010857143\n",
      "model saved\n",
      "[21] Train loss: 0.1203452802\n",
      "[21] Validation loss: 0.1050184334\n",
      "[22] Train loss: 0.0974998178\n",
      "[22] Validation loss: 0.1059661666\n",
      "[23] Train loss: 0.0821136679\n",
      "[23] Validation loss: 0.1006096432\n",
      "model saved\n",
      "[24] Train loss: 0.0714216586\n",
      "[24] Validation loss: 0.0967311079\n",
      "model saved\n",
      "[25] Train loss: 0.0642154624\n",
      "[25] Validation loss: 0.0998457405\n",
      "[26] Train loss: 0.0589251833\n",
      "[26] Validation loss: 0.1104988696\n",
      "[27] Train loss: 0.0554694153\n",
      "[27] Validation loss: 0.1205371493\n",
      "[28] Train loss: 0.0543596395\n",
      "[28] Validation loss: 0.1221025682\n",
      "[29] Train loss: 0.0561584950\n",
      "[29] Validation loss: 0.1131849638\n",
      "[30] Train loss: 0.0620420975\n",
      "[30] Validation loss: 0.1067482671\n",
      "[31] Train loss: 0.0713211886\n",
      "[31] Validation loss: 0.1051769510\n",
      "[32] Train loss: 0.0801183577\n",
      "[32] Validation loss: 0.1111168964\n",
      "[33] Train loss: 0.0885181807\n",
      "[33] Validation loss: 0.1125698593\n",
      "[34] Train loss: 0.0941561807\n",
      "[34] Validation loss: 0.1063151648\n",
      "[35] Train loss: 0.1049653278\n",
      "[35] Validation loss: 0.1116676987\n",
      "[36] Train loss: 0.1303369878\n",
      "[36] Validation loss: 0.1595445247\n",
      "[37] Train loss: 0.1625962178\n",
      "[37] Validation loss: 0.2208572859\n",
      "[38] Train loss: 0.1858019251\n",
      "[38] Validation loss: 0.2339720698\n",
      "[39] Train loss: 0.2053010059\n",
      "[39] Validation loss: 0.1722699858\n",
      "[40] Train loss: 0.2354756624\n",
      "[40] Validation loss: 0.1094248975\n",
      "[41] Train loss: 0.2444849527\n",
      "[41] Validation loss: 0.1011519874\n",
      "[42] Train loss: 0.2074419928\n",
      "[42] Validation loss: 0.0976091218\n",
      "[43] Train loss: 0.1533266669\n",
      "[43] Validation loss: 0.1640158147\n",
      "[44] Train loss: 0.1337282890\n",
      "[44] Validation loss: 0.2362909019\n",
      "[45] Train loss: 0.1181208530\n",
      "[45] Validation loss: 0.1651205327\n",
      "[46] Train loss: 0.1096850799\n",
      "[46] Validation loss: 0.0926196468\n",
      "model saved\n",
      "[47] Train loss: 0.1138201925\n",
      "[47] Validation loss: 0.0656220650\n",
      "model saved\n",
      "[48] Train loss: 0.1064139840\n",
      "[48] Validation loss: 0.0755900292\n",
      "[49] Train loss: 0.0954235812\n",
      "[49] Validation loss: 0.0998539636\n",
      "[50] Train loss: 0.0844597520\n",
      "[50] Validation loss: 0.1239919753\n",
      "[51] Train loss: 0.0718963693\n",
      "[51] Validation loss: 0.1342471347\n",
      "[52] Train loss: 0.0657894658\n",
      "[52] Validation loss: 0.1163237600\n",
      "[53] Train loss: 0.0666517130\n",
      "[53] Validation loss: 0.0876049746\n",
      "[54] Train loss: 0.0658728622\n",
      "[54] Validation loss: 0.0806128946\n",
      "[55] Train loss: 0.0616433682\n",
      "[55] Validation loss: 0.0788446950\n",
      "[56] Train loss: 0.0730340067\n",
      "[56] Validation loss: 0.0693516796\n",
      "[57] Train loss: 0.0855730470\n",
      "[57] Validation loss: 0.0764243450\n",
      "[58] Train loss: 0.0845484103\n",
      "[58] Validation loss: 0.0975538457\n",
      "[59] Train loss: 0.0811093700\n",
      "[59] Validation loss: 0.0870422733\n",
      "[60] Train loss: 0.0875670665\n",
      "[60] Validation loss: 0.1492445301\n",
      "[61] Train loss: 0.0970849774\n",
      "[61] Validation loss: 0.3060580436\n",
      "[62] Train loss: 0.1148962429\n",
      "[62] Validation loss: 0.2065539733\n",
      "[63] Train loss: 0.1326654853\n",
      "[63] Validation loss: 0.0820460888\n",
      "[64] Train loss: 0.1212650144\n",
      "[64] Validation loss: 0.1100144959\n",
      "[65] Train loss: 0.1263713381\n",
      "[65] Validation loss: 0.1103972842\n",
      "[66] Train loss: 0.1012255660\n",
      "[66] Validation loss: 0.2008442767\n",
      "[67] Train loss: 0.0816923201\n",
      "[67] Validation loss: 0.1444073210\n",
      "[68] Train loss: 0.0819007651\n",
      "[68] Validation loss: 0.0776958623\n",
      "[69] Train loss: 0.0827131003\n",
      "[69] Validation loss: 0.0708889591\n",
      "[70] Train loss: 0.0846674796\n",
      "[70] Validation loss: 0.0740947354\n",
      "[71] Train loss: 0.0739199127\n",
      "[71] Validation loss: 0.0820557802\n",
      "[72] Train loss: 0.0687272421\n",
      "[72] Validation loss: 0.0646289976\n",
      "model saved\n",
      "[73] Train loss: 0.0641313666\n",
      "[73] Validation loss: 0.0710389968\n",
      "[74] Train loss: 0.0642701480\n",
      "[74] Validation loss: 0.0787321429\n",
      "[75] Train loss: 0.0654663633\n",
      "[75] Validation loss: 0.0760649728\n",
      "[76] Train loss: 0.0638876986\n",
      "[76] Validation loss: 0.0831707641\n",
      "[77] Train loss: 0.0625983663\n",
      "[77] Validation loss: 0.1025201990\n",
      "[78] Train loss: 0.0610214593\n",
      "[78] Validation loss: 0.1308787651\n",
      "[79] Train loss: 0.0665450564\n",
      "[79] Validation loss: 0.1432409512\n",
      "[80] Train loss: 0.0730443839\n",
      "[80] Validation loss: 0.1282583501\n",
      "[81] Train loss: 0.0768233361\n",
      "[81] Validation loss: 0.1086072496\n",
      "[82] Train loss: 0.0762838577\n",
      "[82] Validation loss: 0.0955561677\n",
      "[83] Train loss: 0.0727435920\n",
      "[83] Validation loss: 0.1070411028\n",
      "[84] Train loss: 0.0712898750\n",
      "[84] Validation loss: 0.1322105727\n",
      "[85] Train loss: 0.0718224813\n",
      "[85] Validation loss: 0.1292303097\n",
      "[86] Train loss: 0.0731804312\n",
      "[86] Validation loss: 0.1099970895\n",
      "[87] Train loss: 0.0746800852\n",
      "[87] Validation loss: 0.0969469415\n",
      "[88] Train loss: 0.0802642384\n",
      "[88] Validation loss: 0.0834943373\n",
      "[89] Train loss: 0.0972050219\n",
      "[89] Validation loss: 0.0733895181\n",
      "[90] Train loss: 0.1166223084\n",
      "[90] Validation loss: 0.1117499622\n",
      "[91] Train loss: 0.1326906846\n",
      "[91] Validation loss: 0.1784418030\n",
      "[92] Train loss: 0.1655069307\n",
      "[92] Validation loss: 0.1169798477\n",
      "[93] Train loss: 0.1659876215\n",
      "[93] Validation loss: 0.0765576961\n",
      "[94] Train loss: 0.1426654335\n",
      "[94] Validation loss: 0.0778527851\n",
      "[95] Train loss: 0.1371231446\n",
      "[95] Validation loss: 0.0650230276\n",
      "[96] Train loss: 0.1043893751\n",
      "[96] Validation loss: 0.0825915311\n",
      "[97] Train loss: 0.0896937878\n",
      "[97] Validation loss: 0.0923060486\n",
      "[98] Train loss: 0.0799484599\n",
      "[98] Validation loss: 0.0826254913\n",
      "[99] Train loss: 0.0717470341\n",
      "[99] Validation loss: 0.0760961508\n",
      "[100] Train loss: 0.0599503852\n",
      "[100] Validation loss: 0.0703683102\n",
      "[101] Train loss: 0.0504472344\n",
      "[101] Validation loss: 0.0743309434\n",
      "[102] Train loss: 0.0510829816\n",
      "[102] Validation loss: 0.0789287623\n",
      "[103] Train loss: 0.0549322299\n",
      "[103] Validation loss: 0.0829827513\n",
      "[104] Train loss: 0.0584947137\n",
      "[104] Validation loss: 0.0902076855\n",
      "[105] Train loss: 0.0611091954\n",
      "[105] Validation loss: 0.0926496792\n",
      "[106] Train loss: 0.0630618795\n",
      "[106] Validation loss: 0.0770698716\n",
      "[107] Train loss: 0.0608778870\n",
      "[107] Validation loss: 0.0572038929\n",
      "model saved\n",
      "[108] Train loss: 0.0592382145\n",
      "[108] Validation loss: 0.0512976893\n",
      "model saved\n",
      "[109] Train loss: 0.0628978450\n",
      "[109] Validation loss: 0.0715920730\n",
      "[110] Train loss: 0.0703165692\n",
      "[110] Validation loss: 0.1138623093\n",
      "[111] Train loss: 0.0794444454\n",
      "[111] Validation loss: 0.1609363714\n",
      "[112] Train loss: 0.0796889294\n",
      "[112] Validation loss: 0.1903204762\n",
      "[113] Train loss: 0.0809561019\n",
      "[113] Validation loss: 0.1707644467\n",
      "[114] Train loss: 0.0801989251\n",
      "[114] Validation loss: 0.1340106677\n",
      "[115] Train loss: 0.0833379261\n",
      "[115] Validation loss: 0.1005428231\n",
      "[116] Train loss: 0.0728720211\n",
      "[116] Validation loss: 0.0867619171\n",
      "[117] Train loss: 0.0632767176\n",
      "[117] Validation loss: 0.0944541423\n",
      "[118] Train loss: 0.0543038305\n",
      "[118] Validation loss: 0.0922593684\n",
      "[119] Train loss: 0.0511987457\n",
      "[119] Validation loss: 0.0797593475\n",
      "[120] Train loss: 0.0566094135\n",
      "[120] Validation loss: 0.0807641430\n",
      "[121] Train loss: 0.0627753111\n",
      "[121] Validation loss: 0.0701764477\n",
      "[122] Train loss: 0.0631428553\n",
      "[122] Validation loss: 0.0643297553\n",
      "[123] Train loss: 0.0627606009\n",
      "[123] Validation loss: 0.1083920231\n",
      "[124] Train loss: 0.0626320523\n",
      "[124] Validation loss: 0.1298387372\n",
      "[125] Train loss: 0.0694371656\n",
      "[125] Validation loss: 0.0871499870\n",
      "[126] Train loss: 0.0759322957\n",
      "[126] Validation loss: 0.0694151309\n",
      "[127] Train loss: 0.0725055073\n",
      "[127] Validation loss: 0.0596261381\n",
      "[128] Train loss: 0.0725409399\n",
      "[128] Validation loss: 0.0992927052\n",
      "[129] Train loss: 0.0713276306\n",
      "[129] Validation loss: 0.1065947134\n",
      "[130] Train loss: 0.0633394793\n",
      "[130] Validation loss: 0.0675677757\n",
      "[131] Train loss: 0.0606783096\n",
      "[131] Validation loss: 0.0568662042\n",
      "[132] Train loss: 0.0687701642\n",
      "[132] Validation loss: 0.0551038171\n",
      "[133] Train loss: 0.0710606569\n",
      "[133] Validation loss: 0.0547803502\n",
      "[134] Train loss: 0.0728653856\n",
      "[134] Validation loss: 0.0642837528\n",
      "[135] Train loss: 0.0736974523\n",
      "[135] Validation loss: 0.0798480232\n",
      "[136] Train loss: 0.0833300698\n",
      "[136] Validation loss: 0.1315985156\n",
      "[137] Train loss: 0.0964442339\n",
      "[137] Validation loss: 0.1501660347\n",
      "[138] Train loss: 0.1162271685\n",
      "[138] Validation loss: 0.1392417001\n",
      "[139] Train loss: 0.1332012739\n",
      "[139] Validation loss: 0.1374618332\n",
      "[140] Train loss: 0.1412600506\n",
      "[140] Validation loss: 0.1379269671\n",
      "[141] Train loss: 0.1417399562\n",
      "[141] Validation loss: 0.1491909558\n",
      "[142] Train loss: 0.1577549047\n",
      "[142] Validation loss: 0.0940718639\n",
      "[143] Train loss: 0.1759005722\n",
      "[143] Validation loss: 0.0522557788\n",
      "[144] Train loss: 0.1538927627\n",
      "[144] Validation loss: 0.0578538987\n",
      "[145] Train loss: 0.1197385594\n",
      "[145] Validation loss: 0.0622762530\n",
      "[146] Train loss: 0.0890931264\n",
      "[146] Validation loss: 0.0705450347\n",
      "[147] Train loss: 0.0663766770\n",
      "[147] Validation loss: 0.0557307116\n",
      "[148] Train loss: 0.0515467729\n",
      "[148] Validation loss: 0.0599654817\n",
      "[149] Train loss: 0.0454309410\n",
      "[149] Validation loss: 0.0614057874\n",
      "[150] Train loss: 0.0390373246\n",
      "[150] Validation loss: 0.0592432230\n",
      "[151] Train loss: 0.0348076777\n",
      "[151] Validation loss: 0.0693928500\n",
      "[152] Train loss: 0.0330430148\n",
      "[152] Validation loss: 0.0888523263\n",
      "[153] Train loss: 0.0338179331\n",
      "[153] Validation loss: 0.0994905783\n",
      "[154] Train loss: 0.0350307739\n",
      "[154] Validation loss: 0.0980223970\n",
      "[155] Train loss: 0.0361997549\n",
      "[155] Validation loss: 0.0835157305\n",
      "[156] Train loss: 0.0382985281\n",
      "[156] Validation loss: 0.0627471553\n",
      "[157] Train loss: 0.0401973024\n",
      "[157] Validation loss: 0.0514497889\n",
      "[158] Train loss: 0.0403108850\n",
      "[158] Validation loss: 0.0565853334\n",
      "[159] Train loss: 0.0419662289\n",
      "[159] Validation loss: 0.0637301728\n",
      "[160] Train loss: 0.0381166356\n",
      "[160] Validation loss: 0.0568790472\n",
      "[161] Train loss: 0.0354813213\n",
      "[161] Validation loss: 0.0496845674\n",
      "model saved\n",
      "[162] Train loss: 0.0342218481\n",
      "[162] Validation loss: 0.0459102145\n",
      "model saved\n",
      "[163] Train loss: 0.0330534977\n",
      "[163] Validation loss: 0.0455413548\n",
      "model saved\n",
      "[164] Train loss: 0.0312476873\n",
      "[164] Validation loss: 0.0454618093\n",
      "model saved\n",
      "[165] Train loss: 0.0279861582\n",
      "[165] Validation loss: 0.0455041840\n",
      "[166] Train loss: 0.0264101698\n",
      "[166] Validation loss: 0.0460202690\n",
      "[167] Train loss: 0.0255839930\n",
      "[167] Validation loss: 0.0480539735\n",
      "[168] Train loss: 0.0234510596\n",
      "[168] Validation loss: 0.0441053131\n",
      "model saved\n",
      "[169] Train loss: 0.0215834267\n",
      "[169] Validation loss: 0.0449482667\n",
      "[170] Train loss: 0.0196556789\n",
      "[170] Validation loss: 0.0464756528\n",
      "[171] Train loss: 0.0177672554\n",
      "[171] Validation loss: 0.0418027026\n",
      "model saved\n",
      "[172] Train loss: 0.0184790967\n",
      "[172] Validation loss: 0.0410265283\n",
      "model saved\n",
      "[173] Train loss: 0.0213903832\n",
      "[173] Validation loss: 0.0497730102\n",
      "[174] Train loss: 0.0248995904\n",
      "[174] Validation loss: 0.0479476620\n",
      "[175] Train loss: 0.0270285755\n",
      "[175] Validation loss: 0.0425001832\n",
      "[176] Train loss: 0.0272685959\n",
      "[176] Validation loss: 0.0437697920\n",
      "[177] Train loss: 0.0303292719\n",
      "[177] Validation loss: 0.0483715931\n",
      "[178] Train loss: 0.0354633092\n",
      "[178] Validation loss: 0.0742074617\n",
      "[179] Train loss: 0.0347384734\n",
      "[179] Validation loss: 0.0804074593\n",
      "[180] Train loss: 0.0358147528\n",
      "[180] Validation loss: 0.0639171836\n",
      "[181] Train loss: 0.0363315487\n",
      "[181] Validation loss: 0.0669153876\n",
      "[182] Train loss: 0.0341147155\n",
      "[182] Validation loss: 0.0731704817\n",
      "[183] Train loss: 0.0307401482\n",
      "[183] Validation loss: 0.0857680356\n",
      "[184] Train loss: 0.0309509899\n",
      "[184] Validation loss: 0.0808512444\n",
      "[185] Train loss: 0.0291854268\n",
      "[185] Validation loss: 0.0632301013\n",
      "[186] Train loss: 0.0232188723\n",
      "[186] Validation loss: 0.0488805673\n",
      "[187] Train loss: 0.0234975475\n",
      "[187] Validation loss: 0.0435088761\n",
      "[188] Train loss: 0.0262240769\n",
      "[188] Validation loss: 0.0569486765\n",
      "[189] Train loss: 0.0274928164\n",
      "[189] Validation loss: 0.0616221385\n",
      "[190] Train loss: 0.0286770614\n",
      "[190] Validation loss: 0.0480361234\n",
      "[191] Train loss: 0.0316293468\n",
      "[191] Validation loss: 0.0502309856\n",
      "[192] Train loss: 0.0380065684\n",
      "[192] Validation loss: 0.0452249182\n",
      "[193] Train loss: 0.0346692934\n",
      "[193] Validation loss: 0.0470866190\n",
      "[194] Train loss: 0.0314413080\n",
      "[194] Validation loss: 0.0584856403\n",
      "[195] Train loss: 0.0331635493\n",
      "[195] Validation loss: 0.0636502698\n",
      "[196] Train loss: 0.0315865736\n",
      "[196] Validation loss: 0.0662372435\n",
      "[197] Train loss: 0.0326971789\n",
      "[197] Validation loss: 0.0470237540\n",
      "[198] Train loss: 0.0356265029\n",
      "[198] Validation loss: 0.0391947938\n",
      "model saved\n",
      "[199] Train loss: 0.0343215924\n",
      "[199] Validation loss: 0.0564451532\n",
      "[200] Train loss: 0.0292191968\n",
      "[200] Validation loss: 0.0729462209\n",
      "2 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 2.6862062856\n",
      "[1] Validation loss: 0.1884803362\n",
      "model saved\n",
      "[2] Train loss: 0.7568421839\n",
      "[2] Validation loss: 0.2441349276\n",
      "[3] Train loss: 0.3822903810\n",
      "[3] Validation loss: 0.2570756720\n",
      "[4] Train loss: 0.2554606944\n",
      "[4] Validation loss: 0.2443817873\n",
      "[5] Train loss: 0.1891003295\n",
      "[5] Validation loss: 0.2171910349\n",
      "[6] Train loss: 0.1546300319\n",
      "[6] Validation loss: 0.1883418774\n",
      "model saved\n",
      "[7] Train loss: 0.1467251844\n",
      "[7] Validation loss: 0.2313052551\n",
      "[8] Train loss: 0.1894617027\n",
      "[8] Validation loss: 0.2351660626\n",
      "[9] Train loss: 0.3227199009\n",
      "[9] Validation loss: 0.2384005408\n",
      "[10] Train loss: 0.6883147340\n",
      "[10] Validation loss: 0.4124656860\n",
      "[11] Train loss: 1.3709671199\n",
      "[11] Validation loss: 0.4431876084\n",
      "[12] Train loss: 1.0987373977\n",
      "[12] Validation loss: 0.2026911057\n",
      "[13] Train loss: 0.4385930878\n",
      "[13] Validation loss: 0.1322719441\n",
      "model saved\n",
      "[14] Train loss: 0.1711985124\n",
      "[14] Validation loss: 0.1287452518\n",
      "model saved\n",
      "[15] Train loss: 0.1254903860\n",
      "[15] Validation loss: 0.1311930260\n",
      "[16] Train loss: 0.1095273854\n",
      "[16] Validation loss: 0.1365110208\n",
      "[17] Train loss: 0.1096905010\n",
      "[17] Validation loss: 0.1491244482\n",
      "[18] Train loss: 0.1148648349\n",
      "[18] Validation loss: 0.1713082404\n",
      "[19] Train loss: 0.1280313604\n",
      "[19] Validation loss: 0.2032127799\n",
      "[20] Train loss: 0.1551582666\n",
      "[20] Validation loss: 0.2331014785\n",
      "[21] Train loss: 0.1960417588\n",
      "[21] Validation loss: 0.2139788270\n",
      "[22] Train loss: 0.2503942961\n",
      "[22] Validation loss: 0.1549299741\n",
      "[23] Train loss: 0.3006662235\n",
      "[23] Validation loss: 0.1514276415\n",
      "[24] Train loss: 0.3342961975\n",
      "[24] Validation loss: 0.2165568313\n",
      "[25] Train loss: 0.3844501441\n",
      "[25] Validation loss: 0.1750145941\n",
      "[26] Train loss: 0.3455512527\n",
      "[26] Validation loss: 0.1409529452\n",
      "[27] Train loss: 0.2237608425\n",
      "[27] Validation loss: 0.1456788424\n",
      "[28] Train loss: 0.1605079870\n",
      "[28] Validation loss: 0.1078590422\n",
      "model saved\n",
      "[29] Train loss: 0.1192982867\n",
      "[29] Validation loss: 0.0854283575\n",
      "model saved\n",
      "[30] Train loss: 0.0970596329\n",
      "[30] Validation loss: 0.0799827198\n",
      "model saved\n",
      "[31] Train loss: 0.0885575751\n",
      "[31] Validation loss: 0.0778790461\n",
      "model saved\n",
      "[32] Train loss: 0.0817895407\n",
      "[32] Validation loss: 0.0815955799\n",
      "[33] Train loss: 0.0753150955\n",
      "[33] Validation loss: 0.0903729207\n",
      "[34] Train loss: 0.0699690297\n",
      "[34] Validation loss: 0.1011498240\n",
      "[35] Train loss: 0.0654450484\n",
      "[35] Validation loss: 0.1061570768\n",
      "[36] Train loss: 0.0607629828\n",
      "[36] Validation loss: 0.1039662140\n",
      "[37] Train loss: 0.0578693457\n",
      "[37] Validation loss: 0.0980245599\n",
      "[38] Train loss: 0.0561880197\n",
      "[38] Validation loss: 0.0917791266\n",
      "[39] Train loss: 0.0551559131\n",
      "[39] Validation loss: 0.0908934494\n",
      "[40] Train loss: 0.0547016635\n",
      "[40] Validation loss: 0.0979000931\n",
      "[41] Train loss: 0.0555617152\n",
      "[41] Validation loss: 0.1112371637\n",
      "[42] Train loss: 0.0575051963\n",
      "[42] Validation loss: 0.1256055539\n",
      "[43] Train loss: 0.0617039627\n",
      "[43] Validation loss: 0.1298487028\n",
      "[44] Train loss: 0.0693979835\n",
      "[44] Validation loss: 0.1222599421\n",
      "[45] Train loss: 0.0792239005\n",
      "[45] Validation loss: 0.1100726421\n",
      "[46] Train loss: 0.0860351893\n",
      "[46] Validation loss: 0.1008856818\n",
      "[47] Train loss: 0.0900175145\n",
      "[47] Validation loss: 0.1052573803\n",
      "[48] Train loss: 0.0955084354\n",
      "[48] Validation loss: 0.1163082840\n",
      "[49] Train loss: 0.1048803960\n",
      "[49] Validation loss: 0.1212391411\n",
      "[50] Train loss: 0.1139235887\n",
      "[50] Validation loss: 0.1043409802\n",
      "[51] Train loss: 0.1273322767\n",
      "[51] Validation loss: 0.0883461020\n",
      "[52] Train loss: 0.1409788385\n",
      "[52] Validation loss: 0.0883609308\n",
      "[53] Train loss: 0.1647426845\n",
      "[53] Validation loss: 0.0993002686\n",
      "[54] Train loss: 0.2030241205\n",
      "[54] Validation loss: 0.1116502881\n",
      "[55] Train loss: 0.2137707688\n",
      "[55] Validation loss: 0.1404839107\n",
      "[56] Train loss: 0.2156760612\n",
      "[56] Validation loss: 0.1126160114\n",
      "[57] Train loss: 0.1723385705\n",
      "[57] Validation loss: 0.1000692940\n",
      "[58] Train loss: 0.1245355972\n",
      "[58] Validation loss: 0.0967502010\n",
      "[59] Train loss: 0.1019322709\n",
      "[59] Validation loss: 0.0707150018\n",
      "model saved\n",
      "[60] Train loss: 0.0739251770\n",
      "[60] Validation loss: 0.0728934244\n",
      "[61] Train loss: 0.0557691332\n",
      "[61] Validation loss: 0.0815742678\n",
      "[62] Train loss: 0.0426764557\n",
      "[62] Validation loss: 0.0873151920\n",
      "[63] Train loss: 0.0411027169\n",
      "[63] Validation loss: 0.0815281877\n",
      "[64] Train loss: 0.0401093694\n",
      "[64] Validation loss: 0.0737797791\n",
      "[65] Train loss: 0.0385261832\n",
      "[65] Validation loss: 0.0770625635\n",
      "[66] Train loss: 0.0396636052\n",
      "[66] Validation loss: 0.0849775254\n",
      "[67] Train loss: 0.0357144962\n",
      "[67] Validation loss: 0.0984812106\n",
      "[68] Train loss: 0.0379916534\n",
      "[68] Validation loss: 0.0986260262\n",
      "[69] Train loss: 0.0372970694\n",
      "[69] Validation loss: 0.0940008550\n",
      "[70] Train loss: 0.0406673451\n",
      "[70] Validation loss: 0.0920489728\n",
      "[71] Train loss: 0.0451732395\n",
      "[71] Validation loss: 0.0890993855\n",
      "[72] Train loss: 0.0481904727\n",
      "[72] Validation loss: 0.0867132084\n",
      "[73] Train loss: 0.0575898852\n",
      "[73] Validation loss: 0.0842616837\n",
      "[74] Train loss: 0.0597392515\n",
      "[74] Validation loss: 0.0858641881\n",
      "[75] Train loss: 0.0627096229\n",
      "[75] Validation loss: 0.0842173677\n",
      "[76] Train loss: 0.0690799916\n",
      "[76] Validation loss: 0.0841949896\n",
      "[77] Train loss: 0.0771087735\n",
      "[77] Validation loss: 0.1141653010\n",
      "[78] Train loss: 0.0965813494\n",
      "[78] Validation loss: 0.1319763497\n",
      "[79] Train loss: 0.1039402529\n",
      "[79] Validation loss: 0.1210918440\n",
      "[80] Train loss: 0.1082694044\n",
      "[80] Validation loss: 0.1190624351\n",
      "[81] Train loss: 0.1142163132\n",
      "[81] Validation loss: 0.0966590709\n",
      "[82] Train loss: 0.1178131119\n",
      "[82] Validation loss: 0.0789081038\n",
      "[83] Train loss: 0.1125988720\n",
      "[83] Validation loss: 0.0713891860\n",
      "[84] Train loss: 0.1006593583\n",
      "[84] Validation loss: 0.0798417204\n",
      "[85] Train loss: 0.1124245274\n",
      "[85] Validation loss: 0.0796005309\n",
      "[86] Train loss: 0.1021686278\n",
      "[86] Validation loss: 0.0945584129\n",
      "[87] Train loss: 0.0927149479\n",
      "[87] Validation loss: 0.0935440925\n",
      "[88] Train loss: 0.0911098317\n",
      "[88] Validation loss: 0.0860790065\n",
      "[89] Train loss: 0.0807955996\n",
      "[89] Validation loss: 0.0804547279\n",
      "[90] Train loss: 0.0677258246\n",
      "[90] Validation loss: 0.0689222931\n",
      "model saved\n",
      "[91] Train loss: 0.0598527496\n",
      "[91] Validation loss: 0.0587427395\n",
      "model saved\n",
      "[92] Train loss: 0.0557645987\n",
      "[92] Validation loss: 0.0541247737\n",
      "model saved\n",
      "[93] Train loss: 0.0488902997\n",
      "[93] Validation loss: 0.0569571636\n",
      "[94] Train loss: 0.0426275372\n",
      "[94] Validation loss: 0.0575801285\n",
      "[95] Train loss: 0.0396915317\n",
      "[95] Validation loss: 0.0533941011\n",
      "model saved\n",
      "[96] Train loss: 0.0379178868\n",
      "[96] Validation loss: 0.0500781287\n",
      "model saved\n",
      "[97] Train loss: 0.0338334563\n",
      "[97] Validation loss: 0.0536730228\n",
      "[98] Train loss: 0.0338488510\n",
      "[98] Validation loss: 0.0598876780\n",
      "[99] Train loss: 0.0394761636\n",
      "[99] Validation loss: 0.0623516310\n",
      "[100] Train loss: 0.0459230988\n",
      "[100] Validation loss: 0.0621204260\n",
      "[101] Train loss: 0.0500569662\n",
      "[101] Validation loss: 0.0627270152\n",
      "[102] Train loss: 0.0488563333\n",
      "[102] Validation loss: 0.0608757439\n",
      "[103] Train loss: 0.0484661323\n",
      "[103] Validation loss: 0.0592015347\n",
      "[104] Train loss: 0.0506128703\n",
      "[104] Validation loss: 0.0671330688\n",
      "[105] Train loss: 0.0582744201\n",
      "[105] Validation loss: 0.0701210127\n",
      "[106] Train loss: 0.0709690261\n",
      "[106] Validation loss: 0.0560826089\n",
      "[107] Train loss: 0.0762019910\n",
      "[107] Validation loss: 0.0556760376\n",
      "[108] Train loss: 0.0718792441\n",
      "[108] Validation loss: 0.0568070705\n",
      "[109] Train loss: 0.0674694049\n",
      "[109] Validation loss: 0.0514998008\n",
      "[110] Train loss: 0.0506479366\n",
      "[110] Validation loss: 0.0615728932\n",
      "[111] Train loss: 0.0461363966\n",
      "[111] Validation loss: 0.0578409522\n",
      "[112] Train loss: 0.0475770095\n",
      "[112] Validation loss: 0.0535078596\n",
      "[113] Train loss: 0.0418937097\n",
      "[113] Validation loss: 0.0573820850\n",
      "[114] Train loss: 0.0417573696\n",
      "[114] Validation loss: 0.0668280481\n",
      "[115] Train loss: 0.0458616322\n",
      "[115] Validation loss: 0.0848229937\n",
      "[116] Train loss: 0.0466436553\n",
      "[116] Validation loss: 0.1036157627\n",
      "[117] Train loss: 0.0522726506\n",
      "[117] Validation loss: 0.0987659332\n",
      "[118] Train loss: 0.0556289538\n",
      "[118] Validation loss: 0.0877456591\n",
      "[119] Train loss: 0.0600979417\n",
      "[119] Validation loss: 0.0688334464\n",
      "[120] Train loss: 0.0676510934\n",
      "[120] Validation loss: 0.0571535439\n",
      "[121] Train loss: 0.0643236985\n",
      "[121] Validation loss: 0.0603822524\n",
      "[122] Train loss: 0.0566410640\n",
      "[122] Validation loss: 0.0679605666\n",
      "[123] Train loss: 0.0526318004\n",
      "[123] Validation loss: 0.0749547936\n",
      "[124] Train loss: 0.0518919930\n",
      "[124] Validation loss: 0.0770544908\n",
      "[125] Train loss: 0.0554836661\n",
      "[125] Validation loss: 0.0742960903\n",
      "[126] Train loss: 0.0539026793\n",
      "[126] Validation loss: 0.0808564797\n",
      "[127] Train loss: 0.0514097073\n",
      "[127] Validation loss: 0.0917260090\n",
      "[128] Train loss: 0.0460208180\n",
      "[128] Validation loss: 0.0959394649\n",
      "[129] Train loss: 0.0427633188\n",
      "[129] Validation loss: 0.0857785498\n",
      "[130] Train loss: 0.0438008989\n",
      "[130] Validation loss: 0.0812147364\n",
      "[131] Train loss: 0.0401481621\n",
      "[131] Validation loss: 0.0825528102\n",
      "[132] Train loss: 0.0405545707\n",
      "[132] Validation loss: 0.0780507259\n",
      "[133] Train loss: 0.0454100043\n",
      "[133] Validation loss: 0.0612465256\n",
      "[134] Train loss: 0.0456882583\n",
      "[134] Validation loss: 0.0606963661\n",
      "[135] Train loss: 0.0473760211\n",
      "[135] Validation loss: 0.0664484277\n",
      "[136] Train loss: 0.0485230262\n",
      "[136] Validation loss: 0.0698486960\n",
      "[137] Train loss: 0.0499923868\n",
      "[137] Validation loss: 0.0787059225\n",
      "[138] Train loss: 0.0618679076\n",
      "[138] Validation loss: 0.0738462503\n",
      "[139] Train loss: 0.0664769043\n",
      "[139] Validation loss: 0.0650253536\n",
      "[140] Train loss: 0.0648948973\n",
      "[140] Validation loss: 0.0703645357\n",
      "[141] Train loss: 0.0587498658\n",
      "[141] Validation loss: 0.0835253194\n",
      "[142] Train loss: 0.0526686067\n",
      "[142] Validation loss: 0.0755618807\n",
      "[143] Train loss: 0.0596256504\n",
      "[143] Validation loss: 0.0550606076\n",
      "[144] Train loss: 0.0534653582\n",
      "[144] Validation loss: 0.0579274315\n",
      "[145] Train loss: 0.0402907642\n",
      "[145] Validation loss: 0.0556167732\n",
      "[146] Train loss: 0.0313352112\n",
      "[146] Validation loss: 0.0531483683\n",
      "[147] Train loss: 0.0269295945\n",
      "[147] Validation loss: 0.0483306495\n",
      "model saved\n",
      "[148] Train loss: 0.0236781519\n",
      "[148] Validation loss: 0.0480916450\n",
      "model saved\n",
      "[149] Train loss: 0.0212322170\n",
      "[149] Validation loss: 0.0505401070\n",
      "[150] Train loss: 0.0209238619\n",
      "[150] Validation loss: 0.0511296529\n",
      "[151] Train loss: 0.0219141306\n",
      "[151] Validation loss: 0.0494280716\n",
      "[152] Train loss: 0.0246483314\n",
      "[152] Validation loss: 0.0451397848\n",
      "model saved\n",
      "[153] Train loss: 0.0268904373\n",
      "[153] Validation loss: 0.0456523182\n",
      "[154] Train loss: 0.0259093569\n",
      "[154] Validation loss: 0.0562689417\n",
      "[155] Train loss: 0.0283749650\n",
      "[155] Validation loss: 0.0650029152\n",
      "[156] Train loss: 0.0349185199\n",
      "[156] Validation loss: 0.0636323234\n",
      "[157] Train loss: 0.0387420530\n",
      "[157] Validation loss: 0.0657034128\n",
      "[158] Train loss: 0.0418415763\n",
      "[158] Validation loss: 0.0661842618\n",
      "[159] Train loss: 0.0548717893\n",
      "[159] Validation loss: 0.0496523803\n",
      "[160] Train loss: 0.0505239947\n",
      "[160] Validation loss: 0.0482597767\n",
      "[161] Train loss: 0.0442429841\n",
      "[161] Validation loss: 0.0465093253\n",
      "[162] Train loss: 0.0289692916\n",
      "[162] Validation loss: 0.0435496481\n",
      "model saved\n",
      "[163] Train loss: 0.0244848469\n",
      "[163] Validation loss: 0.0413207905\n",
      "model saved\n",
      "[164] Train loss: 0.0204812849\n",
      "[164] Validation loss: 0.0457579184\n",
      "[165] Train loss: 0.0201804418\n",
      "[165] Validation loss: 0.0443487522\n",
      "[166] Train loss: 0.0210090936\n",
      "[166] Validation loss: 0.0440495808\n",
      "[167] Train loss: 0.0214708642\n",
      "[167] Validation loss: 0.0498474488\n",
      "[168] Train loss: 0.0217197841\n",
      "[168] Validation loss: 0.0547037073\n",
      "[169] Train loss: 0.0239899887\n",
      "[169] Validation loss: 0.0540519725\n",
      "[170] Train loss: 0.0258788824\n",
      "[170] Validation loss: 0.0494156701\n",
      "[171] Train loss: 0.0307610057\n",
      "[171] Validation loss: 0.0472071159\n",
      "[172] Train loss: 0.0347366700\n",
      "[172] Validation loss: 0.0537793996\n",
      "[173] Train loss: 0.0395850984\n",
      "[173] Validation loss: 0.0633343414\n",
      "[174] Train loss: 0.0461541101\n",
      "[174] Validation loss: 0.0613436735\n",
      "[175] Train loss: 0.0515598902\n",
      "[175] Validation loss: 0.0493606988\n",
      "[176] Train loss: 0.0600435744\n",
      "[176] Validation loss: 0.0507430233\n",
      "[177] Train loss: 0.0575323263\n",
      "[177] Validation loss: 0.0646664292\n",
      "[178] Train loss: 0.0604227498\n",
      "[178] Validation loss: 0.0665448969\n",
      "[179] Train loss: 0.0609904416\n",
      "[179] Validation loss: 0.0585971985\n",
      "[180] Train loss: 0.0497137475\n",
      "[180] Validation loss: 0.0455251505\n",
      "[181] Train loss: 0.0397772185\n",
      "[181] Validation loss: 0.0522594257\n",
      "[182] Train loss: 0.0367828326\n",
      "[182] Validation loss: 0.0560736411\n",
      "[183] Train loss: 0.0332954488\n",
      "[183] Validation loss: 0.0563754806\n",
      "[184] Train loss: 0.0308314175\n",
      "[184] Validation loss: 0.0605735413\n",
      "[185] Train loss: 0.0298092018\n",
      "[185] Validation loss: 0.0723401636\n",
      "[186] Train loss: 0.0313605471\n",
      "[186] Validation loss: 0.0799086710\n",
      "[187] Train loss: 0.0353627002\n",
      "[187] Validation loss: 0.0783951969\n",
      "[188] Train loss: 0.0406440232\n",
      "[188] Validation loss: 0.0844715529\n",
      "[189] Train loss: 0.0424854383\n",
      "[189] Validation loss: 0.1160788415\n",
      "[190] Train loss: 0.0462137674\n",
      "[190] Validation loss: 0.1392321317\n",
      "[191] Train loss: 0.0536349405\n",
      "[191] Validation loss: 0.1186252134\n",
      "[192] Train loss: 0.0633532578\n",
      "[192] Validation loss: 0.0883994187\n",
      "[193] Train loss: 0.0729338943\n",
      "[193] Validation loss: 0.0833912657\n",
      "[194] Train loss: 0.0823203438\n",
      "[194] Validation loss: 0.0747340168\n",
      "[195] Train loss: 0.0885967573\n",
      "[195] Validation loss: 0.0604670172\n",
      "[196] Train loss: 0.0821259937\n",
      "[196] Validation loss: 0.0507647736\n",
      "[197] Train loss: 0.0877924894\n",
      "[197] Validation loss: 0.0473769354\n",
      "[198] Train loss: 0.1015730988\n",
      "[198] Validation loss: 0.0452562832\n",
      "[199] Train loss: 0.1060723660\n",
      "[199] Validation loss: 0.0573536537\n",
      "[200] Train loss: 0.1085160222\n",
      "[200] Validation loss: 0.0761929500\n",
      "3 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 3.4404277746\n",
      "[1] Validation loss: 0.2464482449\n",
      "model saved\n",
      "[2] Train loss: 0.7522558901\n",
      "[2] Validation loss: 0.2703572572\n",
      "[3] Train loss: 0.4020024099\n",
      "[3] Validation loss: 0.2519776800\n",
      "[4] Train loss: 0.2674987413\n",
      "[4] Validation loss: 0.2256552239\n",
      "model saved\n",
      "[5] Train loss: 0.1953393264\n",
      "[5] Validation loss: 0.2172744754\n",
      "model saved\n",
      "[6] Train loss: 0.1689520438\n",
      "[6] Validation loss: 0.2298734812\n",
      "[7] Train loss: 0.1675056861\n",
      "[7] Validation loss: 0.2598393154\n",
      "[8] Train loss: 0.1893660168\n",
      "[8] Validation loss: 0.2994545512\n",
      "[9] Train loss: 0.2494531062\n",
      "[9] Validation loss: 0.3222534778\n",
      "[10] Train loss: 0.3587307693\n",
      "[10] Validation loss: 0.3033794332\n",
      "[11] Train loss: 0.5427547060\n",
      "[11] Validation loss: 0.4291977901\n",
      "[12] Train loss: 0.7443580390\n",
      "[12] Validation loss: 0.9188196007\n",
      "[13] Train loss: 1.2271452914\n",
      "[13] Validation loss: 0.5912493002\n",
      "[14] Train loss: 1.1291624778\n",
      "[14] Validation loss: 0.2975776121\n",
      "[15] Train loss: 0.6037552778\n",
      "[15] Validation loss: 0.2499679588\n",
      "[16] Train loss: 0.3252317035\n",
      "[16] Validation loss: 0.1987107033\n",
      "model saved\n",
      "[17] Train loss: 0.2216263677\n",
      "[17] Validation loss: 0.2061998136\n",
      "[18] Train loss: 0.1568634650\n",
      "[18] Validation loss: 0.2020248557\n",
      "[19] Train loss: 0.1303727083\n",
      "[19] Validation loss: 0.1947844073\n",
      "model saved\n",
      "[20] Train loss: 0.1131297310\n",
      "[20] Validation loss: 0.1794235730\n",
      "model saved\n",
      "[21] Train loss: 0.0967687887\n",
      "[21] Validation loss: 0.1654327402\n",
      "model saved\n",
      "[22] Train loss: 0.0818075247\n",
      "[22] Validation loss: 0.1612505778\n",
      "model saved\n",
      "[23] Train loss: 0.0695522712\n",
      "[23] Validation loss: 0.1655787327\n",
      "[24] Train loss: 0.0620861176\n",
      "[24] Validation loss: 0.1714157679\n",
      "[25] Train loss: 0.0595490000\n",
      "[25] Validation loss: 0.1734522791\n",
      "[26] Train loss: 0.0591704104\n",
      "[26] Validation loss: 0.1692372048\n",
      "[27] Train loss: 0.0571169063\n",
      "[27] Validation loss: 0.1632434069\n",
      "[28] Train loss: 0.0530696998\n",
      "[28] Validation loss: 0.1611182967\n",
      "model saved\n",
      "[29] Train loss: 0.0497533549\n",
      "[29] Validation loss: 0.1623880500\n",
      "[30] Train loss: 0.0502300106\n",
      "[30] Validation loss: 0.1645678773\n",
      "[31] Train loss: 0.0567057673\n",
      "[31] Validation loss: 0.1618992835\n",
      "[32] Train loss: 0.0702887865\n",
      "[32] Validation loss: 0.1525799441\n",
      "model saved\n",
      "[33] Train loss: 0.0881667419\n",
      "[33] Validation loss: 0.1423959958\n",
      "model saved\n",
      "[34] Train loss: 0.1033347888\n",
      "[34] Validation loss: 0.1450313418\n",
      "[35] Train loss: 0.1171506245\n",
      "[35] Validation loss: 0.1621399729\n",
      "[36] Train loss: 0.1367218138\n",
      "[36] Validation loss: 0.1662631377\n",
      "[37] Train loss: 0.1827001245\n",
      "[37] Validation loss: 0.1535332969\n",
      "[38] Train loss: 0.2478903991\n",
      "[38] Validation loss: 0.1873568760\n",
      "[39] Train loss: 0.2730685316\n",
      "[39] Validation loss: 0.2656505625\n",
      "[40] Train loss: 0.2790386128\n",
      "[40] Validation loss: 0.1993804036\n",
      "[41] Train loss: 0.2521039472\n",
      "[41] Validation loss: 0.1643995498\n",
      "[42] Train loss: 0.1910412095\n",
      "[42] Validation loss: 0.1948406459\n",
      "[43] Train loss: 0.1434858529\n",
      "[43] Validation loss: 0.1717020734\n",
      "[44] Train loss: 0.1113532455\n",
      "[44] Validation loss: 0.1573786451\n",
      "[45] Train loss: 0.0931649592\n",
      "[45] Validation loss: 0.1738038501\n",
      "[46] Train loss: 0.0838754333\n",
      "[46] Validation loss: 0.1937195496\n",
      "[47] Train loss: 0.0747142672\n",
      "[47] Validation loss: 0.1905591330\n",
      "[48] Train loss: 0.0680559324\n",
      "[48] Validation loss: 0.1858252762\n",
      "[49] Train loss: 0.0668175399\n",
      "[49] Validation loss: 0.1863402827\n",
      "[50] Train loss: 0.0679379882\n",
      "[50] Validation loss: 0.1830088294\n",
      "[51] Train loss: 0.0663509552\n",
      "[51] Validation loss: 0.1732200678\n",
      "[52] Train loss: 0.0643597371\n",
      "[52] Validation loss: 0.1708705693\n",
      "[53] Train loss: 0.0634874785\n",
      "[53] Validation loss: 0.1818628211\n",
      "[54] Train loss: 0.0656124879\n",
      "[54] Validation loss: 0.1918732198\n",
      "[55] Train loss: 0.0692362821\n",
      "[55] Validation loss: 0.1876224901\n",
      "[56] Train loss: 0.0717656528\n",
      "[56] Validation loss: 0.1687185855\n",
      "[57] Train loss: 0.0758165096\n",
      "[57] Validation loss: 0.1536673880\n",
      "[58] Train loss: 0.0829516178\n",
      "[58] Validation loss: 0.1484219218\n",
      "[59] Train loss: 0.0925569585\n",
      "[59] Validation loss: 0.1397149269\n",
      "model saved\n",
      "[60] Train loss: 0.1011320849\n",
      "[60] Validation loss: 0.1411881943\n",
      "[61] Train loss: 0.1031981092\n",
      "[61] Validation loss: 0.1591827669\n",
      "[62] Train loss: 0.1088188558\n",
      "[62] Validation loss: 0.1733852522\n",
      "[63] Train loss: 0.1182153815\n",
      "[63] Validation loss: 0.1657074555\n",
      "[64] Train loss: 0.1230471252\n",
      "[64] Validation loss: 0.1717425566\n",
      "[65] Train loss: 0.1187472234\n",
      "[65] Validation loss: 0.1678173291\n",
      "[66] Train loss: 0.1134051537\n",
      "[66] Validation loss: 0.1425493278\n",
      "[67] Train loss: 0.1033724700\n",
      "[67] Validation loss: 0.1425556014\n",
      "[68] Train loss: 0.0954047237\n",
      "[68] Validation loss: 0.1499440977\n",
      "[69] Train loss: 0.0852471016\n",
      "[69] Validation loss: 0.1366667631\n",
      "model saved\n",
      "[70] Train loss: 0.0662305348\n",
      "[70] Validation loss: 0.1252994724\n",
      "model saved\n",
      "[71] Train loss: 0.0543354469\n",
      "[71] Validation loss: 0.1312880298\n",
      "[72] Train loss: 0.0533497301\n",
      "[72] Validation loss: 0.1374729335\n",
      "[73] Train loss: 0.0484344744\n",
      "[73] Validation loss: 0.1466534827\n",
      "[74] Train loss: 0.0412547882\n",
      "[74] Validation loss: 0.1616706576\n",
      "[75] Train loss: 0.0397213667\n",
      "[75] Validation loss: 0.1678206869\n",
      "[76] Train loss: 0.0403755993\n",
      "[76] Validation loss: 0.1612660938\n",
      "[77] Train loss: 0.0407989100\n",
      "[77] Validation loss: 0.1493774327\n",
      "[78] Train loss: 0.0435013360\n",
      "[78] Validation loss: 0.1382772948\n",
      "[79] Train loss: 0.0442145375\n",
      "[79] Validation loss: 0.1302321901\n",
      "[80] Train loss: 0.0440476083\n",
      "[80] Validation loss: 0.1292272344\n",
      "[81] Train loss: 0.0482507030\n",
      "[81] Validation loss: 0.1330781023\n",
      "[82] Train loss: 0.0574262645\n",
      "[82] Validation loss: 0.1343213911\n",
      "[83] Train loss: 0.0663082562\n",
      "[83] Validation loss: 0.1381677024\n",
      "[84] Train loss: 0.0720530350\n",
      "[84] Validation loss: 0.1461862870\n",
      "[85] Train loss: 0.0774868389\n",
      "[85] Validation loss: 0.1516386014\n",
      "[86] Train loss: 0.0885815677\n",
      "[86] Validation loss: 0.1399273989\n",
      "[87] Train loss: 0.1004870070\n",
      "[87] Validation loss: 0.1335018766\n",
      "[88] Train loss: 0.1008770538\n",
      "[88] Validation loss: 0.1502718844\n",
      "[89] Train loss: 0.0933148412\n",
      "[89] Validation loss: 0.1453218516\n",
      "[90] Train loss: 0.0858581919\n",
      "[90] Validation loss: 0.1290306270\n",
      "[91] Train loss: 0.0696892969\n",
      "[91] Validation loss: 0.1265612863\n",
      "[92] Train loss: 0.0509413538\n",
      "[92] Validation loss: 0.1287586465\n",
      "[93] Train loss: 0.0383836839\n",
      "[93] Validation loss: 0.1304174442\n",
      "[94] Train loss: 0.0343990645\n",
      "[94] Validation loss: 0.1290150884\n",
      "[95] Train loss: 0.0323464138\n",
      "[95] Validation loss: 0.1290713055\n",
      "[96] Train loss: 0.0275847483\n",
      "[96] Validation loss: 0.1323918306\n",
      "[97] Train loss: 0.0262556030\n",
      "[97] Validation loss: 0.1339917684\n",
      "[98] Train loss: 0.0282333980\n",
      "[98] Validation loss: 0.1307721669\n",
      "[99] Train loss: 0.0290337002\n",
      "[99] Validation loss: 0.1277025798\n",
      "[100] Train loss: 0.0306937112\n",
      "[100] Validation loss: 0.1270929822\n",
      "[101] Train loss: 0.0359499824\n",
      "[101] Validation loss: 0.1254232745\n",
      "[102] Train loss: 0.0425374784\n",
      "[102] Validation loss: 0.1323115913\n",
      "[103] Train loss: 0.0536617592\n",
      "[103] Validation loss: 0.1442658026\n",
      "[104] Train loss: 0.0701624048\n",
      "[104] Validation loss: 0.1373061489\n",
      "[105] Train loss: 0.0938374029\n",
      "[105] Validation loss: 0.1408807714\n",
      "[106] Train loss: 0.1145384858\n",
      "[106] Validation loss: 0.1521417154\n",
      "[107] Train loss: 0.1260182529\n",
      "[107] Validation loss: 0.1217300815\n",
      "model saved\n",
      "[108] Train loss: 0.1055955680\n",
      "[108] Validation loss: 0.1184208180\n",
      "model saved\n",
      "[109] Train loss: 0.0715325417\n",
      "[109] Validation loss: 0.1178390140\n",
      "model saved\n",
      "[110] Train loss: 0.0463096215\n",
      "[110] Validation loss: 0.1196040032\n",
      "[111] Train loss: 0.0356700344\n",
      "[111] Validation loss: 0.1181185384\n",
      "[112] Train loss: 0.0330994275\n",
      "[112] Validation loss: 0.1192604288\n",
      "[113] Train loss: 0.0312007971\n",
      "[113] Validation loss: 0.1299832489\n",
      "[114] Train loss: 0.0307367115\n",
      "[114] Validation loss: 0.1398695956\n",
      "[115] Train loss: 0.0356619328\n",
      "[115] Validation loss: 0.1400612192\n",
      "[116] Train loss: 0.0400970046\n",
      "[116] Validation loss: 0.1348083739\n",
      "[117] Train loss: 0.0429294789\n",
      "[117] Validation loss: 0.1343553632\n",
      "[118] Train loss: 0.0473601014\n",
      "[118] Validation loss: 0.1421169160\n",
      "[119] Train loss: 0.0533083744\n",
      "[119] Validation loss: 0.1450260977\n",
      "[120] Train loss: 0.0589493745\n",
      "[120] Validation loss: 0.1506596889\n",
      "[121] Train loss: 0.0647015950\n",
      "[121] Validation loss: 0.1677232296\n",
      "[122] Train loss: 0.0745808291\n",
      "[122] Validation loss: 0.1539507690\n",
      "[123] Train loss: 0.0925428071\n",
      "[123] Validation loss: 0.1319524811\n",
      "[124] Train loss: 0.0889964915\n",
      "[124] Validation loss: 0.1491063815\n",
      "[125] Train loss: 0.0787632124\n",
      "[125] Validation loss: 0.1381705189\n",
      "[126] Train loss: 0.0635258945\n",
      "[126] Validation loss: 0.1431961516\n",
      "[127] Train loss: 0.0560856342\n",
      "[127] Validation loss: 0.1281981043\n",
      "[128] Train loss: 0.0566636083\n",
      "[128] Validation loss: 0.1302873648\n",
      "[129] Train loss: 0.0581893278\n",
      "[129] Validation loss: 0.1384271053\n",
      "[130] Train loss: 0.0602128520\n",
      "[130] Validation loss: 0.1433322148\n",
      "[131] Train loss: 0.0605654935\n",
      "[131] Validation loss: 0.1595400851\n",
      "[132] Train loss: 0.0664225960\n",
      "[132] Validation loss: 0.1715487328\n",
      "[133] Train loss: 0.0837472410\n",
      "[133] Validation loss: 0.1637703110\n",
      "[134] Train loss: 0.1020022995\n",
      "[134] Validation loss: 0.1494682620\n",
      "[135] Train loss: 0.1224269549\n",
      "[135] Validation loss: 0.1550588694\n",
      "[136] Train loss: 0.1364157409\n",
      "[136] Validation loss: 0.1571868423\n",
      "[137] Train loss: 0.1653822244\n",
      "[137] Validation loss: 0.1781802261\n",
      "[138] Train loss: 0.1766896998\n",
      "[138] Validation loss: 0.1482966430\n",
      "[139] Train loss: 0.1830575162\n",
      "[139] Validation loss: 0.1987519944\n",
      "[140] Train loss: 0.1851674083\n",
      "[140] Validation loss: 0.1905820228\n",
      "[141] Train loss: 0.1717822541\n",
      "[141] Validation loss: 0.1570340053\n",
      "[142] Train loss: 0.1508273328\n",
      "[142] Validation loss: 0.1496670139\n",
      "[143] Train loss: 0.1421106199\n",
      "[143] Validation loss: 0.1491559751\n",
      "[144] Train loss: 0.1303952591\n",
      "[144] Validation loss: 0.1319550248\n",
      "[145] Train loss: 0.1142657018\n",
      "[145] Validation loss: 0.1159405570\n",
      "model saved\n",
      "[146] Train loss: 0.0942602808\n",
      "[146] Validation loss: 0.1149907091\n",
      "model saved\n",
      "[147] Train loss: 0.0733266839\n",
      "[147] Validation loss: 0.1220124381\n",
      "[148] Train loss: 0.0579855411\n",
      "[148] Validation loss: 0.1228331376\n",
      "[149] Train loss: 0.0468474811\n",
      "[149] Validation loss: 0.1166413171\n",
      "[150] Train loss: 0.0386923341\n",
      "[150] Validation loss: 0.1092310987\n",
      "model saved\n",
      "[151] Train loss: 0.0310750890\n",
      "[151] Validation loss: 0.1060645340\n",
      "model saved\n",
      "[152] Train loss: 0.0253846730\n",
      "[152] Validation loss: 0.1066934064\n",
      "[153] Train loss: 0.0218953199\n",
      "[153] Validation loss: 0.1083467650\n",
      "[154] Train loss: 0.0194689112\n",
      "[154] Validation loss: 0.1097308918\n",
      "[155] Train loss: 0.0171430718\n",
      "[155] Validation loss: 0.1121759157\n",
      "[156] Train loss: 0.0157929202\n",
      "[156] Validation loss: 0.1152988848\n",
      "[157] Train loss: 0.0153605356\n",
      "[157] Validation loss: 0.1183985609\n",
      "[158] Train loss: 0.0152461849\n",
      "[158] Validation loss: 0.1199974410\n",
      "[159] Train loss: 0.0150612541\n",
      "[159] Validation loss: 0.1211790215\n",
      "[160] Train loss: 0.0143784630\n",
      "[160] Validation loss: 0.1240233046\n",
      "[161] Train loss: 0.0143892288\n",
      "[161] Validation loss: 0.1275697311\n",
      "[162] Train loss: 0.0148738422\n",
      "[162] Validation loss: 0.1306214738\n",
      "[163] Train loss: 0.0161772391\n",
      "[163] Validation loss: 0.1319316216\n",
      "[164] Train loss: 0.0180008316\n",
      "[164] Validation loss: 0.1329382950\n",
      "[165] Train loss: 0.0199612732\n",
      "[165] Validation loss: 0.1323413649\n",
      "[166] Train loss: 0.0214516832\n",
      "[166] Validation loss: 0.1283507716\n",
      "[167] Train loss: 0.0231656156\n",
      "[167] Validation loss: 0.1220786361\n",
      "[168] Train loss: 0.0242604699\n",
      "[168] Validation loss: 0.1147248890\n",
      "[169] Train loss: 0.0260167713\n",
      "[169] Validation loss: 0.1083756231\n",
      "[170] Train loss: 0.0280093303\n",
      "[170] Validation loss: 0.1074765403\n",
      "[171] Train loss: 0.0303994297\n",
      "[171] Validation loss: 0.1075231178\n",
      "[172] Train loss: 0.0329017630\n",
      "[172] Validation loss: 0.1123662826\n",
      "[173] Train loss: 0.0340100426\n",
      "[173] Validation loss: 0.1190573043\n",
      "[174] Train loss: 0.0382649268\n",
      "[174] Validation loss: 0.1273732220\n",
      "[175] Train loss: 0.0413072602\n",
      "[175] Validation loss: 0.1392404278\n",
      "[176] Train loss: 0.0454799915\n",
      "[176] Validation loss: 0.1481979738\n",
      "[177] Train loss: 0.0472911505\n",
      "[177] Validation loss: 0.1404389029\n",
      "[178] Train loss: 0.0472247191\n",
      "[178] Validation loss: 0.1267893255\n",
      "[179] Train loss: 0.0457133070\n",
      "[179] Validation loss: 0.1254297723\n",
      "[180] Train loss: 0.0493336562\n",
      "[180] Validation loss: 0.1291524253\n",
      "[181] Train loss: 0.0503596834\n",
      "[181] Validation loss: 0.1233258587\n",
      "[182] Train loss: 0.0483092444\n",
      "[182] Validation loss: 0.1269666543\n",
      "[183] Train loss: 0.0506999618\n",
      "[183] Validation loss: 0.1256760973\n",
      "[184] Train loss: 0.0527721503\n",
      "[184] Validation loss: 0.1130865177\n",
      "[185] Train loss: 0.0543332421\n",
      "[185] Validation loss: 0.1141966727\n",
      "[186] Train loss: 0.0524642692\n",
      "[186] Validation loss: 0.1106705648\n",
      "[187] Train loss: 0.0512599408\n",
      "[187] Validation loss: 0.1190157726\n",
      "[188] Train loss: 0.0617662297\n",
      "[188] Validation loss: 0.1468720040\n",
      "[189] Train loss: 0.0691989701\n",
      "[189] Validation loss: 0.1421029704\n",
      "[190] Train loss: 0.0653020717\n",
      "[190] Validation loss: 0.1281511470\n",
      "[191] Train loss: 0.0634559956\n",
      "[191] Validation loss: 0.1399837760\n",
      "[192] Train loss: 0.0625583776\n",
      "[192] Validation loss: 0.1873486317\n",
      "[193] Train loss: 0.0715295862\n",
      "[193] Validation loss: 0.1780674390\n",
      "[194] Train loss: 0.0826112154\n",
      "[194] Validation loss: 0.1462156469\n",
      "[195] Train loss: 0.0917785635\n",
      "[195] Validation loss: 0.1422606923\n",
      "[196] Train loss: 0.0926320958\n",
      "[196] Validation loss: 0.1440953331\n",
      "[197] Train loss: 0.0850963128\n",
      "[197] Validation loss: 0.1197712016\n",
      "[198] Train loss: 0.0758008582\n",
      "[198] Validation loss: 0.1133153429\n",
      "[199] Train loss: 0.0639660774\n",
      "[199] Validation loss: 0.1182658775\n",
      "[200] Train loss: 0.0532950740\n",
      "[200] Validation loss: 0.1151988535\n",
      "4 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 1.7747326121\n",
      "[1] Validation loss: 0.2286674450\n",
      "model saved\n",
      "[2] Train loss: 0.7087911237\n",
      "[2] Validation loss: 0.2199901151\n",
      "model saved\n",
      "[3] Train loss: 0.3952666586\n",
      "[3] Validation loss: 0.2062104382\n",
      "model saved\n",
      "[4] Train loss: 0.3314299486\n",
      "[4] Validation loss: 0.1956209978\n",
      "model saved\n",
      "[5] Train loss: 0.3830556055\n",
      "[5] Validation loss: 0.1759135723\n",
      "model saved\n",
      "[6] Train loss: 0.4155230408\n",
      "[6] Validation loss: 0.4286766597\n",
      "[7] Train loss: 0.6870437765\n",
      "[7] Validation loss: 0.5754566267\n",
      "[8] Train loss: 0.9402206040\n",
      "[8] Validation loss: 0.2231042078\n",
      "[9] Train loss: 0.7285416287\n",
      "[9] Validation loss: 0.1417888054\n",
      "model saved\n",
      "[10] Train loss: 0.3172435869\n",
      "[10] Validation loss: 0.1914633000\n",
      "[11] Train loss: 0.1752286071\n",
      "[11] Validation loss: 0.1701230877\n",
      "[12] Train loss: 0.1410947012\n",
      "[12] Validation loss: 0.1375630777\n",
      "model saved\n",
      "[13] Train loss: 0.1339095149\n",
      "[13] Validation loss: 0.1264817691\n",
      "model saved\n",
      "[14] Train loss: 0.1340242224\n",
      "[14] Validation loss: 0.1177597023\n",
      "model saved\n",
      "[15] Train loss: 0.1295676744\n",
      "[15] Validation loss: 0.1176687109\n",
      "model saved\n",
      "[16] Train loss: 0.1303426365\n",
      "[16] Validation loss: 0.1430659648\n",
      "[17] Train loss: 0.1536582201\n",
      "[17] Validation loss: 0.1766954181\n",
      "[18] Train loss: 0.1847635806\n",
      "[18] Validation loss: 0.1654710679\n",
      "[19] Train loss: 0.2109318561\n",
      "[19] Validation loss: 0.1050991282\n",
      "model saved\n",
      "[20] Train loss: 0.2105051505\n",
      "[20] Validation loss: 0.1202149678\n",
      "[21] Train loss: 0.2062334860\n",
      "[21] Validation loss: 0.1801100653\n",
      "[22] Train loss: 0.2244230018\n",
      "[22] Validation loss: 0.1368424525\n",
      "[23] Train loss: 0.1906797930\n",
      "[23] Validation loss: 0.0903972159\n",
      "model saved\n",
      "[24] Train loss: 0.1436767405\n",
      "[24] Validation loss: 0.1086714801\n",
      "[25] Train loss: 0.1148002269\n",
      "[25] Validation loss: 0.1354512270\n",
      "[26] Train loss: 0.0978178857\n",
      "[26] Validation loss: 0.1508292595\n",
      "[27] Train loss: 0.0945213451\n",
      "[27] Validation loss: 0.1406915195\n",
      "[28] Train loss: 0.0936991541\n",
      "[28] Validation loss: 0.1357997259\n",
      "[29] Train loss: 0.0958085622\n",
      "[29] Validation loss: 0.1480656627\n",
      "[30] Train loss: 0.0965976886\n",
      "[30] Validation loss: 0.1633079755\n",
      "[31] Train loss: 0.0907832761\n",
      "[31] Validation loss: 0.1662809714\n",
      "[32] Train loss: 0.0843968953\n",
      "[32] Validation loss: 0.1632614303\n",
      "[33] Train loss: 0.0833629942\n",
      "[33] Validation loss: 0.1450877141\n",
      "[34] Train loss: 0.0812568814\n",
      "[34] Validation loss: 0.1402323911\n",
      "[35] Train loss: 0.0792518251\n",
      "[35] Validation loss: 0.1714409768\n",
      "[36] Train loss: 0.0893290934\n",
      "[36] Validation loss: 0.1925576786\n",
      "[37] Train loss: 0.1109093617\n",
      "[37] Validation loss: 0.1497159193\n",
      "[38] Train loss: 0.1241913049\n",
      "[38] Validation loss: 0.1254652254\n",
      "[39] Train loss: 0.1428369160\n",
      "[39] Validation loss: 0.1697825331\n",
      "[40] Train loss: 0.1897033177\n",
      "[40] Validation loss: 0.1832328630\n",
      "[41] Train loss: 0.2151841696\n",
      "[41] Validation loss: 0.1550082606\n",
      "[42] Train loss: 0.1829430626\n",
      "[42] Validation loss: 0.1958011338\n",
      "[43] Train loss: 0.1984557104\n",
      "[43] Validation loss: 0.2095119460\n",
      "[44] Train loss: 0.1877314916\n",
      "[44] Validation loss: 0.2330331602\n",
      "[45] Train loss: 0.1691276528\n",
      "[45] Validation loss: 0.1967806672\n",
      "[46] Train loss: 0.1544717504\n",
      "[46] Validation loss: 0.1515670400\n",
      "[47] Train loss: 0.1332994198\n",
      "[47] Validation loss: 0.1441571859\n",
      "[48] Train loss: 0.1144355271\n",
      "[48] Validation loss: 0.1566476575\n",
      "[49] Train loss: 0.1119180852\n",
      "[49] Validation loss: 0.1615357923\n",
      "[50] Train loss: 0.1142588853\n",
      "[50] Validation loss: 0.1495637812\n",
      "[51] Train loss: 0.1132954797\n",
      "[51] Validation loss: 0.1544683164\n",
      "[52] Train loss: 0.1097235639\n",
      "[52] Validation loss: 0.1647169206\n",
      "[53] Train loss: 0.1066437079\n",
      "[53] Validation loss: 0.1655671381\n",
      "[54] Train loss: 0.1111398172\n",
      "[54] Validation loss: 0.1531838143\n",
      "[55] Train loss: 0.1176082236\n",
      "[55] Validation loss: 0.1377243050\n",
      "[56] Train loss: 0.1203705268\n",
      "[56] Validation loss: 0.1222052670\n",
      "[57] Train loss: 0.1201186402\n",
      "[57] Validation loss: 0.1052731161\n",
      "[58] Train loss: 0.1133093251\n",
      "[58] Validation loss: 0.0989081573\n",
      "[59] Train loss: 0.1034606031\n",
      "[59] Validation loss: 0.0975632658\n",
      "[60] Train loss: 0.0926685602\n",
      "[60] Validation loss: 0.0975814548\n",
      "[61] Train loss: 0.0844841407\n",
      "[61] Validation loss: 0.0970642136\n",
      "[62] Train loss: 0.0803837601\n",
      "[62] Validation loss: 0.1032559269\n",
      "[63] Train loss: 0.0820311180\n",
      "[63] Validation loss: 0.1179296316\n",
      "[64] Train loss: 0.0857543186\n",
      "[64] Validation loss: 0.1336471549\n",
      "[65] Train loss: 0.0864196781\n",
      "[65] Validation loss: 0.1450352604\n",
      "[66] Train loss: 0.0836000394\n",
      "[66] Validation loss: 0.1600642570\n",
      "[67] Train loss: 0.0778563489\n",
      "[67] Validation loss: 0.1692080320\n",
      "[68] Train loss: 0.0769032738\n",
      "[68] Validation loss: 0.1681996849\n",
      "[69] Train loss: 0.0737862633\n",
      "[69] Validation loss: 0.1534577098\n",
      "[70] Train loss: 0.0748416249\n",
      "[70] Validation loss: 0.1297424964\n",
      "[71] Train loss: 0.0718164991\n",
      "[71] Validation loss: 0.1118399522\n",
      "[72] Train loss: 0.0702573188\n",
      "[72] Validation loss: 0.1059437280\n",
      "[73] Train loss: 0.0733657281\n",
      "[73] Validation loss: 0.1103462457\n",
      "[74] Train loss: 0.0788433730\n",
      "[74] Validation loss: 0.1188644898\n",
      "[75] Train loss: 0.0871516552\n",
      "[75] Validation loss: 0.1177595707\n",
      "[76] Train loss: 0.0944824223\n",
      "[76] Validation loss: 0.1120803303\n",
      "[77] Train loss: 0.0983101191\n",
      "[77] Validation loss: 0.1221090055\n",
      "[78] Train loss: 0.1009911635\n",
      "[78] Validation loss: 0.1409613865\n",
      "[79] Train loss: 0.1137243354\n",
      "[79] Validation loss: 0.1524181277\n",
      "[80] Train loss: 0.1187228345\n",
      "[80] Validation loss: 0.1345825037\n",
      "[81] Train loss: 0.1082080732\n",
      "[81] Validation loss: 0.1251272671\n",
      "[82] Train loss: 0.0902262802\n",
      "[82] Validation loss: 0.1314811618\n",
      "[83] Train loss: 0.0791714818\n",
      "[83] Validation loss: 0.1246202833\n",
      "[84] Train loss: 0.0707254931\n",
      "[84] Validation loss: 0.1042526530\n",
      "[85] Train loss: 0.0566281536\n",
      "[85] Validation loss: 0.0959913933\n",
      "[86] Train loss: 0.0487722117\n",
      "[86] Validation loss: 0.0929832272\n",
      "[87] Train loss: 0.0461358550\n",
      "[87] Validation loss: 0.0900316897\n",
      "model saved\n",
      "[88] Train loss: 0.0447391330\n",
      "[88] Validation loss: 0.0910536307\n",
      "[89] Train loss: 0.0465383581\n",
      "[89] Validation loss: 0.0914738073\n",
      "[90] Train loss: 0.0465304752\n",
      "[90] Validation loss: 0.0910154453\n",
      "[91] Train loss: 0.0455893788\n",
      "[91] Validation loss: 0.0922604979\n",
      "[92] Train loss: 0.0442531632\n",
      "[92] Validation loss: 0.0944892215\n",
      "[93] Train loss: 0.0441373772\n",
      "[93] Validation loss: 0.0936943732\n",
      "[94] Train loss: 0.0462993057\n",
      "[94] Validation loss: 0.0914280849\n",
      "[95] Train loss: 0.0485012470\n",
      "[95] Validation loss: 0.0864500272\n",
      "model saved\n",
      "[96] Train loss: 0.0524277666\n",
      "[96] Validation loss: 0.0815154695\n",
      "model saved\n",
      "[97] Train loss: 0.0578824352\n",
      "[97] Validation loss: 0.0839333220\n",
      "[98] Train loss: 0.0651216062\n",
      "[98] Validation loss: 0.0930792439\n",
      "[99] Train loss: 0.0701497075\n",
      "[99] Validation loss: 0.1071528267\n",
      "[100] Train loss: 0.0775883659\n",
      "[100] Validation loss: 0.1229406821\n",
      "[101] Train loss: 0.0858943773\n",
      "[101] Validation loss: 0.1178232677\n",
      "[102] Train loss: 0.0866148670\n",
      "[102] Validation loss: 0.1023459474\n",
      "[103] Train loss: 0.0862051540\n",
      "[103] Validation loss: 0.0888110350\n",
      "[104] Train loss: 0.0892352906\n",
      "[104] Validation loss: 0.0776467362\n",
      "model saved\n",
      "[105] Train loss: 0.0855262894\n",
      "[105] Validation loss: 0.0674896115\n",
      "model saved\n",
      "[106] Train loss: 0.0711856063\n",
      "[106] Validation loss: 0.0641166364\n",
      "model saved\n",
      "[107] Train loss: 0.0564943842\n",
      "[107] Validation loss: 0.0716107741\n",
      "[108] Train loss: 0.0515592607\n",
      "[108] Validation loss: 0.0713233204\n",
      "[109] Train loss: 0.0494407124\n",
      "[109] Validation loss: 0.0610061968\n",
      "model saved\n",
      "[110] Train loss: 0.0438130103\n",
      "[110] Validation loss: 0.0617116264\n",
      "[111] Train loss: 0.0410002485\n",
      "[111] Validation loss: 0.0648487334\n",
      "[112] Train loss: 0.0389310442\n",
      "[112] Validation loss: 0.0625630334\n",
      "[113] Train loss: 0.0350015750\n",
      "[113] Validation loss: 0.0637343696\n",
      "[114] Train loss: 0.0332738908\n",
      "[114] Validation loss: 0.0649957806\n",
      "[115] Train loss: 0.0350761427\n",
      "[115] Validation loss: 0.0620671481\n",
      "[116] Train loss: 0.0353457053\n",
      "[116] Validation loss: 0.0663299253\n",
      "[117] Train loss: 0.0357248455\n",
      "[117] Validation loss: 0.0775751980\n",
      "[118] Train loss: 0.0408542636\n",
      "[118] Validation loss: 0.0831807533\n",
      "[119] Train loss: 0.0462616859\n",
      "[119] Validation loss: 0.0811860324\n",
      "[120] Train loss: 0.0503267676\n",
      "[120] Validation loss: 0.0734719562\n",
      "[121] Train loss: 0.0637381609\n",
      "[121] Validation loss: 0.0725713011\n",
      "[122] Train loss: 0.0818213749\n",
      "[122] Validation loss: 0.0846387200\n",
      "[123] Train loss: 0.0980685206\n",
      "[123] Validation loss: 0.1097484885\n",
      "[124] Train loss: 0.1149104034\n",
      "[124] Validation loss: 0.1376869495\n",
      "[125] Train loss: 0.1295031209\n",
      "[125] Validation loss: 0.1054257404\n",
      "[126] Train loss: 0.1128374637\n",
      "[126] Validation loss: 0.0730806733\n",
      "[127] Train loss: 0.0902561910\n",
      "[127] Validation loss: 0.0884815850\n",
      "[128] Train loss: 0.0811120775\n",
      "[128] Validation loss: 0.1213116859\n",
      "[129] Train loss: 0.0827573906\n",
      "[129] Validation loss: 0.1217202109\n",
      "[130] Train loss: 0.0919107530\n",
      "[130] Validation loss: 0.1021034259\n",
      "[131] Train loss: 0.1014956806\n",
      "[131] Validation loss: 0.0977652823\n",
      "[132] Train loss: 0.1195478538\n",
      "[132] Validation loss: 0.0978550485\n",
      "[133] Train loss: 0.1407904215\n",
      "[133] Validation loss: 0.0835787704\n",
      "[134] Train loss: 0.1598662793\n",
      "[134] Validation loss: 0.0684178383\n",
      "[135] Train loss: 0.1746463208\n",
      "[135] Validation loss: 0.0882899895\n",
      "[136] Train loss: 0.1807115672\n",
      "[136] Validation loss: 0.1260813181\n",
      "[137] Train loss: 0.1732803531\n",
      "[137] Validation loss: 0.1219914169\n",
      "[138] Train loss: 0.1495591683\n",
      "[138] Validation loss: 0.0932079956\n",
      "[139] Train loss: 0.1200299989\n",
      "[139] Validation loss: 0.0693385017\n",
      "[140] Train loss: 0.0898374908\n",
      "[140] Validation loss: 0.0567020837\n",
      "model saved\n",
      "[141] Train loss: 0.0637724621\n",
      "[141] Validation loss: 0.0572222467\n",
      "[142] Train loss: 0.0464212960\n",
      "[142] Validation loss: 0.0663827042\n",
      "[143] Train loss: 0.0402161515\n",
      "[143] Validation loss: 0.0632602564\n",
      "[144] Train loss: 0.0329577755\n",
      "[144] Validation loss: 0.0610025576\n",
      "[145] Train loss: 0.0318276303\n",
      "[145] Validation loss: 0.0630801891\n",
      "[146] Train loss: 0.0279998417\n",
      "[146] Validation loss: 0.0630813748\n",
      "[147] Train loss: 0.0282415270\n",
      "[147] Validation loss: 0.0708220742\n",
      "[148] Train loss: 0.0257427587\n",
      "[148] Validation loss: 0.0807101680\n",
      "[149] Train loss: 0.0260783419\n",
      "[149] Validation loss: 0.0746581601\n",
      "[150] Train loss: 0.0276307204\n",
      "[150] Validation loss: 0.0759562593\n",
      "[151] Train loss: 0.0293727611\n",
      "[151] Validation loss: 0.0885516235\n",
      "[152] Train loss: 0.0282017406\n",
      "[152] Validation loss: 0.0955957634\n",
      "[153] Train loss: 0.0303503331\n",
      "[153] Validation loss: 0.0860871368\n",
      "[154] Train loss: 0.0303838182\n",
      "[154] Validation loss: 0.0881974701\n",
      "[155] Train loss: 0.0294923269\n",
      "[155] Validation loss: 0.0904821765\n",
      "[156] Train loss: 0.0305032228\n",
      "[156] Validation loss: 0.0843284283\n",
      "[157] Train loss: 0.0303030613\n",
      "[157] Validation loss: 0.0773624345\n",
      "[158] Train loss: 0.0310600052\n",
      "[158] Validation loss: 0.0757428939\n",
      "[159] Train loss: 0.0322283815\n",
      "[159] Validation loss: 0.0777878767\n",
      "[160] Train loss: 0.0336161519\n",
      "[160] Validation loss: 0.0805600173\n",
      "[161] Train loss: 0.0345550088\n",
      "[161] Validation loss: 0.0765380075\n",
      "[162] Train loss: 0.0363286384\n",
      "[162] Validation loss: 0.0697373266\n",
      "[163] Train loss: 0.0364777303\n",
      "[163] Validation loss: 0.0696671733\n",
      "[164] Train loss: 0.0351533401\n",
      "[164] Validation loss: 0.0800092480\n",
      "[165] Train loss: 0.0363199530\n",
      "[165] Validation loss: 0.0832243785\n",
      "[166] Train loss: 0.0397752597\n",
      "[166] Validation loss: 0.0785216770\n",
      "[167] Train loss: 0.0436760078\n",
      "[167] Validation loss: 0.0797062548\n",
      "[168] Train loss: 0.0396141023\n",
      "[168] Validation loss: 0.0810739426\n",
      "[169] Train loss: 0.0380626650\n",
      "[169] Validation loss: 0.0712702197\n",
      "[170] Train loss: 0.0332666553\n",
      "[170] Validation loss: 0.0663524073\n",
      "[171] Train loss: 0.0256726432\n",
      "[171] Validation loss: 0.0651042227\n",
      "[172] Train loss: 0.0226258399\n",
      "[172] Validation loss: 0.0652951963\n",
      "[173] Train loss: 0.0215342703\n",
      "[173] Validation loss: 0.0631699578\n",
      "[174] Train loss: 0.0212954615\n",
      "[174] Validation loss: 0.0602186945\n",
      "[175] Train loss: 0.0201347141\n",
      "[175] Validation loss: 0.0641137767\n",
      "[176] Train loss: 0.0210217255\n",
      "[176] Validation loss: 0.0692511095\n",
      "[177] Train loss: 0.0230176357\n",
      "[177] Validation loss: 0.0717760089\n",
      "[178] Train loss: 0.0239819931\n",
      "[178] Validation loss: 0.0821748889\n",
      "[179] Train loss: 0.0241495022\n",
      "[179] Validation loss: 0.0945125959\n",
      "[180] Train loss: 0.0281689176\n",
      "[180] Validation loss: 0.0825079582\n",
      "[181] Train loss: 0.0290800292\n",
      "[181] Validation loss: 0.0685661046\n",
      "[182] Train loss: 0.0283905448\n",
      "[182] Validation loss: 0.0648360007\n",
      "[183] Train loss: 0.0347675050\n",
      "[183] Validation loss: 0.0686880343\n",
      "[184] Train loss: 0.0351622117\n",
      "[184] Validation loss: 0.0733840040\n",
      "[185] Train loss: 0.0321280002\n",
      "[185] Validation loss: 0.0733408083\n",
      "[186] Train loss: 0.0315745494\n",
      "[186] Validation loss: 0.0667630041\n",
      "[187] Train loss: 0.0341791710\n",
      "[187] Validation loss: 0.0599709261\n",
      "[188] Train loss: 0.0333109368\n",
      "[188] Validation loss: 0.0604125714\n",
      "[189] Train loss: 0.0267953561\n",
      "[189] Validation loss: 0.0630995613\n",
      "[190] Train loss: 0.0224233443\n",
      "[190] Validation loss: 0.0692730310\n",
      "[191] Train loss: 0.0211037361\n",
      "[191] Validation loss: 0.0674283981\n",
      "[192] Train loss: 0.0210514867\n",
      "[192] Validation loss: 0.0647900203\n",
      "[193] Train loss: 0.0219219027\n",
      "[193] Validation loss: 0.0613466875\n",
      "[194] Train loss: 0.0219151582\n",
      "[194] Validation loss: 0.0606498232\n",
      "[195] Train loss: 0.0238037766\n",
      "[195] Validation loss: 0.0547007580\n",
      "model saved\n",
      "[196] Train loss: 0.0229931822\n",
      "[196] Validation loss: 0.0552427493\n",
      "[197] Train loss: 0.0229242259\n",
      "[197] Validation loss: 0.0610978274\n",
      "[198] Train loss: 0.0248435866\n",
      "[198] Validation loss: 0.0617154336\n",
      "[199] Train loss: 0.0217888934\n",
      "[199] Validation loss: 0.0631969534\n",
      "[200] Train loss: 0.0210183167\n",
      "[200] Validation loss: 0.0678652363\n",
      "5 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch import optim\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=41)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    model = Regressor()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=1e-7)\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "\n",
    "    trainsets = TensorData(X_train, Y_train)\n",
    "    valsets = TensorData(X_val, Y_val)\n",
    "\n",
    "    trainloader = DataLoader(trainsets, batch_size=CFG[\"BATCH_SIZE\"])\n",
    "    valloader = DataLoader(valsets, batch_size=CFG[\"BATCH_SIZE\"])\n",
    "\n",
    "    train(model, optimizer, trainloader, valloader)\n",
    "\n",
    "    n_iter += 1\n",
    "\n",
    "    file_oldname = os.path.join(dirpath + \"best_model/\" + \"_best_model.pth\")\n",
    "    file_newname_newfile = os.path.join(dirpath + \"best_model/\" + str(n_iter) + \"_best_model.pth\")\n",
    "    os.rename(file_oldname, file_newname_newfile)\n",
    "\n",
    "    print('{} 번째, 학습데이터 크기 : {}, 검증데이터 크기 : {}'.format(n_iter, X_train.shape[0], X_val.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.clf()\n",
    "# plt.plot(loss_,'ro',label='training loss')\n",
    "plt.plot(val_loss_,'g',label='validation loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}