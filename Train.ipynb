{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This is file for train, prediction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dirpath = 'C:/Python/Used-Car-Price-Regression-DACON/'\n",
    "\n",
    "train = pd.read_csv('data/modified_train.csv')\n",
    "test = pd.read_csv('data/modified_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   title  odometer  location  isimported  engine  transmission  fuel  paint  \\\n0    147     18277         0           0       3             0     0      0   \n1     93        10         0           2       3             0     0     10   \n2     55     83091         0           0       4             0     0      0   \n3    122     91524         0           0       3             0     0      6   \n4    116     94177         0           0       4             0     0      0   \n\n   year  brand    target  \n0  2016     36  13665000  \n1  2019     36  33015000  \n2  2012     31   9915000  \n3  2007      6   3815000  \n4  2010     36   7385000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>odometer</th>\n      <th>location</th>\n      <th>isimported</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>paint</th>\n      <th>year</th>\n      <th>brand</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>147</td>\n      <td>18277</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>36</td>\n      <td>13665000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>36</td>\n      <td>33015000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>83091</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2012</td>\n      <td>31</td>\n      <td>9915000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>122</td>\n      <td>91524</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>6</td>\n      <td>3815000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>94177</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010</td>\n      <td>36</td>\n      <td>7385000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   title  odometer  location  isimported  engine  transmission  fuel  paint  \\\n0     14      1234         1           2       3             0     0     11   \n1     88     29938         1           0       3             0     0     11   \n2     29     87501         0           0       3             0     0     10   \n3     91    180894         0           1       4             0     0      6   \n4     17    104814         0           0       3             0     0     11   \n\n   year  brand  \n0  2017     34  \n1  2013     14  \n2  2012     34  \n3  2001     36  \n4  2000     36  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>odometer</th>\n      <th>location</th>\n      <th>isimported</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>paint</th>\n      <th>year</th>\n      <th>brand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>1234</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2017</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>88</td>\n      <td>29938</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2013</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>87501</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2012</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>91</td>\n      <td>180894</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2001</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>104814</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2000</td>\n      <td>36</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Y = train[ ['target'] ].values\n",
    "X = train[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((1015, 10), (1015, 1))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "\n",
    "scalerY = MinMaxScaler()\n",
    "scalerY.fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':200,\n",
    "    'BATCH_SIZE':16,\n",
    "    'LEARNING_RATE' :3e-4\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(10, 64, bias=False),\n",
    "            nn.BatchNorm1d(64, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64, 128, bias=False),\n",
    "            nn.BatchNorm1d(128, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 256, bias=False),\n",
    "            nn.BatchNorm1d(256, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Linear(256, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loss_ = [] # loss 저장할 리스트\n",
    "val_loss_ = [] # val loss 저장할 리스트\n",
    "\n",
    "def train(model, optimizer, trainloader, valloader):\n",
    "    best_loss = 1000 # to save best model\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, CFG[\"EPOCHS\"]+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, values = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, values)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss))\n",
    "        loss_.append(running_loss)\n",
    "\n",
    "        #validation set evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서.\n",
    "        actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서.\n",
    "\n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for i, data in enumerate(valloader, 0): # enumerate(인자, index)\n",
    "                inputs, values = data\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, values)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print('[%d] Validation loss: %.10f' %(epoch, val_loss))\n",
    "\n",
    "        if val_loss < best_loss :\n",
    "            round_val_loss = round(val_loss, 7)\n",
    "            torch.save(model.state_dict(), dirpath + \"best_model/\" + str(round_val_loss) + \"_best_model.pth\")\n",
    "            best_loss = val_loss\n",
    "            print('model saved')\n",
    "\n",
    "        val_loss_.append(val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 2.1804356547\n",
      "[1] Validation loss: 0.2290217457\n",
      "model saved\n",
      "[2] Train loss: 0.9094228935\n",
      "[2] Validation loss: 0.1809675843\n",
      "model saved\n",
      "[3] Train loss: 0.4689760723\n",
      "[3] Validation loss: 0.1673168696\n",
      "model saved\n",
      "[4] Train loss: 0.2763663386\n",
      "[4] Validation loss: 0.1757677651\n",
      "[5] Train loss: 0.1970378668\n",
      "[5] Validation loss: 0.1715036838\n",
      "[6] Train loss: 0.1801326175\n",
      "[6] Validation loss: 0.1669532920\n",
      "model saved\n",
      "[7] Train loss: 0.1583229051\n",
      "[7] Validation loss: 0.1557850027\n",
      "model saved\n",
      "[8] Train loss: 0.1715230453\n",
      "[8] Validation loss: 0.1551437140\n",
      "model saved\n",
      "[9] Train loss: 0.1982179271\n",
      "[9] Validation loss: 0.1726146187\n",
      "[10] Train loss: 0.3595398059\n",
      "[10] Validation loss: 0.2189945157\n",
      "[11] Train loss: 0.5052782926\n",
      "[11] Validation loss: 0.3437848380\n",
      "[12] Train loss: 0.8911847263\n",
      "[12] Validation loss: 0.2853718293\n",
      "[13] Train loss: 1.0607366776\n",
      "[13] Validation loss: 0.1693265117\n",
      "[14] Train loss: 0.7008953909\n",
      "[14] Validation loss: 0.2069960716\n",
      "[15] Train loss: 0.4155246124\n",
      "[15] Validation loss: 0.1151353825\n",
      "model saved\n",
      "[16] Train loss: 0.1645244698\n",
      "[16] Validation loss: 0.1003896226\n",
      "model saved\n",
      "[17] Train loss: 0.0888561239\n",
      "[17] Validation loss: 0.1015442514\n",
      "[18] Train loss: 0.0722814377\n",
      "[18] Validation loss: 0.1090416003\n",
      "[19] Train loss: 0.0676869931\n",
      "[19] Validation loss: 0.1096479250\n",
      "[20] Train loss: 0.0641942111\n",
      "[20] Validation loss: 0.1056497169\n",
      "[21] Train loss: 0.0590195198\n",
      "[21] Validation loss: 0.1002771815\n",
      "model saved\n",
      "[22] Train loss: 0.0569491986\n",
      "[22] Validation loss: 0.0956402724\n",
      "model saved\n",
      "[23] Train loss: 0.0555387765\n",
      "[23] Validation loss: 0.0929484954\n",
      "model saved\n",
      "[24] Train loss: 0.0542323501\n",
      "[24] Validation loss: 0.0936098986\n",
      "[25] Train loss: 0.0543197570\n",
      "[25] Validation loss: 0.0968055294\n",
      "[26] Train loss: 0.0570321842\n",
      "[26] Validation loss: 0.1016928190\n",
      "[27] Train loss: 0.0611067381\n",
      "[27] Validation loss: 0.1081743690\n",
      "[28] Train loss: 0.0649905394\n",
      "[28] Validation loss: 0.1155904739\n",
      "[29] Train loss: 0.0700931038\n",
      "[29] Validation loss: 0.1231388941\n",
      "[30] Train loss: 0.0724281278\n",
      "[30] Validation loss: 0.1318295279\n",
      "[31] Train loss: 0.0734136261\n",
      "[31] Validation loss: 0.1416267963\n",
      "[32] Train loss: 0.0768890814\n",
      "[32] Validation loss: 0.1488247933\n",
      "[33] Train loss: 0.0923703830\n",
      "[33] Validation loss: 0.1451495017\n",
      "[34] Train loss: 0.1306490469\n",
      "[34] Validation loss: 0.1388724607\n",
      "[35] Train loss: 0.1967670190\n",
      "[35] Validation loss: 0.1620896138\n",
      "[36] Train loss: 0.2733683444\n",
      "[36] Validation loss: 0.2064366767\n",
      "[37] Train loss: 0.3295122825\n",
      "[37] Validation loss: 0.1732280604\n",
      "[38] Train loss: 0.3297464488\n",
      "[38] Validation loss: 0.1330778420\n",
      "[39] Train loss: 0.2544139719\n",
      "[39] Validation loss: 0.1328912638\n",
      "[40] Train loss: 0.2066833035\n",
      "[40] Validation loss: 0.0847275812\n",
      "model saved\n",
      "[41] Train loss: 0.1408034484\n",
      "[41] Validation loss: 0.0821237505\n",
      "model saved\n",
      "[42] Train loss: 0.1031454475\n",
      "[42] Validation loss: 0.0891379369\n",
      "[43] Train loss: 0.0901282907\n",
      "[43] Validation loss: 0.0835418389\n",
      "[44] Train loss: 0.0744573144\n",
      "[44] Validation loss: 0.0736615935\n",
      "model saved\n",
      "[45] Train loss: 0.0633602796\n",
      "[45] Validation loss: 0.0698509982\n",
      "model saved\n",
      "[46] Train loss: 0.0602898674\n",
      "[46] Validation loss: 0.0697796629\n",
      "model saved\n",
      "[47] Train loss: 0.0600923951\n",
      "[47] Validation loss: 0.0693311599\n",
      "model saved\n",
      "[48] Train loss: 0.0557501974\n",
      "[48] Validation loss: 0.0713888892\n",
      "[49] Train loss: 0.0483042646\n",
      "[49] Validation loss: 0.0772294098\n",
      "[50] Train loss: 0.0429222695\n",
      "[50] Validation loss: 0.0849023416\n",
      "[51] Train loss: 0.0411488219\n",
      "[51] Validation loss: 0.0891528339\n",
      "[52] Train loss: 0.0384725774\n",
      "[52] Validation loss: 0.0901888267\n",
      "[53] Train loss: 0.0332762966\n",
      "[53] Validation loss: 0.0895383538\n",
      "[54] Train loss: 0.0309984966\n",
      "[54] Validation loss: 0.0871770710\n",
      "[55] Train loss: 0.0347499534\n",
      "[55] Validation loss: 0.0820786615\n",
      "[56] Train loss: 0.0421505802\n",
      "[56] Validation loss: 0.0761841650\n",
      "[57] Train loss: 0.0449013085\n",
      "[57] Validation loss: 0.0748764467\n",
      "[58] Train loss: 0.0453304978\n",
      "[58] Validation loss: 0.0861754852\n",
      "[59] Train loss: 0.0550370954\n",
      "[59] Validation loss: 0.0993779881\n",
      "[60] Train loss: 0.0862028056\n",
      "[60] Validation loss: 0.0842950746\n",
      "[61] Train loss: 0.1020336072\n",
      "[61] Validation loss: 0.0688543853\n",
      "model saved\n",
      "[62] Train loss: 0.0910334020\n",
      "[62] Validation loss: 0.0956755163\n",
      "[63] Train loss: 0.1066533399\n",
      "[63] Validation loss: 0.1244442831\n",
      "[64] Train loss: 0.1475407497\n",
      "[64] Validation loss: 0.0900977937\n",
      "[65] Train loss: 0.1280730025\n",
      "[65] Validation loss: 0.0775739317\n",
      "[66] Train loss: 0.0767149348\n",
      "[66] Validation loss: 0.0729986143\n",
      "[67] Train loss: 0.0764298875\n",
      "[67] Validation loss: 0.0703251498\n",
      "[68] Train loss: 0.0502756682\n",
      "[68] Validation loss: 0.0817779644\n",
      "[69] Train loss: 0.0430794714\n",
      "[69] Validation loss: 0.0797893600\n",
      "[70] Train loss: 0.0380976293\n",
      "[70] Validation loss: 0.0764670017\n",
      "[71] Train loss: 0.0329918121\n",
      "[71] Validation loss: 0.0753985657\n",
      "[72] Train loss: 0.0344039651\n",
      "[72] Validation loss: 0.0716195077\n",
      "[73] Train loss: 0.0347221867\n",
      "[73] Validation loss: 0.0703970568\n",
      "[74] Train loss: 0.0349805979\n",
      "[74] Validation loss: 0.0804938434\n",
      "[75] Train loss: 0.0429425743\n",
      "[75] Validation loss: 0.0968393577\n",
      "[76] Train loss: 0.0493129164\n",
      "[76] Validation loss: 0.1003594695\n",
      "[77] Train loss: 0.0469689464\n",
      "[77] Validation loss: 0.0857481072\n",
      "[78] Train loss: 0.0501195239\n",
      "[78] Validation loss: 0.0690077834\n",
      "[79] Train loss: 0.0531014236\n",
      "[79] Validation loss: 0.0680591132\n",
      "model saved\n",
      "[80] Train loss: 0.0527493918\n",
      "[80] Validation loss: 0.0818307158\n",
      "[81] Train loss: 0.0594084510\n",
      "[81] Validation loss: 0.0843889227\n",
      "[82] Train loss: 0.0678512318\n",
      "[82] Validation loss: 0.0722566299\n",
      "[83] Train loss: 0.0625773392\n",
      "[83] Validation loss: 0.0711456981\n",
      "[84] Train loss: 0.0653704189\n",
      "[84] Validation loss: 0.0717186753\n",
      "[85] Train loss: 0.0715981443\n",
      "[85] Validation loss: 0.0682641111\n",
      "[86] Train loss: 0.0555801106\n",
      "[86] Validation loss: 0.0763690795\n",
      "[87] Train loss: 0.0524248483\n",
      "[87] Validation loss: 0.0833626040\n",
      "[88] Train loss: 0.0671288855\n",
      "[88] Validation loss: 0.0783958129\n",
      "[89] Train loss: 0.0537713352\n",
      "[89] Validation loss: 0.0745716548\n",
      "[90] Train loss: 0.0428655279\n",
      "[90] Validation loss: 0.0704061477\n",
      "[91] Train loss: 0.0533685966\n",
      "[91] Validation loss: 0.0714639107\n",
      "[92] Train loss: 0.0523024182\n",
      "[92] Validation loss: 0.0812847036\n",
      "[93] Train loss: 0.0539523401\n",
      "[93] Validation loss: 0.0799784708\n",
      "[94] Train loss: 0.0741354996\n",
      "[94] Validation loss: 0.0759989019\n",
      "[95] Train loss: 0.0833661485\n",
      "[95] Validation loss: 0.0862837089\n",
      "[96] Train loss: 0.0739539267\n",
      "[96] Validation loss: 0.0806645415\n",
      "[97] Train loss: 0.0683558582\n",
      "[97] Validation loss: 0.0802021341\n",
      "[98] Train loss: 0.0557801415\n",
      "[98] Validation loss: 0.0822515104\n",
      "[99] Train loss: 0.0478732302\n",
      "[99] Validation loss: 0.0769230924\n",
      "[100] Train loss: 0.0467175594\n",
      "[100] Validation loss: 0.0762958811\n",
      "[101] Train loss: 0.0466109708\n",
      "[101] Validation loss: 0.0748238068\n",
      "[102] Train loss: 0.0471567350\n",
      "[102] Validation loss: 0.0726974958\n",
      "[103] Train loss: 0.0413698344\n",
      "[103] Validation loss: 0.0762836725\n",
      "[104] Train loss: 0.0446284631\n",
      "[104] Validation loss: 0.0804077106\n",
      "[105] Train loss: 0.0575091619\n",
      "[105] Validation loss: 0.0800075191\n",
      "[106] Train loss: 0.0602178873\n",
      "[106] Validation loss: 0.0794084772\n",
      "[107] Train loss: 0.0547432064\n",
      "[107] Validation loss: 0.0881698785\n",
      "[108] Train loss: 0.0569710323\n",
      "[108] Validation loss: 0.0976927027\n",
      "[109] Train loss: 0.0685672955\n",
      "[109] Validation loss: 0.0916453610\n",
      "[110] Train loss: 0.0729133261\n",
      "[110] Validation loss: 0.0769139661\n",
      "[111] Train loss: 0.0690005671\n",
      "[111] Validation loss: 0.0740727980\n",
      "[112] Train loss: 0.0761626736\n",
      "[112] Validation loss: 0.0700703364\n",
      "[113] Train loss: 0.0857068484\n",
      "[113] Validation loss: 0.0724030692\n",
      "[114] Train loss: 0.0668601677\n",
      "[114] Validation loss: 0.0994851476\n",
      "[115] Train loss: 0.0672885959\n",
      "[115] Validation loss: 0.0959880608\n",
      "[116] Train loss: 0.0719226231\n",
      "[116] Validation loss: 0.0758953152\n",
      "[117] Train loss: 0.0516167191\n",
      "[117] Validation loss: 0.0717814949\n",
      "[118] Train loss: 0.0518005850\n",
      "[118] Validation loss: 0.0638257356\n",
      "model saved\n",
      "[119] Train loss: 0.0426303928\n",
      "[119] Validation loss: 0.0707446398\n",
      "[120] Train loss: 0.0331483803\n",
      "[120] Validation loss: 0.0708223231\n",
      "[121] Train loss: 0.0356574191\n",
      "[121] Validation loss: 0.0623327869\n",
      "model saved\n",
      "[122] Train loss: 0.0252575083\n",
      "[122] Validation loss: 0.0643205207\n",
      "[123] Train loss: 0.0251715623\n",
      "[123] Validation loss: 0.0717402649\n",
      "[124] Train loss: 0.0252477354\n",
      "[124] Validation loss: 0.0874203694\n",
      "[125] Train loss: 0.0272724952\n",
      "[125] Validation loss: 0.0864538284\n",
      "[126] Train loss: 0.0314993407\n",
      "[126] Validation loss: 0.0745082371\n",
      "[127] Train loss: 0.0294062276\n",
      "[127] Validation loss: 0.0704526586\n",
      "[128] Train loss: 0.0326805728\n",
      "[128] Validation loss: 0.0721435563\n",
      "[129] Train loss: 0.0414848090\n",
      "[129] Validation loss: 0.0886292733\n",
      "[130] Train loss: 0.0400408491\n",
      "[130] Validation loss: 0.0925377231\n",
      "[131] Train loss: 0.0501969850\n",
      "[131] Validation loss: 0.0762049365\n",
      "[132] Train loss: 0.0459396631\n",
      "[132] Validation loss: 0.0736181038\n",
      "[133] Train loss: 0.0459725980\n",
      "[133] Validation loss: 0.0791757787\n",
      "[134] Train loss: 0.0599318500\n",
      "[134] Validation loss: 0.1043389688\n",
      "[135] Train loss: 0.0545041996\n",
      "[135] Validation loss: 0.0961395968\n",
      "[136] Train loss: 0.0635093108\n",
      "[136] Validation loss: 0.0799643144\n",
      "[137] Train loss: 0.0504934132\n",
      "[137] Validation loss: 0.0842904592\n",
      "[138] Train loss: 0.0537684395\n",
      "[138] Validation loss: 0.0896905727\n",
      "[139] Train loss: 0.0591150481\n",
      "[139] Validation loss: 0.0794472264\n",
      "[140] Train loss: 0.0569125947\n",
      "[140] Validation loss: 0.0754356156\n",
      "[141] Train loss: 0.0538985356\n",
      "[141] Validation loss: 0.0809803373\n",
      "[142] Train loss: 0.0619435181\n",
      "[142] Validation loss: 0.0824441131\n",
      "[143] Train loss: 0.0604423707\n",
      "[143] Validation loss: 0.0748228085\n",
      "[144] Train loss: 0.0558735179\n",
      "[144] Validation loss: 0.0686680326\n",
      "[145] Train loss: 0.0474848955\n",
      "[145] Validation loss: 0.0703636954\n",
      "[146] Train loss: 0.0583318883\n",
      "[146] Validation loss: 0.0736094468\n",
      "[147] Train loss: 0.0683054774\n",
      "[147] Validation loss: 0.0714052238\n",
      "[148] Train loss: 0.0693929746\n",
      "[148] Validation loss: 0.0755437819\n",
      "[149] Train loss: 0.0706481358\n",
      "[149] Validation loss: 0.0648284406\n",
      "[150] Train loss: 0.0544516672\n",
      "[150] Validation loss: 0.0767420414\n",
      "[151] Train loss: 0.0609181016\n",
      "[151] Validation loss: 0.0953891618\n",
      "[152] Train loss: 0.0710788600\n",
      "[152] Validation loss: 0.0978414047\n",
      "[153] Train loss: 0.0726164689\n",
      "[153] Validation loss: 0.0932782213\n",
      "[154] Train loss: 0.0751520178\n",
      "[154] Validation loss: 0.0967127664\n",
      "[155] Train loss: 0.0755915687\n",
      "[155] Validation loss: 0.1327616624\n",
      "[156] Train loss: 0.0945103303\n",
      "[156] Validation loss: 0.1405784776\n",
      "[157] Train loss: 0.1094999455\n",
      "[157] Validation loss: 0.1133074369\n",
      "[158] Train loss: 0.1233936260\n",
      "[158] Validation loss: 0.0815301753\n",
      "[159] Train loss: 0.1350063609\n",
      "[159] Validation loss: 0.0708304561\n",
      "[160] Train loss: 0.1428170701\n",
      "[160] Validation loss: 0.0763035541\n",
      "[161] Train loss: 0.1294157056\n",
      "[161] Validation loss: 0.0889662472\n",
      "[162] Train loss: 0.1031367211\n",
      "[162] Validation loss: 0.1009070282\n",
      "[163] Train loss: 0.0750975045\n",
      "[163] Validation loss: 0.0861310925\n",
      "[164] Train loss: 0.0533567727\n",
      "[164] Validation loss: 0.0683349747\n",
      "[165] Train loss: 0.0386220600\n",
      "[165] Validation loss: 0.0579432775\n",
      "model saved\n",
      "[166] Train loss: 0.0304508352\n",
      "[166] Validation loss: 0.0572261975\n",
      "model saved\n",
      "[167] Train loss: 0.0245866496\n",
      "[167] Validation loss: 0.0606255959\n",
      "[168] Train loss: 0.0203588965\n",
      "[168] Validation loss: 0.0608739321\n",
      "[169] Train loss: 0.0179907340\n",
      "[169] Validation loss: 0.0610329462\n",
      "[170] Train loss: 0.0164513969\n",
      "[170] Validation loss: 0.0616759594\n",
      "[171] Train loss: 0.0152853611\n",
      "[171] Validation loss: 0.0643926256\n",
      "[172] Train loss: 0.0146104060\n",
      "[172] Validation loss: 0.0657292522\n",
      "[173] Train loss: 0.0158493186\n",
      "[173] Validation loss: 0.0634100087\n",
      "[174] Train loss: 0.0166852704\n",
      "[174] Validation loss: 0.0574631442\n",
      "[175] Train loss: 0.0160887336\n",
      "[175] Validation loss: 0.0527580731\n",
      "model saved\n",
      "[176] Train loss: 0.0155705242\n",
      "[176] Validation loss: 0.0513194096\n",
      "model saved\n",
      "[177] Train loss: 0.0148388267\n",
      "[177] Validation loss: 0.0502025219\n",
      "model saved\n",
      "[178] Train loss: 0.0136224827\n",
      "[178] Validation loss: 0.0502298356\n",
      "[179] Train loss: 0.0124241001\n",
      "[179] Validation loss: 0.0546527146\n",
      "[180] Train loss: 0.0122602314\n",
      "[180] Validation loss: 0.0605575490\n",
      "[181] Train loss: 0.0123136736\n",
      "[181] Validation loss: 0.0637749836\n",
      "[182] Train loss: 0.0118180306\n",
      "[182] Validation loss: 0.0592092630\n",
      "[183] Train loss: 0.0122899854\n",
      "[183] Validation loss: 0.0547386114\n",
      "[184] Train loss: 0.0123943282\n",
      "[184] Validation loss: 0.0531790768\n",
      "[185] Train loss: 0.0121713325\n",
      "[185] Validation loss: 0.0537743845\n",
      "[186] Train loss: 0.0132307548\n",
      "[186] Validation loss: 0.0569249560\n",
      "[187] Train loss: 0.0154650197\n",
      "[187] Validation loss: 0.0635050065\n",
      "[188] Train loss: 0.0203080256\n",
      "[188] Validation loss: 0.0645215968\n",
      "[189] Train loss: 0.0240798582\n",
      "[189] Validation loss: 0.0651683480\n",
      "[190] Train loss: 0.0241782501\n",
      "[190] Validation loss: 0.0668717005\n",
      "[191] Train loss: 0.0289626246\n",
      "[191] Validation loss: 0.0637142699\n",
      "[192] Train loss: 0.0303242418\n",
      "[192] Validation loss: 0.0656506575\n",
      "[193] Train loss: 0.0339178036\n",
      "[193] Validation loss: 0.0632478491\n",
      "[194] Train loss: 0.0299731487\n",
      "[194] Validation loss: 0.0684753214\n",
      "[195] Train loss: 0.0289948162\n",
      "[195] Validation loss: 0.0657272332\n",
      "[196] Train loss: 0.0272352115\n",
      "[196] Validation loss: 0.0547327162\n",
      "[197] Train loss: 0.0290027947\n",
      "[197] Validation loss: 0.0528741710\n",
      "[198] Train loss: 0.0337824722\n",
      "[198] Validation loss: 0.0602872399\n",
      "[199] Train loss: 0.0349265873\n",
      "[199] Validation loss: 0.0730879577\n",
      "[200] Train loss: 0.0248398041\n",
      "[200] Validation loss: 0.0832410726\n",
      "1 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.2101774979\n",
      "[1] Validation loss: 0.0931619281\n",
      "model saved\n",
      "[2] Train loss: 0.1324710814\n",
      "[2] Validation loss: 0.0607609921\n",
      "model saved\n",
      "[3] Train loss: 0.0826298155\n",
      "[3] Validation loss: 0.0493475299\n",
      "model saved\n",
      "[4] Train loss: 0.0625799353\n",
      "[4] Validation loss: 0.0534711493\n",
      "[5] Train loss: 0.0528585696\n",
      "[5] Validation loss: 0.0629108140\n",
      "[6] Train loss: 0.0490640417\n",
      "[6] Validation loss: 0.0597054996\n",
      "[7] Train loss: 0.0432158943\n",
      "[7] Validation loss: 0.0539454356\n",
      "[8] Train loss: 0.0409206322\n",
      "[8] Validation loss: 0.0493239997\n",
      "model saved\n",
      "[9] Train loss: 0.0464280633\n",
      "[9] Validation loss: 0.0443132053\n",
      "model saved\n",
      "[10] Train loss: 0.0445855485\n",
      "[10] Validation loss: 0.0570310160\n",
      "[11] Train loss: 0.0475778496\n",
      "[11] Validation loss: 0.0650189163\n",
      "[12] Train loss: 0.0508123846\n",
      "[12] Validation loss: 0.0546196010\n",
      "[13] Train loss: 0.0645055383\n",
      "[13] Validation loss: 0.0801472835\n",
      "[14] Train loss: 0.0592361914\n",
      "[14] Validation loss: 0.0927476021\n",
      "[15] Train loss: 0.0529290090\n",
      "[15] Validation loss: 0.0551233308\n",
      "[16] Train loss: 0.0454160390\n",
      "[16] Validation loss: 0.0614130009\n",
      "[17] Train loss: 0.0414035191\n",
      "[17] Validation loss: 0.0813478988\n",
      "[18] Train loss: 0.0482279785\n",
      "[18] Validation loss: 0.0466357126\n",
      "[19] Train loss: 0.0345469165\n",
      "[19] Validation loss: 0.0448030882\n",
      "[20] Train loss: 0.0354169710\n",
      "[20] Validation loss: 0.0405331994\n",
      "model saved\n",
      "[21] Train loss: 0.0321054554\n",
      "[21] Validation loss: 0.0736776827\n",
      "[22] Train loss: 0.0331483749\n",
      "[22] Validation loss: 0.0557491257\n",
      "[23] Train loss: 0.0326260055\n",
      "[23] Validation loss: 0.0393806142\n",
      "model saved\n",
      "[24] Train loss: 0.0322029549\n",
      "[24] Validation loss: 0.0490396288\n",
      "[25] Train loss: 0.0382251111\n",
      "[25] Validation loss: 0.0445514560\n",
      "[26] Train loss: 0.0354225646\n",
      "[26] Validation loss: 0.0483592660\n",
      "[27] Train loss: 0.0340967461\n",
      "[27] Validation loss: 0.0572580964\n",
      "[28] Train loss: 0.0353052702\n",
      "[28] Validation loss: 0.0786495816\n",
      "[29] Train loss: 0.0382485118\n",
      "[29] Validation loss: 0.0738972240\n",
      "[30] Train loss: 0.0394363473\n",
      "[30] Validation loss: 0.0495278069\n",
      "[31] Train loss: 0.0422458331\n",
      "[31] Validation loss: 0.0490784750\n",
      "[32] Train loss: 0.0479488504\n",
      "[32] Validation loss: 0.0746638132\n",
      "[33] Train loss: 0.0490189803\n",
      "[33] Validation loss: 0.1252878280\n",
      "[34] Train loss: 0.0510333348\n",
      "[34] Validation loss: 0.1169432346\n",
      "[35] Train loss: 0.0515719466\n",
      "[35] Validation loss: 0.0939956561\n",
      "[36] Train loss: 0.0501076655\n",
      "[36] Validation loss: 0.0680180510\n",
      "[37] Train loss: 0.0488099670\n",
      "[37] Validation loss: 0.0574355520\n",
      "[38] Train loss: 0.0475621715\n",
      "[38] Validation loss: 0.0502809854\n",
      "[39] Train loss: 0.0482018341\n",
      "[39] Validation loss: 0.0478131935\n",
      "[40] Train loss: 0.0491984468\n",
      "[40] Validation loss: 0.0425264814\n",
      "[41] Train loss: 0.0481627478\n",
      "[41] Validation loss: 0.0492171143\n",
      "[42] Train loss: 0.0454151089\n",
      "[42] Validation loss: 0.0512547480\n",
      "[43] Train loss: 0.0410982014\n",
      "[43] Validation loss: 0.0471653905\n",
      "[44] Train loss: 0.0399082741\n",
      "[44] Validation loss: 0.0443555262\n",
      "[45] Train loss: 0.0399699725\n",
      "[45] Validation loss: 0.0392297276\n",
      "model saved\n",
      "[46] Train loss: 0.0378844033\n",
      "[46] Validation loss: 0.0395462097\n",
      "[47] Train loss: 0.0345151967\n",
      "[47] Validation loss: 0.0517916100\n",
      "[48] Train loss: 0.0313550410\n",
      "[48] Validation loss: 0.0470407954\n",
      "[49] Train loss: 0.0258776642\n",
      "[49] Validation loss: 0.0348760774\n",
      "model saved\n",
      "[50] Train loss: 0.0222735188\n",
      "[50] Validation loss: 0.0364113405\n",
      "[51] Train loss: 0.0209894155\n",
      "[51] Validation loss: 0.0379725251\n",
      "[52] Train loss: 0.0203244573\n",
      "[52] Validation loss: 0.0469085726\n",
      "[53] Train loss: 0.0185259021\n",
      "[53] Validation loss: 0.0795408373\n",
      "[54] Train loss: 0.0188298280\n",
      "[54] Validation loss: 0.0899739602\n",
      "[55] Train loss: 0.0177296176\n",
      "[55] Validation loss: 0.0938671053\n",
      "[56] Train loss: 0.0179498526\n",
      "[56] Validation loss: 0.0778154058\n",
      "[57] Train loss: 0.0188527458\n",
      "[57] Validation loss: 0.0860200721\n",
      "[58] Train loss: 0.0189985835\n",
      "[58] Validation loss: 0.0756985144\n",
      "[59] Train loss: 0.0207234313\n",
      "[59] Validation loss: 0.0843199851\n",
      "[60] Train loss: 0.0221692632\n",
      "[60] Validation loss: 0.0785838222\n",
      "[61] Train loss: 0.0235768801\n",
      "[61] Validation loss: 0.0682729013\n",
      "[62] Train loss: 0.0257577742\n",
      "[62] Validation loss: 0.0680361455\n",
      "[63] Train loss: 0.0308820529\n",
      "[63] Validation loss: 0.0710104115\n",
      "[64] Train loss: 0.0365619524\n",
      "[64] Validation loss: 0.0897635578\n",
      "[65] Train loss: 0.0337041521\n",
      "[65] Validation loss: 0.1014117216\n",
      "[66] Train loss: 0.0334236739\n",
      "[66] Validation loss: 0.0842730815\n",
      "[67] Train loss: 0.0340812523\n",
      "[67] Validation loss: 0.0567402645\n",
      "[68] Train loss: 0.0320809240\n",
      "[68] Validation loss: 0.0581272570\n",
      "[69] Train loss: 0.0323227558\n",
      "[69] Validation loss: 0.0763963953\n",
      "[70] Train loss: 0.0335089466\n",
      "[70] Validation loss: 0.0800015959\n",
      "[71] Train loss: 0.0323553795\n",
      "[71] Validation loss: 0.0533509642\n",
      "[72] Train loss: 0.0316645058\n",
      "[72] Validation loss: 0.0413522783\n",
      "[73] Train loss: 0.0331881566\n",
      "[73] Validation loss: 0.0334263457\n",
      "model saved\n",
      "[74] Train loss: 0.0360870249\n",
      "[74] Validation loss: 0.0371802584\n",
      "[75] Train loss: 0.0335840754\n",
      "[75] Validation loss: 0.0476853441\n",
      "[76] Train loss: 0.0301439336\n",
      "[76] Validation loss: 0.0859091181\n",
      "[77] Train loss: 0.0335891789\n",
      "[77] Validation loss: 0.0578560855\n",
      "[78] Train loss: 0.0327473666\n",
      "[78] Validation loss: 0.0368664657\n",
      "[79] Train loss: 0.0297088713\n",
      "[79] Validation loss: 0.0432977169\n",
      "[80] Train loss: 0.0250496389\n",
      "[80] Validation loss: 0.0479284131\n",
      "[81] Train loss: 0.0244411235\n",
      "[81] Validation loss: 0.0491310281\n",
      "[82] Train loss: 0.0248135549\n",
      "[82] Validation loss: 0.0604941595\n",
      "[83] Train loss: 0.0285867375\n",
      "[83] Validation loss: 0.0453465013\n",
      "[84] Train loss: 0.0295892813\n",
      "[84] Validation loss: 0.0346053030\n",
      "[85] Train loss: 0.0263218314\n",
      "[85] Validation loss: 0.0350603268\n",
      "[86] Train loss: 0.0259226817\n",
      "[86] Validation loss: 0.0589104590\n",
      "[87] Train loss: 0.0278012219\n",
      "[87] Validation loss: 0.0788846278\n",
      "[88] Train loss: 0.0311851474\n",
      "[88] Validation loss: 0.1118501595\n",
      "[89] Train loss: 0.0292058840\n",
      "[89] Validation loss: 0.1641473169\n",
      "[90] Train loss: 0.0281921431\n",
      "[90] Validation loss: 0.1824183540\n",
      "[91] Train loss: 0.0255397426\n",
      "[91] Validation loss: 0.1340593339\n",
      "[92] Train loss: 0.0231495379\n",
      "[92] Validation loss: 0.1184254846\n",
      "[93] Train loss: 0.0228192983\n",
      "[93] Validation loss: 0.1161986136\n",
      "[94] Train loss: 0.0239781097\n",
      "[94] Validation loss: 0.1140745103\n",
      "[95] Train loss: 0.0262023441\n",
      "[95] Validation loss: 0.0853649846\n",
      "[96] Train loss: 0.0229661888\n",
      "[96] Validation loss: 0.0722551407\n",
      "[97] Train loss: 0.0219017394\n",
      "[97] Validation loss: 0.0494489616\n",
      "[98] Train loss: 0.0217888948\n",
      "[98] Validation loss: 0.0356521766\n",
      "[99] Train loss: 0.0215050753\n",
      "[99] Validation loss: 0.0381089951\n",
      "[100] Train loss: 0.0194103261\n",
      "[100] Validation loss: 0.0382564079\n",
      "[101] Train loss: 0.0160158685\n",
      "[101] Validation loss: 0.0421108174\n",
      "[102] Train loss: 0.0162461313\n",
      "[102] Validation loss: 0.0456212431\n",
      "[103] Train loss: 0.0168256493\n",
      "[103] Validation loss: 0.0391807578\n",
      "[104] Train loss: 0.0165734591\n",
      "[104] Validation loss: 0.0334037580\n",
      "model saved\n",
      "[105] Train loss: 0.0188588863\n",
      "[105] Validation loss: 0.0324357625\n",
      "model saved\n",
      "[106] Train loss: 0.0213818040\n",
      "[106] Validation loss: 0.0340535807\n",
      "[107] Train loss: 0.0198766894\n",
      "[107] Validation loss: 0.0329027720\n",
      "[108] Train loss: 0.0200186416\n",
      "[108] Validation loss: 0.0344851733\n",
      "[109] Train loss: 0.0197772685\n",
      "[109] Validation loss: 0.0351863641\n",
      "[110] Train loss: 0.0221085725\n",
      "[110] Validation loss: 0.0465146886\n",
      "[111] Train loss: 0.0243480424\n",
      "[111] Validation loss: 0.0576640388\n",
      "[112] Train loss: 0.0213712047\n",
      "[112] Validation loss: 0.0724865564\n",
      "[113] Train loss: 0.0186423299\n",
      "[113] Validation loss: 0.0732574714\n",
      "[114] Train loss: 0.0171295920\n",
      "[114] Validation loss: 0.0613215490\n",
      "[115] Train loss: 0.0161260444\n",
      "[115] Validation loss: 0.0518174861\n",
      "[116] Train loss: 0.0158874579\n",
      "[116] Validation loss: 0.0533412915\n",
      "[117] Train loss: 0.0149601177\n",
      "[117] Validation loss: 0.0455973234\n",
      "[118] Train loss: 0.0147912745\n",
      "[118] Validation loss: 0.0418637028\n",
      "[119] Train loss: 0.0164160602\n",
      "[119] Validation loss: 0.0365808753\n",
      "[120] Train loss: 0.0185638876\n",
      "[120] Validation loss: 0.0411774730\n",
      "[121] Train loss: 0.0198421115\n",
      "[121] Validation loss: 0.0507742871\n",
      "[122] Train loss: 0.0210235611\n",
      "[122] Validation loss: 0.0602653385\n",
      "[123] Train loss: 0.0224786799\n",
      "[123] Validation loss: 0.0598298260\n",
      "[124] Train loss: 0.0256056614\n",
      "[124] Validation loss: 0.0488441751\n",
      "[125] Train loss: 0.0286926307\n",
      "[125] Validation loss: 0.0367200477\n",
      "[126] Train loss: 0.0285392872\n",
      "[126] Validation loss: 0.0346315630\n",
      "[127] Train loss: 0.0264867403\n",
      "[127] Validation loss: 0.0348164165\n",
      "[128] Train loss: 0.0233592561\n",
      "[128] Validation loss: 0.0297283033\n",
      "model saved\n",
      "[129] Train loss: 0.0270975640\n",
      "[129] Validation loss: 0.0289364447\n",
      "model saved\n",
      "[130] Train loss: 0.0275888840\n",
      "[130] Validation loss: 0.0334440097\n",
      "[131] Train loss: 0.0238359517\n",
      "[131] Validation loss: 0.0430935111\n",
      "[132] Train loss: 0.0181967599\n",
      "[132] Validation loss: 0.0442021738\n",
      "[133] Train loss: 0.0160777358\n",
      "[133] Validation loss: 0.0406220229\n",
      "[134] Train loss: 0.0165780792\n",
      "[134] Validation loss: 0.0422958656\n",
      "[135] Train loss: 0.0156010561\n",
      "[135] Validation loss: 0.0449734813\n",
      "[136] Train loss: 0.0142705645\n",
      "[136] Validation loss: 0.0470176456\n",
      "[137] Train loss: 0.0121032185\n",
      "[137] Validation loss: 0.0433782593\n",
      "[138] Train loss: 0.0102874711\n",
      "[138] Validation loss: 0.0335312936\n",
      "[139] Train loss: 0.0104753520\n",
      "[139] Validation loss: 0.0418333544\n",
      "[140] Train loss: 0.0098499852\n",
      "[140] Validation loss: 0.0475678304\n",
      "[141] Train loss: 0.0097178482\n",
      "[141] Validation loss: 0.0467821606\n",
      "[142] Train loss: 0.0109960686\n",
      "[142] Validation loss: 0.0407444502\n",
      "[143] Train loss: 0.0123395009\n",
      "[143] Validation loss: 0.0396925594\n",
      "[144] Train loss: 0.0118758961\n",
      "[144] Validation loss: 0.0375380502\n",
      "[145] Train loss: 0.0111056787\n",
      "[145] Validation loss: 0.0373723204\n",
      "[146] Train loss: 0.0106135988\n",
      "[146] Validation loss: 0.0500376171\n",
      "[147] Train loss: 0.0104680446\n",
      "[147] Validation loss: 0.0675114972\n",
      "[148] Train loss: 0.0104584849\n",
      "[148] Validation loss: 0.0555243684\n",
      "[149] Train loss: 0.0112514141\n",
      "[149] Validation loss: 0.0479264070\n",
      "[150] Train loss: 0.0116377612\n",
      "[150] Validation loss: 0.0514955007\n",
      "[151] Train loss: 0.0109868505\n",
      "[151] Validation loss: 0.0549378461\n",
      "[152] Train loss: 0.0104656545\n",
      "[152] Validation loss: 0.0510865771\n",
      "[153] Train loss: 0.0109623893\n",
      "[153] Validation loss: 0.0463545907\n",
      "[154] Train loss: 0.0098836476\n",
      "[154] Validation loss: 0.0374744161\n",
      "[155] Train loss: 0.0086751940\n",
      "[155] Validation loss: 0.0289067444\n",
      "model saved\n",
      "[156] Train loss: 0.0093408851\n",
      "[156] Validation loss: 0.0301835851\n",
      "[157] Train loss: 0.0094324471\n",
      "[157] Validation loss: 0.0328392113\n",
      "[158] Train loss: 0.0101837391\n",
      "[158] Validation loss: 0.0340213899\n",
      "[159] Train loss: 0.0108455386\n",
      "[159] Validation loss: 0.0346345984\n",
      "[160] Train loss: 0.0099104793\n",
      "[160] Validation loss: 0.0361150641\n",
      "[161] Train loss: 0.0110687582\n",
      "[161] Validation loss: 0.0385291938\n",
      "[162] Train loss: 0.0111768555\n",
      "[162] Validation loss: 0.0392198400\n",
      "[163] Train loss: 0.0161473588\n",
      "[163] Validation loss: 0.0379762870\n",
      "[164] Train loss: 0.0175554674\n",
      "[164] Validation loss: 0.0457699032\n",
      "[165] Train loss: 0.0180603094\n",
      "[165] Validation loss: 0.0414585541\n",
      "[166] Train loss: 0.0165539246\n",
      "[166] Validation loss: 0.0437075046\n",
      "[167] Train loss: 0.0181497617\n",
      "[167] Validation loss: 0.0381677880\n",
      "[168] Train loss: 0.0190989241\n",
      "[168] Validation loss: 0.0352066440\n",
      "[169] Train loss: 0.0210505502\n",
      "[169] Validation loss: 0.0385512597\n",
      "[170] Train loss: 0.0177281671\n",
      "[170] Validation loss: 0.0341898726\n",
      "[171] Train loss: 0.0191873351\n",
      "[171] Validation loss: 0.0319090961\n",
      "[172] Train loss: 0.0178176259\n",
      "[172] Validation loss: 0.0271200977\n",
      "model saved\n",
      "[173] Train loss: 0.0135522035\n",
      "[173] Validation loss: 0.0306258567\n",
      "[174] Train loss: 0.0122926285\n",
      "[174] Validation loss: 0.0250578495\n",
      "model saved\n",
      "[175] Train loss: 0.0119812629\n",
      "[175] Validation loss: 0.0261252060\n",
      "[176] Train loss: 0.0118811747\n",
      "[176] Validation loss: 0.0312852264\n",
      "[177] Train loss: 0.0135757242\n",
      "[177] Validation loss: 0.0409253053\n",
      "[178] Train loss: 0.0126531800\n",
      "[178] Validation loss: 0.0416237033\n",
      "[179] Train loss: 0.0136174170\n",
      "[179] Validation loss: 0.0335046103\n",
      "[180] Train loss: 0.0128108742\n",
      "[180] Validation loss: 0.0303330222\n",
      "[181] Train loss: 0.0115945773\n",
      "[181] Validation loss: 0.0264050539\n",
      "[182] Train loss: 0.0135283800\n",
      "[182] Validation loss: 0.0295805445\n",
      "[183] Train loss: 0.0144459628\n",
      "[183] Validation loss: 0.0304790410\n",
      "[184] Train loss: 0.0158286324\n",
      "[184] Validation loss: 0.0296147343\n",
      "[185] Train loss: 0.0164348355\n",
      "[185] Validation loss: 0.0440811240\n",
      "[186] Train loss: 0.0165529126\n",
      "[186] Validation loss: 0.0592587893\n",
      "[187] Train loss: 0.0247941787\n",
      "[187] Validation loss: 0.0735318704\n",
      "[188] Train loss: 0.0298400109\n",
      "[188] Validation loss: 0.0988997716\n",
      "[189] Train loss: 0.0304373990\n",
      "[189] Validation loss: 0.0961785180\n",
      "[190] Train loss: 0.0265596787\n",
      "[190] Validation loss: 0.0853716090\n",
      "[191] Train loss: 0.0224748557\n",
      "[191] Validation loss: 0.0819521776\n",
      "[192] Train loss: 0.0169278791\n",
      "[192] Validation loss: 0.0458321230\n",
      "[193] Train loss: 0.0149229924\n",
      "[193] Validation loss: 0.0293872450\n",
      "[194] Train loss: 0.0108180394\n",
      "[194] Validation loss: 0.0256733706\n",
      "[195] Train loss: 0.0089538763\n",
      "[195] Validation loss: 0.0261172458\n",
      "[196] Train loss: 0.0087851458\n",
      "[196] Validation loss: 0.0265939881\n",
      "[197] Train loss: 0.0076605227\n",
      "[197] Validation loss: 0.0272486152\n",
      "[198] Train loss: 0.0069116733\n",
      "[198] Validation loss: 0.0240331557\n",
      "model saved\n",
      "[199] Train loss: 0.0067718211\n",
      "[199] Validation loss: 0.0250670048\n",
      "[200] Train loss: 0.0060251493\n",
      "[200] Validation loss: 0.0289455346\n",
      "2 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.1871260264\n",
      "[1] Validation loss: 0.0418360304\n",
      "model saved\n",
      "[2] Train loss: 0.1048114501\n",
      "[2] Validation loss: 0.0303292437\n",
      "model saved\n",
      "[3] Train loss: 0.0697378896\n",
      "[3] Validation loss: 0.0275994904\n",
      "model saved\n",
      "[4] Train loss: 0.0448760653\n",
      "[4] Validation loss: 0.0286048346\n",
      "[5] Train loss: 0.0314665148\n",
      "[5] Validation loss: 0.0284088223\n",
      "[6] Train loss: 0.0206530099\n",
      "[6] Validation loss: 0.0320151169\n",
      "[7] Train loss: 0.0140218064\n",
      "[7] Validation loss: 0.0307882452\n",
      "[8] Train loss: 0.0113675724\n",
      "[8] Validation loss: 0.0312920767\n",
      "[9] Train loss: 0.0097595247\n",
      "[9] Validation loss: 0.0264999056\n",
      "model saved\n",
      "[10] Train loss: 0.0098029433\n",
      "[10] Validation loss: 0.0296351551\n",
      "[11] Train loss: 0.0097224353\n",
      "[11] Validation loss: 0.0269941190\n",
      "[12] Train loss: 0.0096894608\n",
      "[12] Validation loss: 0.0314432221\n",
      "[13] Train loss: 0.0097978483\n",
      "[13] Validation loss: 0.0277257090\n",
      "[14] Train loss: 0.0083333556\n",
      "[14] Validation loss: 0.0285589184\n",
      "[15] Train loss: 0.0078444804\n",
      "[15] Validation loss: 0.0260147446\n",
      "model saved\n",
      "[16] Train loss: 0.0058122350\n",
      "[16] Validation loss: 0.0254467661\n",
      "model saved\n",
      "[17] Train loss: 0.0054528839\n",
      "[17] Validation loss: 0.0252618199\n",
      "model saved\n",
      "[18] Train loss: 0.0053545686\n",
      "[18] Validation loss: 0.0258283968\n",
      "[19] Train loss: 0.0063220611\n",
      "[19] Validation loss: 0.0274455243\n",
      "[20] Train loss: 0.0054937463\n",
      "[20] Validation loss: 0.0293939130\n",
      "[21] Train loss: 0.0066446197\n",
      "[21] Validation loss: 0.0309173148\n",
      "[22] Train loss: 0.0076759127\n",
      "[22] Validation loss: 0.0320768763\n",
      "[23] Train loss: 0.0086029992\n",
      "[23] Validation loss: 0.0289240958\n",
      "[24] Train loss: 0.0100247268\n",
      "[24] Validation loss: 0.0288868595\n",
      "[25] Train loss: 0.0133389420\n",
      "[25] Validation loss: 0.0311860129\n",
      "[26] Train loss: 0.0154986135\n",
      "[26] Validation loss: 0.0380985190\n",
      "[27] Train loss: 0.0213962905\n",
      "[27] Validation loss: 0.0338302673\n",
      "[28] Train loss: 0.0218048362\n",
      "[28] Validation loss: 0.0325945221\n",
      "[29] Train loss: 0.0228584749\n",
      "[29] Validation loss: 0.0307430995\n",
      "[30] Train loss: 0.0232968442\n",
      "[30] Validation loss: 0.0330449314\n",
      "[31] Train loss: 0.0247819457\n",
      "[31] Validation loss: 0.0299098348\n",
      "[32] Train loss: 0.0195177025\n",
      "[32] Validation loss: 0.0305322781\n",
      "[33] Train loss: 0.0147634438\n",
      "[33] Validation loss: 0.0302905846\n",
      "[34] Train loss: 0.0108709979\n",
      "[34] Validation loss: 0.0296254998\n",
      "[35] Train loss: 0.0069430334\n",
      "[35] Validation loss: 0.0277356065\n",
      "[36] Train loss: 0.0048278078\n",
      "[36] Validation loss: 0.0272965886\n",
      "[37] Train loss: 0.0038254538\n",
      "[37] Validation loss: 0.0262944037\n",
      "[38] Train loss: 0.0036925596\n",
      "[38] Validation loss: 0.0254285602\n",
      "[39] Train loss: 0.0036377602\n",
      "[39] Validation loss: 0.0250478323\n",
      "model saved\n",
      "[40] Train loss: 0.0035022198\n",
      "[40] Validation loss: 0.0257728785\n",
      "[41] Train loss: 0.0032213160\n",
      "[41] Validation loss: 0.0260172455\n",
      "[42] Train loss: 0.0033539174\n",
      "[42] Validation loss: 0.0265130988\n",
      "[43] Train loss: 0.0031779258\n",
      "[43] Validation loss: 0.0266903598\n",
      "[44] Train loss: 0.0041343568\n",
      "[44] Validation loss: 0.0263968548\n",
      "[45] Train loss: 0.0040967085\n",
      "[45] Validation loss: 0.0270286217\n",
      "[46] Train loss: 0.0036449187\n",
      "[46] Validation loss: 0.0283514468\n",
      "[47] Train loss: 0.0041962180\n",
      "[47] Validation loss: 0.0315905705\n",
      "[48] Train loss: 0.0054014361\n",
      "[48] Validation loss: 0.0323013526\n",
      "[49] Train loss: 0.0053493503\n",
      "[49] Validation loss: 0.0346510527\n",
      "[50] Train loss: 0.0066905022\n",
      "[50] Validation loss: 0.0326714869\n",
      "[51] Train loss: 0.0078595248\n",
      "[51] Validation loss: 0.0321559045\n",
      "[52] Train loss: 0.0102397596\n",
      "[52] Validation loss: 0.0278826492\n",
      "[53] Train loss: 0.0095212608\n",
      "[53] Validation loss: 0.0313307840\n",
      "[54] Train loss: 0.0122014299\n",
      "[54] Validation loss: 0.0284873158\n",
      "[55] Train loss: 0.0188807875\n",
      "[55] Validation loss: 0.0337551934\n",
      "[56] Train loss: 0.0130668127\n",
      "[56] Validation loss: 0.0318625945\n",
      "[57] Train loss: 0.0136227180\n",
      "[57] Validation loss: 0.0371489032\n",
      "[58] Train loss: 0.0098826788\n",
      "[58] Validation loss: 0.0326761042\n",
      "[59] Train loss: 0.0091649796\n",
      "[59] Validation loss: 0.0278612203\n",
      "[60] Train loss: 0.0090856221\n",
      "[60] Validation loss: 0.0245140078\n",
      "model saved\n",
      "[61] Train loss: 0.0069991585\n",
      "[61] Validation loss: 0.0258655335\n",
      "[62] Train loss: 0.0063285563\n",
      "[62] Validation loss: 0.0253477492\n",
      "[63] Train loss: 0.0076096486\n",
      "[63] Validation loss: 0.0289209741\n",
      "[64] Train loss: 0.0060062672\n",
      "[64] Validation loss: 0.0285563252\n",
      "[65] Train loss: 0.0062051042\n",
      "[65] Validation loss: 0.0279586941\n",
      "[66] Train loss: 0.0084069132\n",
      "[66] Validation loss: 0.0245521007\n",
      "[67] Train loss: 0.0086686445\n",
      "[67] Validation loss: 0.0253242378\n",
      "[68] Train loss: 0.0076789760\n",
      "[68] Validation loss: 0.0272710456\n",
      "[69] Train loss: 0.0080300458\n",
      "[69] Validation loss: 0.0300556170\n",
      "[70] Train loss: 0.0067576260\n",
      "[70] Validation loss: 0.0308954962\n",
      "[71] Train loss: 0.0056751155\n",
      "[71] Validation loss: 0.0291519250\n",
      "[72] Train loss: 0.0066824392\n",
      "[72] Validation loss: 0.0269567294\n",
      "[73] Train loss: 0.0070240066\n",
      "[73] Validation loss: 0.0267322400\n",
      "[74] Train loss: 0.0070983459\n",
      "[74] Validation loss: 0.0305246542\n",
      "[75] Train loss: 0.0069383611\n",
      "[75] Validation loss: 0.0338592366\n",
      "[76] Train loss: 0.0075382050\n",
      "[76] Validation loss: 0.0363918662\n",
      "[77] Train loss: 0.0068609888\n",
      "[77] Validation loss: 0.0320329694\n",
      "[78] Train loss: 0.0081463056\n",
      "[78] Validation loss: 0.0273425110\n",
      "[79] Train loss: 0.0073478609\n",
      "[79] Validation loss: 0.0252427607\n",
      "[80] Train loss: 0.0070566540\n",
      "[80] Validation loss: 0.0294091461\n",
      "[81] Train loss: 0.0058217523\n",
      "[81] Validation loss: 0.0320573524\n",
      "[82] Train loss: 0.0053089277\n",
      "[82] Validation loss: 0.0343027891\n",
      "[83] Train loss: 0.0049281473\n",
      "[83] Validation loss: 0.0289414415\n",
      "[84] Train loss: 0.0051507840\n",
      "[84] Validation loss: 0.0248962102\n",
      "[85] Train loss: 0.0051999928\n",
      "[85] Validation loss: 0.0237049825\n",
      "model saved\n",
      "[86] Train loss: 0.0058086361\n",
      "[86] Validation loss: 0.0284368765\n",
      "[87] Train loss: 0.0049736577\n",
      "[87] Validation loss: 0.0291714540\n",
      "[88] Train loss: 0.0048735022\n",
      "[88] Validation loss: 0.0314864311\n",
      "[89] Train loss: 0.0053162155\n",
      "[89] Validation loss: 0.0277239175\n",
      "[90] Train loss: 0.0044752854\n",
      "[90] Validation loss: 0.0271200436\n",
      "[91] Train loss: 0.0046569892\n",
      "[91] Validation loss: 0.0248301233\n",
      "[92] Train loss: 0.0053436315\n",
      "[92] Validation loss: 0.0288098195\n",
      "[93] Train loss: 0.0044344632\n",
      "[93] Validation loss: 0.0287112647\n",
      "[94] Train loss: 0.0041180611\n",
      "[94] Validation loss: 0.0304831542\n",
      "[95] Train loss: 0.0045670867\n",
      "[95] Validation loss: 0.0278897043\n",
      "[96] Train loss: 0.0042765257\n",
      "[96] Validation loss: 0.0281680301\n",
      "[97] Train loss: 0.0041442078\n",
      "[97] Validation loss: 0.0262263409\n",
      "[98] Train loss: 0.0045214625\n",
      "[98] Validation loss: 0.0292141041\n",
      "[99] Train loss: 0.0053688787\n",
      "[99] Validation loss: 0.0305795105\n",
      "[100] Train loss: 0.0054284275\n",
      "[100] Validation loss: 0.0308589999\n",
      "[101] Train loss: 0.0053178071\n",
      "[101] Validation loss: 0.0303490792\n",
      "[102] Train loss: 0.0060668691\n",
      "[102] Validation loss: 0.0262303031\n",
      "[103] Train loss: 0.0058581812\n",
      "[103] Validation loss: 0.0259942956\n",
      "[104] Train loss: 0.0078112536\n",
      "[104] Validation loss: 0.0250734519\n",
      "[105] Train loss: 0.0055073462\n",
      "[105] Validation loss: 0.0281286577\n",
      "[106] Train loss: 0.0063602592\n",
      "[106] Validation loss: 0.0286287187\n",
      "[107] Train loss: 0.0086200540\n",
      "[107] Validation loss: 0.0321957656\n",
      "[108] Train loss: 0.0073595486\n",
      "[108] Validation loss: 0.0290077871\n",
      "[109] Train loss: 0.0070318623\n",
      "[109] Validation loss: 0.0259643206\n",
      "[110] Train loss: 0.0063717735\n",
      "[110] Validation loss: 0.0244097203\n",
      "[111] Train loss: 0.0066933364\n",
      "[111] Validation loss: 0.0277920706\n",
      "[112] Train loss: 0.0090996197\n",
      "[112] Validation loss: 0.0288243239\n",
      "[113] Train loss: 0.0087500002\n",
      "[113] Validation loss: 0.0317262055\n",
      "[114] Train loss: 0.0081414891\n",
      "[114] Validation loss: 0.0269649752\n",
      "[115] Train loss: 0.0065237015\n",
      "[115] Validation loss: 0.0261163336\n",
      "[116] Train loss: 0.0048519315\n",
      "[116] Validation loss: 0.0281063610\n",
      "[117] Train loss: 0.0046994848\n",
      "[117] Validation loss: 0.0296748472\n",
      "[118] Train loss: 0.0051475286\n",
      "[118] Validation loss: 0.0325631539\n",
      "[119] Train loss: 0.0050034492\n",
      "[119] Validation loss: 0.0273540562\n",
      "[120] Train loss: 0.0038535708\n",
      "[120] Validation loss: 0.0280345324\n",
      "[121] Train loss: 0.0034913647\n",
      "[121] Validation loss: 0.0281825995\n",
      "[122] Train loss: 0.0057907875\n",
      "[122] Validation loss: 0.0312949927\n",
      "[123] Train loss: 0.0042225997\n",
      "[123] Validation loss: 0.0303009025\n",
      "[124] Train loss: 0.0034483065\n",
      "[124] Validation loss: 0.0290288849\n",
      "[125] Train loss: 0.0035849946\n",
      "[125] Validation loss: 0.0284319953\n",
      "[126] Train loss: 0.0024118641\n",
      "[126] Validation loss: 0.0290129165\n",
      "[127] Train loss: 0.0030281096\n",
      "[127] Validation loss: 0.0289652387\n",
      "[128] Train loss: 0.0028649757\n",
      "[128] Validation loss: 0.0287932158\n",
      "[129] Train loss: 0.0021789345\n",
      "[129] Validation loss: 0.0274611848\n",
      "[130] Train loss: 0.0024033902\n",
      "[130] Validation loss: 0.0274893128\n",
      "[131] Train loss: 0.0020163138\n",
      "[131] Validation loss: 0.0270480203\n",
      "[132] Train loss: 0.0032733721\n",
      "[132] Validation loss: 0.0297023575\n",
      "[133] Train loss: 0.0034926838\n",
      "[133] Validation loss: 0.0280241669\n",
      "[134] Train loss: 0.0041501609\n",
      "[134] Validation loss: 0.0295712399\n",
      "[135] Train loss: 0.0045127049\n",
      "[135] Validation loss: 0.0284587695\n",
      "[136] Train loss: 0.0042065410\n",
      "[136] Validation loss: 0.0271578848\n",
      "[137] Train loss: 0.0045230466\n",
      "[137] Validation loss: 0.0260439879\n",
      "[138] Train loss: 0.0055846559\n",
      "[138] Validation loss: 0.0277759187\n",
      "[139] Train loss: 0.0043988611\n",
      "[139] Validation loss: 0.0294138010\n",
      "[140] Train loss: 0.0046171678\n",
      "[140] Validation loss: 0.0315354068\n",
      "[141] Train loss: 0.0041046824\n",
      "[141] Validation loss: 0.0309016368\n",
      "[142] Train loss: 0.0038616780\n",
      "[142] Validation loss: 0.0303115778\n",
      "[143] Train loss: 0.0052447797\n",
      "[143] Validation loss: 0.0279778604\n",
      "[144] Train loss: 0.0047160737\n",
      "[144] Validation loss: 0.0289643043\n",
      "[145] Train loss: 0.0043099135\n",
      "[145] Validation loss: 0.0278616085\n",
      "[146] Train loss: 0.0056297530\n",
      "[146] Validation loss: 0.0307646036\n",
      "[147] Train loss: 0.0041580210\n",
      "[147] Validation loss: 0.0320899950\n",
      "[148] Train loss: 0.0063369048\n",
      "[148] Validation loss: 0.0338843792\n",
      "[149] Train loss: 0.0063421183\n",
      "[149] Validation loss: 0.0300100727\n",
      "[150] Train loss: 0.0055585035\n",
      "[150] Validation loss: 0.0295198809\n",
      "[151] Train loss: 0.0075756910\n",
      "[151] Validation loss: 0.0261567631\n",
      "[152] Train loss: 0.0086383512\n",
      "[152] Validation loss: 0.0305572217\n",
      "[153] Train loss: 0.0055477847\n",
      "[153] Validation loss: 0.0307445262\n",
      "[154] Train loss: 0.0069867106\n",
      "[154] Validation loss: 0.0311837091\n",
      "[155] Train loss: 0.0060441870\n",
      "[155] Validation loss: 0.0274795868\n",
      "[156] Train loss: 0.0047508251\n",
      "[156] Validation loss: 0.0267095010\n",
      "[157] Train loss: 0.0045345609\n",
      "[157] Validation loss: 0.0259778518\n",
      "[158] Train loss: 0.0045460314\n",
      "[158] Validation loss: 0.0290856492\n",
      "[159] Train loss: 0.0034549191\n",
      "[159] Validation loss: 0.0286655168\n",
      "[160] Train loss: 0.0029136479\n",
      "[160] Validation loss: 0.0272811155\n",
      "[161] Train loss: 0.0039685159\n",
      "[161] Validation loss: 0.0258264765\n",
      "[162] Train loss: 0.0026190148\n",
      "[162] Validation loss: 0.0266505148\n",
      "[163] Train loss: 0.0022151080\n",
      "[163] Validation loss: 0.0273179656\n",
      "[164] Train loss: 0.0026191932\n",
      "[164] Validation loss: 0.0289813753\n",
      "[165] Train loss: 0.0026872310\n",
      "[165] Validation loss: 0.0278513408\n",
      "[166] Train loss: 0.0022899397\n",
      "[166] Validation loss: 0.0268983924\n",
      "[167] Train loss: 0.0034769665\n",
      "[167] Validation loss: 0.0260736108\n",
      "[168] Train loss: 0.0033718401\n",
      "[168] Validation loss: 0.0275679278\n",
      "[169] Train loss: 0.0029913539\n",
      "[169] Validation loss: 0.0278716018\n",
      "[170] Train loss: 0.0042302340\n",
      "[170] Validation loss: 0.0292583776\n",
      "[171] Train loss: 0.0056212517\n",
      "[171] Validation loss: 0.0265459972\n",
      "[172] Train loss: 0.0037294636\n",
      "[172] Validation loss: 0.0275888670\n",
      "[173] Train loss: 0.0064995426\n",
      "[173] Validation loss: 0.0251398641\n",
      "[174] Train loss: 0.0073121985\n",
      "[174] Validation loss: 0.0287433576\n",
      "[175] Train loss: 0.0054774800\n",
      "[175] Validation loss: 0.0264350506\n",
      "[176] Train loss: 0.0052558456\n",
      "[176] Validation loss: 0.0284351993\n",
      "[177] Train loss: 0.0066840622\n",
      "[177] Validation loss: 0.0259393411\n",
      "[178] Train loss: 0.0041021127\n",
      "[178] Validation loss: 0.0274252886\n",
      "[179] Train loss: 0.0041259040\n",
      "[179] Validation loss: 0.0259829283\n",
      "[180] Train loss: 0.0039953481\n",
      "[180] Validation loss: 0.0283609190\n",
      "[181] Train loss: 0.0036253024\n",
      "[181] Validation loss: 0.0266573201\n",
      "[182] Train loss: 0.0019687742\n",
      "[182] Validation loss: 0.0273906773\n",
      "[183] Train loss: 0.0021655190\n",
      "[183] Validation loss: 0.0271918047\n",
      "[184] Train loss: 0.0016637573\n",
      "[184] Validation loss: 0.0283550808\n",
      "[185] Train loss: 0.0019410014\n",
      "[185] Validation loss: 0.0290709532\n",
      "[186] Train loss: 0.0018664805\n",
      "[186] Validation loss: 0.0288934275\n",
      "[187] Train loss: 0.0018953969\n",
      "[187] Validation loss: 0.0291826093\n",
      "[188] Train loss: 0.0015574750\n",
      "[188] Validation loss: 0.0290791561\n",
      "[189] Train loss: 0.0015964535\n",
      "[189] Validation loss: 0.0295805793\n",
      "[190] Train loss: 0.0021476973\n",
      "[190] Validation loss: 0.0323629852\n",
      "[191] Train loss: 0.0020994151\n",
      "[191] Validation loss: 0.0306506417\n",
      "[192] Train loss: 0.0025914708\n",
      "[192] Validation loss: 0.0321416056\n",
      "[193] Train loss: 0.0046715310\n",
      "[193] Validation loss: 0.0275689824\n",
      "[194] Train loss: 0.0075561917\n",
      "[194] Validation loss: 0.0320737791\n",
      "[195] Train loss: 0.0060018254\n",
      "[195] Validation loss: 0.0296191806\n",
      "[196] Train loss: 0.0080799076\n",
      "[196] Validation loss: 0.0345780207\n",
      "[197] Train loss: 0.0058055541\n",
      "[197] Validation loss: 0.0294113064\n",
      "[198] Train loss: 0.0042552720\n",
      "[198] Validation loss: 0.0296326344\n",
      "[199] Train loss: 0.0031256660\n",
      "[199] Validation loss: 0.0291567606\n",
      "[200] Train loss: 0.0031587447\n",
      "[200] Validation loss: 0.0306736081\n",
      "3 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.0859590794\n",
      "[1] Validation loss: 0.0782291783\n",
      "model saved\n",
      "[2] Train loss: 0.0426375485\n",
      "[2] Validation loss: 0.0710762349\n",
      "model saved\n",
      "[3] Train loss: 0.0215244157\n",
      "[3] Validation loss: 0.0758999996\n",
      "[4] Train loss: 0.0155315431\n",
      "[4] Validation loss: 0.0818087501\n",
      "[5] Train loss: 0.0101766483\n",
      "[5] Validation loss: 0.0816952642\n",
      "[6] Train loss: 0.0057240061\n",
      "[6] Validation loss: 0.0815698689\n",
      "[7] Train loss: 0.0040494165\n",
      "[7] Validation loss: 0.0786635875\n",
      "[8] Train loss: 0.0026483722\n",
      "[8] Validation loss: 0.0767659763\n",
      "[9] Train loss: 0.0020546123\n",
      "[9] Validation loss: 0.0778831953\n",
      "[10] Train loss: 0.0017331987\n",
      "[10] Validation loss: 0.0810436720\n",
      "[11] Train loss: 0.0017194093\n",
      "[11] Validation loss: 0.0818385653\n",
      "[12] Train loss: 0.0015766592\n",
      "[12] Validation loss: 0.0805361597\n",
      "[13] Train loss: 0.0018708693\n",
      "[13] Validation loss: 0.0786565748\n",
      "[14] Train loss: 0.0018901902\n",
      "[14] Validation loss: 0.0794249015\n",
      "[15] Train loss: 0.0022713866\n",
      "[15] Validation loss: 0.0819198866\n",
      "[16] Train loss: 0.0028731952\n",
      "[16] Validation loss: 0.0835631708\n",
      "[17] Train loss: 0.0031042098\n",
      "[17] Validation loss: 0.0846936767\n",
      "[18] Train loss: 0.0034338010\n",
      "[18] Validation loss: 0.0808780093\n",
      "[19] Train loss: 0.0036075254\n",
      "[19] Validation loss: 0.0804006038\n",
      "[20] Train loss: 0.0032529651\n",
      "[20] Validation loss: 0.0833804938\n",
      "[21] Train loss: 0.0032655479\n",
      "[21] Validation loss: 0.0884738424\n",
      "[22] Train loss: 0.0039670786\n",
      "[22] Validation loss: 0.0905480227\n",
      "[23] Train loss: 0.0055414749\n",
      "[23] Validation loss: 0.0930366584\n",
      "[24] Train loss: 0.0053146793\n",
      "[24] Validation loss: 0.0835863316\n",
      "[25] Train loss: 0.0053966114\n",
      "[25] Validation loss: 0.0787985106\n",
      "[26] Train loss: 0.0052124977\n",
      "[26] Validation loss: 0.0804661271\n",
      "[27] Train loss: 0.0050950730\n",
      "[27] Validation loss: 0.0895319744\n",
      "[28] Train loss: 0.0045118545\n",
      "[28] Validation loss: 0.0884165809\n",
      "[29] Train loss: 0.0039154811\n",
      "[29] Validation loss: 0.0813240463\n",
      "[30] Train loss: 0.0036301509\n",
      "[30] Validation loss: 0.0801977635\n",
      "[31] Train loss: 0.0035591387\n",
      "[31] Validation loss: 0.0847919113\n",
      "[32] Train loss: 0.0033965526\n",
      "[32] Validation loss: 0.0872139585\n",
      "[33] Train loss: 0.0029657155\n",
      "[33] Validation loss: 0.0870166856\n",
      "[34] Train loss: 0.0030711897\n",
      "[34] Validation loss: 0.0860771952\n",
      "[35] Train loss: 0.0036901201\n",
      "[35] Validation loss: 0.0819326325\n",
      "[36] Train loss: 0.0031222517\n",
      "[36] Validation loss: 0.0797924104\n",
      "[37] Train loss: 0.0031236603\n",
      "[37] Validation loss: 0.0804946626\n",
      "[38] Train loss: 0.0033689176\n",
      "[38] Validation loss: 0.0829286037\n",
      "[39] Train loss: 0.0029368388\n",
      "[39] Validation loss: 0.0849562734\n",
      "[40] Train loss: 0.0031360339\n",
      "[40] Validation loss: 0.0848893849\n",
      "[41] Train loss: 0.0041621436\n",
      "[41] Validation loss: 0.0778334658\n",
      "[42] Train loss: 0.0035673853\n",
      "[42] Validation loss: 0.0795325485\n",
      "[43] Train loss: 0.0034470295\n",
      "[43] Validation loss: 0.0822888532\n",
      "[44] Train loss: 0.0030210289\n",
      "[44] Validation loss: 0.0855078334\n",
      "[45] Train loss: 0.0025848380\n",
      "[45] Validation loss: 0.0850268429\n",
      "[46] Train loss: 0.0028711942\n",
      "[46] Validation loss: 0.0800231326\n",
      "[47] Train loss: 0.0026206096\n",
      "[47] Validation loss: 0.0809090856\n",
      "[48] Train loss: 0.0025336926\n",
      "[48] Validation loss: 0.0861426870\n",
      "[49] Train loss: 0.0029407434\n",
      "[49] Validation loss: 0.0837802348\n",
      "[50] Train loss: 0.0028385076\n",
      "[50] Validation loss: 0.0839781770\n",
      "[51] Train loss: 0.0026533318\n",
      "[51] Validation loss: 0.0801812506\n",
      "[52] Train loss: 0.0033162082\n",
      "[52] Validation loss: 0.0856558115\n",
      "[53] Train loss: 0.0033613821\n",
      "[53] Validation loss: 0.0851665625\n",
      "[54] Train loss: 0.0034444204\n",
      "[54] Validation loss: 0.0863953987\n",
      "[55] Train loss: 0.0039483978\n",
      "[55] Validation loss: 0.0843776183\n",
      "[56] Train loss: 0.0046512938\n",
      "[56] Validation loss: 0.0897129455\n",
      "[57] Train loss: 0.0035822491\n",
      "[57] Validation loss: 0.0910524135\n",
      "[58] Train loss: 0.0032256605\n",
      "[58] Validation loss: 0.0886516014\n",
      "[59] Train loss: 0.0042116279\n",
      "[59] Validation loss: 0.0842408320\n",
      "[60] Train loss: 0.0055295043\n",
      "[60] Validation loss: 0.0917552269\n",
      "[61] Train loss: 0.0043099499\n",
      "[61] Validation loss: 0.0895014005\n",
      "[62] Train loss: 0.0041231825\n",
      "[62] Validation loss: 0.0905412024\n",
      "[63] Train loss: 0.0029457397\n",
      "[63] Validation loss: 0.0870604138\n",
      "[64] Train loss: 0.0034901860\n",
      "[64] Validation loss: 0.0917073613\n",
      "[65] Train loss: 0.0022211231\n",
      "[65] Validation loss: 0.0890156030\n",
      "[66] Train loss: 0.0025958067\n",
      "[66] Validation loss: 0.0901023195\n",
      "[67] Train loss: 0.0022872915\n",
      "[67] Validation loss: 0.0836412636\n",
      "[68] Train loss: 0.0022820838\n",
      "[68] Validation loss: 0.0877943376\n",
      "[69] Train loss: 0.0018584962\n",
      "[69] Validation loss: 0.0892640922\n",
      "[70] Train loss: 0.0019038422\n",
      "[70] Validation loss: 0.0876786478\n",
      "[71] Train loss: 0.0017291556\n",
      "[71] Validation loss: 0.0831179662\n",
      "[72] Train loss: 0.0019500371\n",
      "[72] Validation loss: 0.0817392005\n",
      "[73] Train loss: 0.0020162904\n",
      "[73] Validation loss: 0.0851244935\n",
      "[74] Train loss: 0.0025301229\n",
      "[74] Validation loss: 0.0818479698\n",
      "[75] Train loss: 0.0027512895\n",
      "[75] Validation loss: 0.0795807525\n",
      "[76] Train loss: 0.0033484134\n",
      "[76] Validation loss: 0.0821643644\n",
      "[77] Train loss: 0.0036079195\n",
      "[77] Validation loss: 0.0835567045\n",
      "[78] Train loss: 0.0049157159\n",
      "[78] Validation loss: 0.0809867164\n",
      "[79] Train loss: 0.0062621437\n",
      "[79] Validation loss: 0.0760911211\n",
      "[80] Train loss: 0.0064819771\n",
      "[80] Validation loss: 0.0809207496\n",
      "[81] Train loss: 0.0090690758\n",
      "[81] Validation loss: 0.0931525553\n",
      "[82] Train loss: 0.0118011608\n",
      "[82] Validation loss: 0.0793304675\n",
      "[83] Train loss: 0.0061144170\n",
      "[83] Validation loss: 0.0860747733\n",
      "[84] Train loss: 0.0041410642\n",
      "[84] Validation loss: 0.0930282784\n",
      "[85] Train loss: 0.0047339583\n",
      "[85] Validation loss: 0.0886506232\n",
      "[86] Train loss: 0.0042076399\n",
      "[86] Validation loss: 0.0907061063\n",
      "[87] Train loss: 0.0038551246\n",
      "[87] Validation loss: 0.1003964102\n",
      "[88] Train loss: 0.0037400738\n",
      "[88] Validation loss: 0.0923085456\n",
      "[89] Train loss: 0.0047844172\n",
      "[89] Validation loss: 0.1004502258\n",
      "[90] Train loss: 0.0039698784\n",
      "[90] Validation loss: 0.0975716813\n",
      "[91] Train loss: 0.0034573607\n",
      "[91] Validation loss: 0.0922074173\n",
      "[92] Train loss: 0.0035428535\n",
      "[92] Validation loss: 0.0886267092\n",
      "[93] Train loss: 0.0033737330\n",
      "[93] Validation loss: 0.0842495258\n",
      "[94] Train loss: 0.0037624216\n",
      "[94] Validation loss: 0.0900938726\n",
      "[95] Train loss: 0.0032621881\n",
      "[95] Validation loss: 0.0844075952\n",
      "[96] Train loss: 0.0035568115\n",
      "[96] Validation loss: 0.0851947586\n",
      "[97] Train loss: 0.0041006948\n",
      "[97] Validation loss: 0.0814848084\n",
      "[98] Train loss: 0.0047799472\n",
      "[98] Validation loss: 0.0807195820\n",
      "[99] Train loss: 0.0049742035\n",
      "[99] Validation loss: 0.0853338579\n",
      "[100] Train loss: 0.0058419164\n",
      "[100] Validation loss: 0.0837203515\n",
      "[101] Train loss: 0.0041111363\n",
      "[101] Validation loss: 0.0940447822\n",
      "[102] Train loss: 0.0056729976\n",
      "[102] Validation loss: 0.0889029465\n",
      "[103] Train loss: 0.0040494448\n",
      "[103] Validation loss: 0.0959398277\n",
      "[104] Train loss: 0.0043499402\n",
      "[104] Validation loss: 0.0934577477\n",
      "[105] Train loss: 0.0047513034\n",
      "[105] Validation loss: 0.1007652699\n",
      "[106] Train loss: 0.0045414135\n",
      "[106] Validation loss: 0.0969836166\n",
      "[107] Train loss: 0.0055108363\n",
      "[107] Validation loss: 0.0920519206\n",
      "[108] Train loss: 0.0046851074\n",
      "[108] Validation loss: 0.0867456749\n",
      "[109] Train loss: 0.0045398543\n",
      "[109] Validation loss: 0.0833041289\n",
      "[110] Train loss: 0.0040268747\n",
      "[110] Validation loss: 0.0829690343\n",
      "[111] Train loss: 0.0039285411\n",
      "[111] Validation loss: 0.0819155768\n",
      "[112] Train loss: 0.0040399938\n",
      "[112] Validation loss: 0.0833474186\n",
      "[113] Train loss: 0.0053887743\n",
      "[113] Validation loss: 0.0846654907\n",
      "[114] Train loss: 0.0062755461\n",
      "[114] Validation loss: 0.0886407704\n",
      "[115] Train loss: 0.0059066601\n",
      "[115] Validation loss: 0.0977051971\n",
      "[116] Train loss: 0.0056447911\n",
      "[116] Validation loss: 0.1039171897\n",
      "[117] Train loss: 0.0052758656\n",
      "[117] Validation loss: 0.1015812005\n",
      "[118] Train loss: 0.0067762100\n",
      "[118] Validation loss: 0.0969479717\n",
      "[119] Train loss: 0.0054634055\n",
      "[119] Validation loss: 0.0886911011\n",
      "[120] Train loss: 0.0078870222\n",
      "[120] Validation loss: 0.0875840923\n",
      "[121] Train loss: 0.0049296464\n",
      "[121] Validation loss: 0.0824207352\n",
      "[122] Train loss: 0.0050780211\n",
      "[122] Validation loss: 0.0820151069\n",
      "[123] Train loss: 0.0053967277\n",
      "[123] Validation loss: 0.0844968549\n",
      "[124] Train loss: 0.0054169421\n",
      "[124] Validation loss: 0.0881350170\n",
      "[125] Train loss: 0.0047171884\n",
      "[125] Validation loss: 0.0998097964\n",
      "[126] Train loss: 0.0049309247\n",
      "[126] Validation loss: 0.1044898292\n",
      "[127] Train loss: 0.0037471767\n",
      "[127] Validation loss: 0.0997426035\n",
      "[128] Train loss: 0.0034146784\n",
      "[128] Validation loss: 0.0931554497\n",
      "[129] Train loss: 0.0037759593\n",
      "[129] Validation loss: 0.0898676399\n",
      "[130] Train loss: 0.0026378806\n",
      "[130] Validation loss: 0.0859503343\n",
      "[131] Train loss: 0.0024261300\n",
      "[131] Validation loss: 0.0846888109\n",
      "[132] Train loss: 0.0026778287\n",
      "[132] Validation loss: 0.0862722037\n",
      "[133] Train loss: 0.0027216320\n",
      "[133] Validation loss: 0.0878080678\n",
      "[134] Train loss: 0.0026836334\n",
      "[134] Validation loss: 0.0951563440\n",
      "[135] Train loss: 0.0022637865\n",
      "[135] Validation loss: 0.0989461701\n",
      "[136] Train loss: 0.0020539906\n",
      "[136] Validation loss: 0.0977828969\n",
      "[137] Train loss: 0.0024481479\n",
      "[137] Validation loss: 0.0966917473\n",
      "[138] Train loss: 0.0021947505\n",
      "[138] Validation loss: 0.0859975631\n",
      "[139] Train loss: 0.0028943456\n",
      "[139] Validation loss: 0.0894147546\n",
      "[140] Train loss: 0.0020853844\n",
      "[140] Validation loss: 0.0836811253\n",
      "[141] Train loss: 0.0019950148\n",
      "[141] Validation loss: 0.0867402117\n",
      "[142] Train loss: 0.0027604783\n",
      "[142] Validation loss: 0.0881844066\n",
      "[143] Train loss: 0.0035853523\n",
      "[143] Validation loss: 0.0903771064\n",
      "[144] Train loss: 0.0029246331\n",
      "[144] Validation loss: 0.0979859352\n",
      "[145] Train loss: 0.0036150074\n",
      "[145] Validation loss: 0.0949678914\n",
      "[146] Train loss: 0.0032014223\n",
      "[146] Validation loss: 0.1000355739\n",
      "[147] Train loss: 0.0030795967\n",
      "[147] Validation loss: 0.0901826530\n",
      "[148] Train loss: 0.0029597902\n",
      "[148] Validation loss: 0.0890829161\n",
      "[149] Train loss: 0.0021145765\n",
      "[149] Validation loss: 0.0862545896\n",
      "[150] Train loss: 0.0015436961\n",
      "[150] Validation loss: 0.0830766884\n",
      "[151] Train loss: 0.0017139425\n",
      "[151] Validation loss: 0.0883115101\n",
      "[152] Train loss: 0.0020370949\n",
      "[152] Validation loss: 0.0865365905\n",
      "[153] Train loss: 0.0017041319\n",
      "[153] Validation loss: 0.0943789859\n",
      "[154] Train loss: 0.0019486778\n",
      "[154] Validation loss: 0.0945542683\n",
      "[155] Train loss: 0.0020242023\n",
      "[155] Validation loss: 0.0988575669\n",
      "[156] Train loss: 0.0019726918\n",
      "[156] Validation loss: 0.0960582560\n",
      "[157] Train loss: 0.0024406678\n",
      "[157] Validation loss: 0.0900500593\n",
      "[158] Train loss: 0.0028582382\n",
      "[158] Validation loss: 0.0898330275\n",
      "[159] Train loss: 0.0019552814\n",
      "[159] Validation loss: 0.0833740686\n",
      "[160] Train loss: 0.0026501928\n",
      "[160] Validation loss: 0.0866384415\n",
      "[161] Train loss: 0.0026175673\n",
      "[161] Validation loss: 0.0829336633\n",
      "[162] Train loss: 0.0022381573\n",
      "[162] Validation loss: 0.0899929631\n",
      "[163] Train loss: 0.0034751647\n",
      "[163] Validation loss: 0.0892943489\n",
      "[164] Train loss: 0.0031351808\n",
      "[164] Validation loss: 0.0998229289\n",
      "[165] Train loss: 0.0028550645\n",
      "[165] Validation loss: 0.1003872711\n",
      "[166] Train loss: 0.0041556415\n",
      "[166] Validation loss: 0.0956704183\n",
      "[167] Train loss: 0.0036802269\n",
      "[167] Validation loss: 0.0951779352\n",
      "[168] Train loss: 0.0037714493\n",
      "[168] Validation loss: 0.0867139043\n",
      "[169] Train loss: 0.0054366041\n",
      "[169] Validation loss: 0.0888557103\n",
      "[170] Train loss: 0.0038124067\n",
      "[170] Validation loss: 0.0833967104\n",
      "[171] Train loss: 0.0033046204\n",
      "[171] Validation loss: 0.0857112961\n",
      "[172] Train loss: 0.0032792227\n",
      "[172] Validation loss: 0.0864057683\n",
      "[173] Train loss: 0.0030439530\n",
      "[173] Validation loss: 0.0911266716\n",
      "[174] Train loss: 0.0028790114\n",
      "[174] Validation loss: 0.0980147646\n",
      "[175] Train loss: 0.0028861577\n",
      "[175] Validation loss: 0.0990228085\n",
      "[176] Train loss: 0.0022175776\n",
      "[176] Validation loss: 0.1005144968\n",
      "[177] Train loss: 0.0022184470\n",
      "[177] Validation loss: 0.0936147029\n",
      "[178] Train loss: 0.0022376987\n",
      "[178] Validation loss: 0.0887812045\n",
      "[179] Train loss: 0.0017800651\n",
      "[179] Validation loss: 0.0871929664\n",
      "[180] Train loss: 0.0016879297\n",
      "[180] Validation loss: 0.0843252984\n",
      "[181] Train loss: 0.0015724865\n",
      "[181] Validation loss: 0.0867506054\n",
      "[182] Train loss: 0.0020272997\n",
      "[182] Validation loss: 0.0878482623\n",
      "[183] Train loss: 0.0021829861\n",
      "[183] Validation loss: 0.0931240277\n",
      "[184] Train loss: 0.0019745820\n",
      "[184] Validation loss: 0.1013132746\n",
      "[185] Train loss: 0.0022545319\n",
      "[185] Validation loss: 0.1010577412\n",
      "[186] Train loss: 0.0024030323\n",
      "[186] Validation loss: 0.0998052546\n",
      "[187] Train loss: 0.0024907314\n",
      "[187] Validation loss: 0.0906024241\n",
      "[188] Train loss: 0.0030218932\n",
      "[188] Validation loss: 0.0869340975\n",
      "[189] Train loss: 0.0025552415\n",
      "[189] Validation loss: 0.0897810841\n",
      "[190] Train loss: 0.0027651811\n",
      "[190] Validation loss: 0.0852769974\n",
      "[191] Train loss: 0.0032619712\n",
      "[191] Validation loss: 0.0888572563\n",
      "[192] Train loss: 0.0037077049\n",
      "[192] Validation loss: 0.0885319733\n",
      "[193] Train loss: 0.0037700643\n",
      "[193] Validation loss: 0.0936021558\n",
      "[194] Train loss: 0.0028879939\n",
      "[194] Validation loss: 0.1060954582\n",
      "[195] Train loss: 0.0032379657\n",
      "[195] Validation loss: 0.1031731039\n",
      "[196] Train loss: 0.0039335112\n",
      "[196] Validation loss: 0.0997517126\n",
      "[197] Train loss: 0.0034936314\n",
      "[197] Validation loss: 0.0870136295\n",
      "[198] Train loss: 0.0037736051\n",
      "[198] Validation loss: 0.0857607177\n",
      "[199] Train loss: 0.0028076055\n",
      "[199] Validation loss: 0.0873422375\n",
      "[200] Train loss: 0.0023243813\n",
      "[200] Validation loss: 0.0876055720\n",
      "4 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n",
      "[1] Train loss: 0.1397097768\n",
      "[1] Validation loss: 0.0386474644\n",
      "model saved\n",
      "[2] Train loss: 0.0750551982\n",
      "[2] Validation loss: 0.0354957388\n",
      "model saved\n",
      "[3] Train loss: 0.0345938557\n",
      "[3] Validation loss: 0.0292354149\n",
      "model saved\n",
      "[4] Train loss: 0.0221170046\n",
      "[4] Validation loss: 0.0274092044\n",
      "model saved\n",
      "[5] Train loss: 0.0150112254\n",
      "[5] Validation loss: 0.0274790388\n",
      "[6] Train loss: 0.0101771909\n",
      "[6] Validation loss: 0.0289575158\n",
      "[7] Train loss: 0.0074195264\n",
      "[7] Validation loss: 0.0306268922\n",
      "[8] Train loss: 0.0051455514\n",
      "[8] Validation loss: 0.0302291499\n",
      "[9] Train loss: 0.0046372437\n",
      "[9] Validation loss: 0.0306252294\n",
      "[10] Train loss: 0.0039804356\n",
      "[10] Validation loss: 0.0289272368\n",
      "[11] Train loss: 0.0037121520\n",
      "[11] Validation loss: 0.0270006782\n",
      "model saved\n",
      "[12] Train loss: 0.0028678818\n",
      "[12] Validation loss: 0.0254360815\n",
      "model saved\n",
      "[13] Train loss: 0.0023825095\n",
      "[13] Validation loss: 0.0251166674\n",
      "model saved\n",
      "[14] Train loss: 0.0021592604\n",
      "[14] Validation loss: 0.0259839270\n",
      "[15] Train loss: 0.0018637079\n",
      "[15] Validation loss: 0.0276429829\n",
      "[16] Train loss: 0.0016744224\n",
      "[16] Validation loss: 0.0284688132\n",
      "[17] Train loss: 0.0017073265\n",
      "[17] Validation loss: 0.0296725489\n",
      "[18] Train loss: 0.0017182477\n",
      "[18] Validation loss: 0.0295724847\n",
      "[19] Train loss: 0.0018744690\n",
      "[19] Validation loss: 0.0276081874\n",
      "[20] Train loss: 0.0023470536\n",
      "[20] Validation loss: 0.0283445931\n",
      "[21] Train loss: 0.0025064231\n",
      "[21] Validation loss: 0.0246786283\n",
      "model saved\n",
      "[22] Train loss: 0.0031136867\n",
      "[22] Validation loss: 0.0271324876\n",
      "[23] Train loss: 0.0030537498\n",
      "[23] Validation loss: 0.0246823933\n",
      "[24] Train loss: 0.0037488566\n",
      "[24] Validation loss: 0.0276300526\n",
      "[25] Train loss: 0.0044733314\n",
      "[25] Validation loss: 0.0290468639\n",
      "[26] Train loss: 0.0041100822\n",
      "[26] Validation loss: 0.0313421015\n",
      "[27] Train loss: 0.0046589483\n",
      "[27] Validation loss: 0.0322752809\n",
      "[28] Train loss: 0.0042802733\n",
      "[28] Validation loss: 0.0302786278\n",
      "[29] Train loss: 0.0047197918\n",
      "[29] Validation loss: 0.0284291450\n",
      "[30] Train loss: 0.0042071222\n",
      "[30] Validation loss: 0.0263098703\n",
      "[31] Train loss: 0.0030652021\n",
      "[31] Validation loss: 0.0265856762\n",
      "[32] Train loss: 0.0028322761\n",
      "[32] Validation loss: 0.0263812132\n",
      "[33] Train loss: 0.0026886982\n",
      "[33] Validation loss: 0.0284454279\n",
      "[34] Train loss: 0.0028871417\n",
      "[34] Validation loss: 0.0274517040\n",
      "[35] Train loss: 0.0028626863\n",
      "[35] Validation loss: 0.0325609715\n",
      "[36] Train loss: 0.0031584813\n",
      "[36] Validation loss: 0.0324347252\n",
      "[37] Train loss: 0.0035193886\n",
      "[37] Validation loss: 0.0334178837\n",
      "[38] Train loss: 0.0037309148\n",
      "[38] Validation loss: 0.0288048123\n",
      "[39] Train loss: 0.0035921439\n",
      "[39] Validation loss: 0.0279205202\n",
      "[40] Train loss: 0.0035593153\n",
      "[40] Validation loss: 0.0251079165\n",
      "[41] Train loss: 0.0029922778\n",
      "[41] Validation loss: 0.0259416001\n",
      "[42] Train loss: 0.0034839289\n",
      "[42] Validation loss: 0.0275036963\n",
      "[43] Train loss: 0.0036827501\n",
      "[43] Validation loss: 0.0287104942\n",
      "[44] Train loss: 0.0041752873\n",
      "[44] Validation loss: 0.0328011426\n",
      "[45] Train loss: 0.0047235756\n",
      "[45] Validation loss: 0.0342616681\n",
      "[46] Train loss: 0.0043885838\n",
      "[46] Validation loss: 0.0353626402\n",
      "[47] Train loss: 0.0050771498\n",
      "[47] Validation loss: 0.0305531244\n",
      "[48] Train loss: 0.0059653668\n",
      "[48] Validation loss: 0.0300701348\n",
      "[49] Train loss: 0.0047876632\n",
      "[49] Validation loss: 0.0259065279\n",
      "[50] Train loss: 0.0053296270\n",
      "[50] Validation loss: 0.0281819044\n",
      "[51] Train loss: 0.0054979699\n",
      "[51] Validation loss: 0.0270172552\n",
      "[52] Train loss: 0.0060112561\n",
      "[52] Validation loss: 0.0304624771\n",
      "[53] Train loss: 0.0052734213\n",
      "[53] Validation loss: 0.0328380596\n",
      "[54] Train loss: 0.0047786971\n",
      "[54] Validation loss: 0.0367502756\n",
      "[55] Train loss: 0.0053053044\n",
      "[55] Validation loss: 0.0350776202\n",
      "[56] Train loss: 0.0037112888\n",
      "[56] Validation loss: 0.0321571831\n",
      "[57] Train loss: 0.0048689447\n",
      "[57] Validation loss: 0.0262468175\n",
      "[58] Train loss: 0.0043227871\n",
      "[58] Validation loss: 0.0274936452\n",
      "[59] Train loss: 0.0038468952\n",
      "[59] Validation loss: 0.0283520331\n",
      "[60] Train loss: 0.0045457988\n",
      "[60] Validation loss: 0.0284461538\n",
      "[61] Train loss: 0.0038692312\n",
      "[61] Validation loss: 0.0326516787\n",
      "[62] Train loss: 0.0034585858\n",
      "[62] Validation loss: 0.0331412354\n",
      "[63] Train loss: 0.0031111613\n",
      "[63] Validation loss: 0.0345773124\n",
      "[64] Train loss: 0.0026486906\n",
      "[64] Validation loss: 0.0309436033\n",
      "[65] Train loss: 0.0021031635\n",
      "[65] Validation loss: 0.0286566845\n",
      "[66] Train loss: 0.0015833925\n",
      "[66] Validation loss: 0.0264602877\n",
      "[67] Train loss: 0.0015032842\n",
      "[67] Validation loss: 0.0277217036\n",
      "[68] Train loss: 0.0013519140\n",
      "[68] Validation loss: 0.0283902009\n",
      "[69] Train loss: 0.0013306202\n",
      "[69] Validation loss: 0.0317218764\n",
      "[70] Train loss: 0.0016723109\n",
      "[70] Validation loss: 0.0329808622\n",
      "[71] Train loss: 0.0013181186\n",
      "[71] Validation loss: 0.0344845015\n",
      "[72] Train loss: 0.0013851246\n",
      "[72] Validation loss: 0.0326232572\n",
      "[73] Train loss: 0.0017652359\n",
      "[73] Validation loss: 0.0307504273\n",
      "[74] Train loss: 0.0015938925\n",
      "[74] Validation loss: 0.0271978629\n",
      "[75] Train loss: 0.0015865966\n",
      "[75] Validation loss: 0.0277613377\n",
      "[76] Train loss: 0.0016479764\n",
      "[76] Validation loss: 0.0270322627\n",
      "[77] Train loss: 0.0020311235\n",
      "[77] Validation loss: 0.0303420831\n",
      "[78] Train loss: 0.0024522408\n",
      "[78] Validation loss: 0.0320104894\n",
      "[79] Train loss: 0.0023831298\n",
      "[79] Validation loss: 0.0361458456\n",
      "[80] Train loss: 0.0030804654\n",
      "[80] Validation loss: 0.0360535479\n",
      "[81] Train loss: 0.0038629920\n",
      "[81] Validation loss: 0.0335538077\n",
      "[82] Train loss: 0.0059398223\n",
      "[82] Validation loss: 0.0292355895\n",
      "[83] Train loss: 0.0063329920\n",
      "[83] Validation loss: 0.0268556639\n",
      "[84] Train loss: 0.0059679419\n",
      "[84] Validation loss: 0.0275210665\n",
      "[85] Train loss: 0.0067062943\n",
      "[85] Validation loss: 0.0280405974\n",
      "[86] Train loss: 0.0054745198\n",
      "[86] Validation loss: 0.0306575063\n",
      "[87] Train loss: 0.0095218666\n",
      "[87] Validation loss: 0.0347411139\n",
      "[88] Train loss: 0.0067005026\n",
      "[88] Validation loss: 0.0383988579\n",
      "[89] Train loss: 0.0051528809\n",
      "[89] Validation loss: 0.0350239218\n",
      "[90] Train loss: 0.0036224187\n",
      "[90] Validation loss: 0.0316390849\n",
      "[91] Train loss: 0.0020875879\n",
      "[91] Validation loss: 0.0289415819\n",
      "[92] Train loss: 0.0016048510\n",
      "[92] Validation loss: 0.0281583632\n",
      "[93] Train loss: 0.0014767604\n",
      "[93] Validation loss: 0.0272639774\n",
      "[94] Train loss: 0.0014726147\n",
      "[94] Validation loss: 0.0313533759\n",
      "[95] Train loss: 0.0018625896\n",
      "[95] Validation loss: 0.0331122905\n",
      "[96] Train loss: 0.0017272403\n",
      "[96] Validation loss: 0.0360051407\n",
      "[97] Train loss: 0.0015257632\n",
      "[97] Validation loss: 0.0331305069\n",
      "[98] Train loss: 0.0016109052\n",
      "[98] Validation loss: 0.0309897396\n",
      "[99] Train loss: 0.0013903613\n",
      "[99] Validation loss: 0.0272418971\n",
      "[100] Train loss: 0.0013375200\n",
      "[100] Validation loss: 0.0281872335\n",
      "[101] Train loss: 0.0013920252\n",
      "[101] Validation loss: 0.0276463458\n",
      "[102] Train loss: 0.0015207942\n",
      "[102] Validation loss: 0.0311982681\n",
      "[103] Train loss: 0.0021403346\n",
      "[103] Validation loss: 0.0339218513\n",
      "[104] Train loss: 0.0022043100\n",
      "[104] Validation loss: 0.0379038868\n",
      "[105] Train loss: 0.0023309103\n",
      "[105] Validation loss: 0.0342787470\n",
      "[106] Train loss: 0.0028866848\n",
      "[106] Validation loss: 0.0326154400\n",
      "[107] Train loss: 0.0028832113\n",
      "[107] Validation loss: 0.0270161113\n",
      "[108] Train loss: 0.0029650892\n",
      "[108] Validation loss: 0.0281075789\n",
      "[109] Train loss: 0.0029434508\n",
      "[109] Validation loss: 0.0271027983\n",
      "[110] Train loss: 0.0028848476\n",
      "[110] Validation loss: 0.0295613029\n",
      "[111] Train loss: 0.0038343613\n",
      "[111] Validation loss: 0.0333575049\n",
      "[112] Train loss: 0.0042045194\n",
      "[112] Validation loss: 0.0403472575\n",
      "[113] Train loss: 0.0044256360\n",
      "[113] Validation loss: 0.0363740035\n",
      "[114] Train loss: 0.0054636985\n",
      "[114] Validation loss: 0.0357073850\n",
      "[115] Train loss: 0.0055382686\n",
      "[115] Validation loss: 0.0272099282\n",
      "[116] Train loss: 0.0043831917\n",
      "[116] Validation loss: 0.0283887866\n",
      "[117] Train loss: 0.0038377352\n",
      "[117] Validation loss: 0.0272246835\n",
      "[118] Train loss: 0.0030414420\n",
      "[118] Validation loss: 0.0296428210\n",
      "[119] Train loss: 0.0036104696\n",
      "[119] Validation loss: 0.0352266995\n",
      "[120] Train loss: 0.0032205479\n",
      "[120] Validation loss: 0.0382868175\n",
      "[121] Train loss: 0.0029290515\n",
      "[121] Validation loss: 0.0370275392\n",
      "[122] Train loss: 0.0032723911\n",
      "[122] Validation loss: 0.0313902164\n",
      "[123] Train loss: 0.0027155281\n",
      "[123] Validation loss: 0.0271256863\n",
      "[124] Train loss: 0.0024979637\n",
      "[124] Validation loss: 0.0277991037\n",
      "[125] Train loss: 0.0023043513\n",
      "[125] Validation loss: 0.0283861055\n",
      "[126] Train loss: 0.0025118261\n",
      "[126] Validation loss: 0.0326488415\n",
      "[127] Train loss: 0.0026399928\n",
      "[127] Validation loss: 0.0360695374\n",
      "[128] Train loss: 0.0026585790\n",
      "[128] Validation loss: 0.0379988266\n",
      "[129] Train loss: 0.0027772350\n",
      "[129] Validation loss: 0.0341686553\n",
      "[130] Train loss: 0.0033011699\n",
      "[130] Validation loss: 0.0301673933\n",
      "[131] Train loss: 0.0032559297\n",
      "[131] Validation loss: 0.0276042841\n",
      "[132] Train loss: 0.0029695910\n",
      "[132] Validation loss: 0.0285370621\n",
      "[133] Train loss: 0.0030961517\n",
      "[133] Validation loss: 0.0299050668\n",
      "[134] Train loss: 0.0028977814\n",
      "[134] Validation loss: 0.0354076466\n",
      "[135] Train loss: 0.0027779724\n",
      "[135] Validation loss: 0.0367822549\n",
      "[136] Train loss: 0.0030417122\n",
      "[136] Validation loss: 0.0371205895\n",
      "[137] Train loss: 0.0029619791\n",
      "[137] Validation loss: 0.0307613975\n",
      "[138] Train loss: 0.0026082729\n",
      "[138] Validation loss: 0.0297905465\n",
      "[139] Train loss: 0.0021617778\n",
      "[139] Validation loss: 0.0274154793\n",
      "[140] Train loss: 0.0022130212\n",
      "[140] Validation loss: 0.0296325737\n",
      "[141] Train loss: 0.0024570436\n",
      "[141] Validation loss: 0.0336591553\n",
      "[142] Train loss: 0.0025565309\n",
      "[142] Validation loss: 0.0380141682\n",
      "[143] Train loss: 0.0023804029\n",
      "[143] Validation loss: 0.0361120677\n",
      "[144] Train loss: 0.0031214388\n",
      "[144] Validation loss: 0.0328409810\n",
      "[145] Train loss: 0.0025409397\n",
      "[145] Validation loss: 0.0285101827\n",
      "[146] Train loss: 0.0023466676\n",
      "[146] Validation loss: 0.0289970153\n",
      "[147] Train loss: 0.0021937724\n",
      "[147] Validation loss: 0.0286783428\n",
      "[148] Train loss: 0.0021220241\n",
      "[148] Validation loss: 0.0328877456\n",
      "[149] Train loss: 0.0021910440\n",
      "[149] Validation loss: 0.0364999333\n",
      "[150] Train loss: 0.0023292590\n",
      "[150] Validation loss: 0.0378966628\n",
      "[151] Train loss: 0.0023730197\n",
      "[151] Validation loss: 0.0335837382\n",
      "[152] Train loss: 0.0024793792\n",
      "[152] Validation loss: 0.0300531922\n",
      "[153] Train loss: 0.0021577625\n",
      "[153] Validation loss: 0.0278066778\n",
      "[154] Train loss: 0.0019709803\n",
      "[154] Validation loss: 0.0286449575\n",
      "[155] Train loss: 0.0021757375\n",
      "[155] Validation loss: 0.0324580742\n",
      "[156] Train loss: 0.0024851047\n",
      "[156] Validation loss: 0.0355843781\n",
      "[157] Train loss: 0.0022458455\n",
      "[157] Validation loss: 0.0389075971\n",
      "[158] Train loss: 0.0032479660\n",
      "[158] Validation loss: 0.0354910984\n",
      "[159] Train loss: 0.0033133086\n",
      "[159] Validation loss: 0.0314543107\n",
      "[160] Train loss: 0.0031478173\n",
      "[160] Validation loss: 0.0291348649\n",
      "[161] Train loss: 0.0032276474\n",
      "[161] Validation loss: 0.0289786947\n",
      "[162] Train loss: 0.0029916543\n",
      "[162] Validation loss: 0.0302164629\n",
      "[163] Train loss: 0.0036592643\n",
      "[163] Validation loss: 0.0333459480\n",
      "[164] Train loss: 0.0033093737\n",
      "[164] Validation loss: 0.0388790150\n",
      "[165] Train loss: 0.0032913373\n",
      "[165] Validation loss: 0.0367518009\n",
      "[166] Train loss: 0.0040567739\n",
      "[166] Validation loss: 0.0343287008\n",
      "[167] Train loss: 0.0030185937\n",
      "[167] Validation loss: 0.0301413402\n",
      "[168] Train loss: 0.0024582715\n",
      "[168] Validation loss: 0.0299692915\n",
      "[169] Train loss: 0.0022191427\n",
      "[169] Validation loss: 0.0289662785\n",
      "[170] Train loss: 0.0018271622\n",
      "[170] Validation loss: 0.0338972132\n",
      "[171] Train loss: 0.0019187898\n",
      "[171] Validation loss: 0.0368188392\n",
      "[172] Train loss: 0.0017714012\n",
      "[172] Validation loss: 0.0386026878\n",
      "[173] Train loss: 0.0016072527\n",
      "[173] Validation loss: 0.0346412376\n",
      "[174] Train loss: 0.0020560416\n",
      "[174] Validation loss: 0.0306113121\n",
      "[175] Train loss: 0.0015534897\n",
      "[175] Validation loss: 0.0295490114\n",
      "[176] Train loss: 0.0014819581\n",
      "[176] Validation loss: 0.0299817150\n",
      "[177] Train loss: 0.0013323212\n",
      "[177] Validation loss: 0.0308148856\n",
      "[178] Train loss: 0.0020184841\n",
      "[178] Validation loss: 0.0366480167\n",
      "[179] Train loss: 0.0018508132\n",
      "[179] Validation loss: 0.0379830966\n",
      "[180] Train loss: 0.0019581365\n",
      "[180] Validation loss: 0.0359585467\n",
      "[181] Train loss: 0.0022850122\n",
      "[181] Validation loss: 0.0334776049\n",
      "[182] Train loss: 0.0020487232\n",
      "[182] Validation loss: 0.0294419062\n",
      "[183] Train loss: 0.0020974114\n",
      "[183] Validation loss: 0.0295578728\n",
      "[184] Train loss: 0.0019820665\n",
      "[184] Validation loss: 0.0288061096\n",
      "[185] Train loss: 0.0020637174\n",
      "[185] Validation loss: 0.0351175167\n",
      "[186] Train loss: 0.0022960636\n",
      "[186] Validation loss: 0.0370594998\n",
      "[187] Train loss: 0.0024919675\n",
      "[187] Validation loss: 0.0404407772\n",
      "[188] Train loss: 0.0029617877\n",
      "[188] Validation loss: 0.0345834736\n",
      "[189] Train loss: 0.0028282616\n",
      "[189] Validation loss: 0.0329406814\n",
      "[190] Train loss: 0.0028413012\n",
      "[190] Validation loss: 0.0279927746\n",
      "[191] Train loss: 0.0030578340\n",
      "[191] Validation loss: 0.0305197624\n",
      "[192] Train loss: 0.0030177292\n",
      "[192] Validation loss: 0.0302629507\n",
      "[193] Train loss: 0.0027680877\n",
      "[193] Validation loss: 0.0377029716\n",
      "[194] Train loss: 0.0033461724\n",
      "[194] Validation loss: 0.0391309229\n",
      "[195] Train loss: 0.0043278636\n",
      "[195] Validation loss: 0.0394047694\n",
      "[196] Train loss: 0.0041916208\n",
      "[196] Validation loss: 0.0320726553\n",
      "[197] Train loss: 0.0035972681\n",
      "[197] Validation loss: 0.0315311594\n",
      "[198] Train loss: 0.0027278227\n",
      "[198] Validation loss: 0.0285191990\n",
      "[199] Train loss: 0.0022358577\n",
      "[199] Validation loss: 0.0313168028\n",
      "[200] Train loss: 0.0025647465\n",
      "[200] Validation loss: 0.0333690293\n",
      "5 번째, 학습데이터 크기 : 812, 검증데이터 크기 : 203\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=41)\n",
    "model = Regressor()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=1e-7)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "\n",
    "    trainsets = TensorData(X_train, Y_train)\n",
    "    valsets = TensorData(X_val, Y_val)\n",
    "\n",
    "    trainloader = DataLoader(trainsets, batch_size=CFG[\"BATCH_SIZE\"])\n",
    "    valloader = DataLoader(valsets, batch_size=CFG[\"BATCH_SIZE\"])\n",
    "\n",
    "    train(model, optimizer, trainloader, valloader)\n",
    "\n",
    "    n_iter += 1\n",
    "    torch.save(model.state_dict(), dirpath + \"best_model/\" + str(n_iter) +\"last_model.pth\")\n",
    "    print('{} 번째, 학습데이터 크기 : {}, 검증데이터 크기 : {}'.format(n_iter, X_train.shape[0], X_val.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "plt.clf()\n",
    "# plt.plot(loss_,'ro',label='training loss')\n",
    "plt.plot(val_loss_,'g',label='validation loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}