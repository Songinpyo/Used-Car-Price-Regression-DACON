{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This is file for train, prediction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dirpath = 'C:/Users/rihot/Desktop/Deep_learning/DACON_used_car_price/'\n",
    "\n",
    "train = pd.read_csv('data/preprocessed_train.csv')\n",
    "test = pd.read_csv('data/preprocessed_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "Y = train[ ['target'] ].values\n",
    "X = train[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values\n",
    "\n",
    "X_test = test[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((1015, 10), (1015, 1))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n",
    "scalerY = MinMaxScaler()\n",
    "scalerY.fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "def LGBM(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        \"n_estimators\" : trial.suggest_int('n_estimators', 500, 4000),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        'learning_rate': 0.01,\n",
    "        'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree',0.5, 1, 0.1),\n",
    "        'nthread' : -1,\n",
    "        'tree_method': 'hist',\n",
    "        'predictor': 'cpu_predictor',\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = LGBMRegressor(**param)\n",
    "    LGBM_model = model.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n",
    "    score = mean_squared_error(LGBM_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-02 15:31:43,348]\u001B[0m A new study created in memory with name: no-name-60ddd04b-bba5-427d-b02f-c778a9be0aac\u001B[0m\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:1487: UserWarning: predictor keyword has been found in `params` and will be ignored.\n",
      "Please use predictor argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: predictor\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.001108756212651572. Current value: lambda_l2=0.001108756212651572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-02 15:31:44,833]\u001B[0m Trial 0 finished with value: 0.05127271337130929 and parameters: {'n_estimators': 1292, 'max_depth': 8, 'colsample_bytree': 0.6, 'lambda': 0.001108756212651572, 'alpha': 0.003128240936599907, 'subsample': 1.0}. Best is trial 0 with value: 0.05127271337130929.\u001B[0m\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:1487: UserWarning: predictor keyword has been found in `params` and will be ignored.\n",
      "Please use predictor argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: predictor\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.007899104394606527. Current value: lambda_l2=0.007899104394606527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-02 15:31:47,427]\u001B[0m Trial 1 finished with value: 0.039180613212411834 and parameters: {'n_estimators': 3424, 'max_depth': 8, 'colsample_bytree': 0.6, 'lambda': 0.007899104394606527, 'alpha': 0.4699235098517489, 'subsample': 0.6}. Best is trial 1 with value: 0.039180613212411834.\u001B[0m\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:1487: UserWarning: predictor keyword has been found in `params` and will be ignored.\n",
      "Please use predictor argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: predictor\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.002512232952810003. Current value: lambda_l2=0.002512232952810003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-02 15:31:50,707]\u001B[0m Trial 2 finished with value: 0.07390562028728377 and parameters: {'n_estimators': 3358, 'max_depth': 12, 'colsample_bytree': 0.8, 'lambda': 0.002512232952810003, 'alpha': 9.139877522567168, 'subsample': 1.0}. Best is trial 1 with value: 0.039180613212411834.\u001B[0m\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:1487: UserWarning: predictor keyword has been found in `params` and will be ignored.\n",
      "Please use predictor argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
      "C:\\Users\\rihot\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: predictor\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=1.8562768699973728. Current value: lambda_l2=1.8562768699973728\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01moptuna\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msamplers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TPESampler\n\u001B[0;32m      3\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m,sampler\u001B[38;5;241m=\u001B[39mTPESampler())\n\u001B[1;32m----> 4\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mLGBM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest trial: score \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mparams \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(study\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mvalue,study\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mparams))\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\optuna\\study\\study.py:400\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    393\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    394\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    395\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis feature will be removed in v4.0.0. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    396\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    397\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    398\u001B[0m     )\n\u001B[1;32m--> 400\u001B[0m \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m show_progress_bar:\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    210\u001B[0m     thread\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 213\u001B[0m     value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01moptuna\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msamplers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TPESampler\n\u001B[0;32m      3\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m,sampler\u001B[38;5;241m=\u001B[39mTPESampler())\n\u001B[1;32m----> 4\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(\u001B[38;5;28;01mlambda\u001B[39;00m trial : \u001B[43mLGBM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m, n_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest trial: score \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mparams \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(study\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mvalue,study\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mparams))\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mLGBM\u001B[1;34m(trial, X, Y, test)\u001B[0m\n\u001B[0;32m     25\u001B[0m y_test  \u001B[38;5;241m=\u001B[39m y_test\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     27\u001B[0m model \u001B[38;5;241m=\u001B[39m LGBMRegressor(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparam)\n\u001B[1;32m---> 28\u001B[0m LGBM_model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m score \u001B[38;5;241m=\u001B[39m mean_squared_error(LGBM_model\u001B[38;5;241m.\u001B[39mpredict(X_test), y_test, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m score\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001B[0m, in \u001B[0;36mLGBMRegressor.fit\u001B[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[0;32m    888\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y,\n\u001B[0;32m    889\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, init_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    890\u001B[0m         eval_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, eval_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, eval_sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    891\u001B[0m         eval_init_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, eval_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, early_stopping_rounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    892\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m'\u001B[39m, feature_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, categorical_feature\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    893\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, init_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 895\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m                \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_sample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m                \u001B[49m\u001B[43meval_init_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_init_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m                \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    899\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcategorical_feature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcategorical_feature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[0;32m    745\u001B[0m evals_result \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    746\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mappend(record_evaluation(evals_result))\n\u001B[1;32m--> 748\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    749\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    751\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_estimators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    752\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_sets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    753\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    755\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metrics_callable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    756\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evals_result:\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evals_result \u001B[38;5;241m=\u001B[39m evals_result\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\engine.py:292\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cb \u001B[38;5;129;01min\u001B[39;00m callbacks_before_iter:\n\u001B[0;32m    285\u001B[0m     cb(callback\u001B[38;5;241m.\u001B[39mCallbackEnv(model\u001B[38;5;241m=\u001B[39mbooster,\n\u001B[0;32m    286\u001B[0m                             params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m    287\u001B[0m                             iteration\u001B[38;5;241m=\u001B[39mi,\n\u001B[0;32m    288\u001B[0m                             begin_iteration\u001B[38;5;241m=\u001B[39minit_iteration,\n\u001B[0;32m    289\u001B[0m                             end_iteration\u001B[38;5;241m=\u001B[39minit_iteration \u001B[38;5;241m+\u001B[39m num_boost_round,\n\u001B[0;32m    290\u001B[0m                             evaluation_result_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m--> 292\u001B[0m \u001B[43mbooster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    294\u001B[0m evaluation_result_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    295\u001B[0m \u001B[38;5;66;03m# check evaluation result.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\deep\\lib\\site-packages\\lightgbm\\basic.py:3021\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, train_set, fobj)\u001B[0m\n\u001B[0;32m   3019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_objective_to_none:\n\u001B[0;32m   3020\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LightGBMError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCannot update due to null objective function.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 3021\u001B[0m _safe_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLGBM_BoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3022\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3023\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_finished\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   3024\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__is_predicted_cur_iter \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__num_dataset)]\n\u001B[0;32m   3025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m is_finished\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from optuna.samplers import TPESampler\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : LGBM(trial, X,  Y, X_test), n_trials=50)\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}