{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This is file for train, prediction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dirpath = 'C:/Users/rihot/Desktop/Deep_learning/DACON_used_car_price/'\n",
    "\n",
    "train = pd.read_csv('data/preprocessed_train.csv')\n",
    "test = pd.read_csv('data/preprocessed_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "Y = train[['target']].values\n",
    "X = train[ ['title', 'odometer', 'location', 'isimported', 'engine', 'paint', 'year', 'brand' ] ].values\n",
    "\n",
    "X_test = test[ ['title', 'odometer', 'location', 'isimported', 'engine', 'paint', 'year', 'brand' ] ].values\n",
    "\n",
    "# X = train[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values\n",
    "#\n",
    "# X_test = test[ ['title', 'odometer', 'location', 'isimported', 'engine', 'transmission', 'fuel', 'paint', 'year', 'brand' ] ].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((1015, 8), (1015, 1))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n",
    "scalerY = MinMaxScaler()\n",
    "scalerY.fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "def LGBM(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        'objective': 'regression', # 회귀\n",
    "        'metric': 'rmse',\n",
    "        \"n_estimators\" : trial.suggest_categorical('n_estimators', [500, 600,700,800,900,1000,1200,1400,1600,1800,2000, 4000]),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05]),\n",
    "        # 'nthread' : -1,\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = LGBMRegressor(**param)\n",
    "    LGBM_model = model.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n",
    "    score = mean_squared_error(LGBM_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-02 23:55:31,269]\u001B[0m A new study created in memory with name: no-name-c5b49c00-f899-479e-a6e2-1049aab8bae2\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:33,461]\u001B[0m Trial 0 finished with value: 0.05465324373714255 and parameters: {'n_estimators': 4000, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 0 with value: 0.05465324373714255.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:33,982]\u001B[0m Trial 1 finished with value: 0.034577816643479066 and parameters: {'n_estimators': 1400, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 1 with value: 0.034577816643479066.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:34,260]\u001B[0m Trial 2 finished with value: 0.04663499004303781 and parameters: {'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.01, 'subsample': 0.6}. Best is trial 1 with value: 0.034577816643479066.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:34,671]\u001B[0m Trial 3 finished with value: 0.04226636350908355 and parameters: {'n_estimators': 700, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 1 with value: 0.034577816643479066.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:35,410]\u001B[0m Trial 4 finished with value: 0.03324786760111061 and parameters: {'n_estimators': 1800, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:35,879]\u001B[0m Trial 5 finished with value: 0.04125988165516647 and parameters: {'n_estimators': 700, 'max_depth': 14, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:36,403]\u001B[0m Trial 6 finished with value: 0.08649744709090405 and parameters: {'n_estimators': 800, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:37,022]\u001B[0m Trial 7 finished with value: 0.04873804706399219 and parameters: {'n_estimators': 1600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:37,640]\u001B[0m Trial 8 finished with value: 0.07218300053152066 and parameters: {'n_estimators': 900, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:38,219]\u001B[0m Trial 9 finished with value: 0.046045223202036176 and parameters: {'n_estimators': 1600, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:39,184]\u001B[0m Trial 10 finished with value: 0.06645567224525366 and parameters: {'n_estimators': 1800, 'max_depth': 11, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:39,788]\u001B[0m Trial 11 finished with value: 0.05820893720683974 and parameters: {'n_estimators': 1400, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:40,563]\u001B[0m Trial 12 finished with value: 0.0430791679979041 and parameters: {'n_estimators': 1400, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:40,981]\u001B[0m Trial 13 finished with value: 0.05646527198035323 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:41,946]\u001B[0m Trial 14 finished with value: 0.05385127270225088 and parameters: {'n_estimators': 1800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:42,428]\u001B[0m Trial 15 finished with value: 0.0444415930925795 and parameters: {'n_estimators': 1200, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:42,694]\u001B[0m Trial 16 finished with value: 0.08687431059831106 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.03324786760111061.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:43,531]\u001B[0m Trial 17 finished with value: 0.02670091692246342 and parameters: {'n_estimators': 2000, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:44,528]\u001B[0m Trial 18 finished with value: 0.08609620748100302 and parameters: {'n_estimators': 2000, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:45,580]\u001B[0m Trial 19 finished with value: 0.03440214513095288 and parameters: {'n_estimators': 2000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:46,465]\u001B[0m Trial 20 finished with value: 0.05138203863119109 and parameters: {'n_estimators': 2000, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:47,525]\u001B[0m Trial 21 finished with value: 0.05551227626627462 and parameters: {'n_estimators': 2000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:48,565]\u001B[0m Trial 22 finished with value: 0.08066701738714364 and parameters: {'n_estimators': 2000, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:49,623]\u001B[0m Trial 23 finished with value: 0.09768281001428544 and parameters: {'n_estimators': 1800, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:50,540]\u001B[0m Trial 24 finished with value: 0.04911295652510873 and parameters: {'n_estimators': 2000, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:52,148]\u001B[0m Trial 25 finished with value: 0.03806300872448647 and parameters: {'n_estimators': 4000, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:52,502]\u001B[0m Trial 26 finished with value: 0.0398838333114104 and parameters: {'n_estimators': 600, 'max_depth': 12, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:52,973]\u001B[0m Trial 27 finished with value: 0.02912249625753814 and parameters: {'n_estimators': 1000, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:53,495]\u001B[0m Trial 28 finished with value: 0.0389169523105172 and parameters: {'n_estimators': 1000, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:53,950]\u001B[0m Trial 29 finished with value: 0.08459845128594455 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:54,495]\u001B[0m Trial 30 finished with value: 0.051852638699780226 and parameters: {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:54,994]\u001B[0m Trial 31 finished with value: 0.034429661831673536 and parameters: {'n_estimators': 900, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:55,294]\u001B[0m Trial 32 finished with value: 0.03748604777620604 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:55,800]\u001B[0m Trial 33 finished with value: 0.03566655791897833 and parameters: {'n_estimators': 1000, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:56,263]\u001B[0m Trial 34 finished with value: 0.09327487438508325 and parameters: {'n_estimators': 800, 'max_depth': 14, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:58,184]\u001B[0m Trial 35 finished with value: 0.047762271133284386 and parameters: {'n_estimators': 4000, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:58,910]\u001B[0m Trial 36 finished with value: 0.07470838744135322 and parameters: {'n_estimators': 1800, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:55:59,190]\u001B[0m Trial 37 finished with value: 0.05307996189807496 and parameters: {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:00,391]\u001B[0m Trial 38 finished with value: 0.04590577638531338 and parameters: {'n_estimators': 2000, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:00,684]\u001B[0m Trial 39 finished with value: 0.07853130170706488 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:01,468]\u001B[0m Trial 40 finished with value: 0.06463210469920039 and parameters: {'n_estimators': 1600, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:01,991]\u001B[0m Trial 41 finished with value: 0.04558398493682258 and parameters: {'n_estimators': 900, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:02,510]\u001B[0m Trial 42 finished with value: 0.044632076046392986 and parameters: {'n_estimators': 900, 'max_depth': 14, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:03,058]\u001B[0m Trial 43 finished with value: 0.07365983813137858 and parameters: {'n_estimators': 900, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:03,589]\u001B[0m Trial 44 finished with value: 0.03822403924430972 and parameters: {'n_estimators': 900, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:04,047]\u001B[0m Trial 45 finished with value: 0.06754881002173287 and parameters: {'n_estimators': 800, 'max_depth': 13, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:05,674]\u001B[0m Trial 46 finished with value: 0.054083287816859275 and parameters: {'n_estimators': 1800, 'max_depth': 11, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:06,152]\u001B[0m Trial 47 finished with value: 0.041014209201450255 and parameters: {'n_estimators': 1400, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:06,712]\u001B[0m Trial 48 finished with value: 0.05809793620072083 and parameters: {'n_estimators': 1000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n",
      "\u001B[32m[I 2022-06-02 23:56:07,017]\u001B[0m Trial 49 finished with value: 0.07952780628642143 and parameters: {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 17 with value: 0.02670091692246342.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.02670091692246342,\n",
      "params {'n_estimators': 2000, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : LGBM(trial, X,  Y, X_test), n_trials=50)\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best trial: score 0.02950600044760606,\n",
    "params {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.02, 'subsample': 0.8}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:19,042]\u001B[0m A new study created in memory with name: no-name-333f7c87-1662-4968-b267-896f708fb965\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:19,926]\u001B[0m Trial 0 finished with value: 0.0839424345688986 and parameters: {'n_estimators': 1800, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 0 with value: 0.0839424345688986.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:20,592]\u001B[0m Trial 1 finished with value: 0.05331714185330453 and parameters: {'n_estimators': 800, 'max_depth': 15, 'learning_rate': 0.01, 'subsample': 0.6}. Best is trial 1 with value: 0.05331714185330453.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:21,111]\u001B[0m Trial 2 finished with value: 0.03864030830845845 and parameters: {'n_estimators': 800, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 2 with value: 0.03864030830845845.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:22,340]\u001B[0m Trial 3 finished with value: 0.0314801292227182 and parameters: {'n_estimators': 4000, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 3 with value: 0.0314801292227182.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:22,925]\u001B[0m Trial 4 finished with value: 0.02088880864021991 and parameters: {'n_estimators': 900, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:23,411]\u001B[0m Trial 5 finished with value: 0.0266136234609935 and parameters: {'n_estimators': 700, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:24,485]\u001B[0m Trial 6 finished with value: 0.06562168514879387 and parameters: {'n_estimators': 2000, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:24,955]\u001B[0m Trial 7 finished with value: 0.03884459563319258 and parameters: {'n_estimators': 600, 'max_depth': 13, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:25,281]\u001B[0m Trial 8 finished with value: 0.07681765616063248 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:26,216]\u001B[0m Trial 9 finished with value: 0.04982225553968342 and parameters: {'n_estimators': 1800, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:26,953]\u001B[0m Trial 10 finished with value: 0.07420236285360123 and parameters: {'n_estimators': 900, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:27,935]\u001B[0m Trial 11 finished with value: 0.03316651225149414 and parameters: {'n_estimators': 1400, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:28,580]\u001B[0m Trial 12 finished with value: 0.033209433583675424 and parameters: {'n_estimators': 700, 'max_depth': 12, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:29,532]\u001B[0m Trial 13 finished with value: 0.05985264000296058 and parameters: {'n_estimators': 1000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:30,319]\u001B[0m Trial 14 finished with value: 0.045339089192124836 and parameters: {'n_estimators': 900, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:30,802]\u001B[0m Trial 15 finished with value: 0.07492602213209931 and parameters: {'n_estimators': 700, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:31,739]\u001B[0m Trial 16 finished with value: 0.044135861272407415 and parameters: {'n_estimators': 1600, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:32,728]\u001B[0m Trial 17 finished with value: 0.04899212511878239 and parameters: {'n_estimators': 1200, 'max_depth': 12, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:33,276]\u001B[0m Trial 18 finished with value: 0.060319887102622566 and parameters: {'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:33,731]\u001B[0m Trial 19 finished with value: 0.030072675670233397 and parameters: {'n_estimators': 700, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:34,929]\u001B[0m Trial 20 finished with value: 0.03674349760273552 and parameters: {'n_estimators': 2000, 'max_depth': 9, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:35,358]\u001B[0m Trial 21 finished with value: 0.027768862327682567 and parameters: {'n_estimators': 700, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:35,770]\u001B[0m Trial 22 finished with value: 0.07647510228750672 and parameters: {'n_estimators': 700, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:36,204]\u001B[0m Trial 23 finished with value: 0.05189288186905545 and parameters: {'n_estimators': 700, 'max_depth': 16, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:36,568]\u001B[0m Trial 24 finished with value: 0.05086640073734041 and parameters: {'n_estimators': 500, 'max_depth': 14, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:38,184]\u001B[0m Trial 25 finished with value: 0.03942395903486626 and parameters: {'n_estimators': 4000, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:38,755]\u001B[0m Trial 26 finished with value: 0.05102813028645873 and parameters: {'n_estimators': 1400, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:39,705]\u001B[0m Trial 27 finished with value: 0.040082603123142664 and parameters: {'n_estimators': 1200, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:40,515]\u001B[0m Trial 28 finished with value: 0.04071870511497466 and parameters: {'n_estimators': 1000, 'max_depth': 12, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:41,190]\u001B[0m Trial 29 finished with value: 0.03817250018520647 and parameters: {'n_estimators': 1600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:41,465]\u001B[0m Trial 30 finished with value: 0.03310055662224667 and parameters: {'n_estimators': 600, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:41,901]\u001B[0m Trial 31 finished with value: 0.03181409668849503 and parameters: {'n_estimators': 700, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:42,410]\u001B[0m Trial 32 finished with value: 0.05259772691120984 and parameters: {'n_estimators': 700, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:42,817]\u001B[0m Trial 33 finished with value: 0.08044739892979842 and parameters: {'n_estimators': 700, 'max_depth': 14, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:43,252]\u001B[0m Trial 34 finished with value: 0.041297829872536586 and parameters: {'n_estimators': 800, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:43,778]\u001B[0m Trial 35 finished with value: 0.03259806710298513 and parameters: {'n_estimators': 900, 'max_depth': 16, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:44,769]\u001B[0m Trial 36 finished with value: 0.04833135362564951 and parameters: {'n_estimators': 1800, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:45,355]\u001B[0m Trial 37 finished with value: 0.044151484610059764 and parameters: {'n_estimators': 700, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:46,621]\u001B[0m Trial 38 finished with value: 0.03544117618939772 and parameters: {'n_estimators': 4000, 'max_depth': 16, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:47,096]\u001B[0m Trial 39 finished with value: 0.03831009934338931 and parameters: {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:47,817]\u001B[0m Trial 40 finished with value: 0.0432718084827138 and parameters: {'n_estimators': 800, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:49,072]\u001B[0m Trial 41 finished with value: 0.04661773370846398 and parameters: {'n_estimators': 4000, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:50,359]\u001B[0m Trial 42 finished with value: 0.07468150384416392 and parameters: {'n_estimators': 4000, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:51,108]\u001B[0m Trial 43 finished with value: 0.05599024696707068 and parameters: {'n_estimators': 2000, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:51,446]\u001B[0m Trial 44 finished with value: 0.08200606342807897 and parameters: {'n_estimators': 600, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:52,202]\u001B[0m Trial 45 finished with value: 0.035065988611341234 and parameters: {'n_estimators': 900, 'max_depth': 12, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:52,537]\u001B[0m Trial 46 finished with value: 0.04616227808928924 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:53,955]\u001B[0m Trial 47 finished with value: 0.06490778869498891 and parameters: {'n_estimators': 1800, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:54,608]\u001B[0m Trial 48 finished with value: 0.0492064880653608 and parameters: {'n_estimators': 1400, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:01:55,180]\u001B[0m Trial 49 finished with value: 0.08382543566422782 and parameters: {'n_estimators': 700, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 4 with value: 0.02088880864021991.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.02088880864021991,\n",
      "params {'n_estimators': 900, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def XGB(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        # 'objective': 'regression', # 회귀\n",
    "        'metric': 'rmse',\n",
    "        \"n_estimators\" : trial.suggest_categorical('n_estimators', [500, 600,700,800,900,1000,1200,1400,1600,1800,2000, 4000]),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05]),\n",
    "        # 'nthread' : -1,\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = XGBRegressor(**param)\n",
    "    XGB_model = model.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n",
    "    score = mean_squared_error(XGB_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : XGB(trial, X,  Y, X_test), n_trials=50)\n",
    "\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best trial: score 0.02088880864021991,\n",
    "params {'n_estimators': 900, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 1.0}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 00:03:17,052]\u001B[0m A new study created in memory with name: no-name-7f36e082-a840-4fc4-bc43-d795703688ff\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:03:56,946]\u001B[0m Trial 0 finished with value: 0.06047475812189175 and parameters: {'n_estimators': 1400, 'max_depth': 12, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 0 with value: 0.06047475812189175.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:04:03,142]\u001B[0m Trial 1 finished with value: 0.05307147628981088 and parameters: {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 1 with value: 0.05307147628981088.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:04:20,953]\u001B[0m Trial 2 finished with value: 0.044453107955052716 and parameters: {'n_estimators': 1200, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 2 with value: 0.044453107955052716.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:04:24,641]\u001B[0m Trial 3 finished with value: 0.04991663524519707 and parameters: {'n_estimators': 1600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 2 with value: 0.044453107955052716.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:04:28,665]\u001B[0m Trial 4 finished with value: 0.07631418429852657 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 2 with value: 0.044453107955052716.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:04:30,368]\u001B[0m Trial 5 finished with value: 0.04713892890407032 and parameters: {'n_estimators': 800, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 2 with value: 0.044453107955052716.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:04:32,817]\u001B[0m Trial 6 finished with value: 0.08911738722191016 and parameters: {'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 2 with value: 0.044453107955052716.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:05:36,574]\u001B[0m Trial 7 finished with value: 0.036544556255277784 and parameters: {'n_estimators': 600, 'max_depth': 14, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:05:43,058]\u001B[0m Trial 8 finished with value: 0.055039697870418305 and parameters: {'n_estimators': 1600, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:06:03,146]\u001B[0m Trial 9 finished with value: 0.092103484941967 and parameters: {'n_estimators': 900, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:13:32,241]\u001B[0m Trial 10 finished with value: 0.060330675587667186 and parameters: {'n_estimators': 2000, 'max_depth': 15, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:15:24,996]\u001B[0m Trial 11 finished with value: 0.08149749593727791 and parameters: {'n_estimators': 1200, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:15:46,746]\u001B[0m Trial 12 finished with value: 0.050213908902254016 and parameters: {'n_estimators': 600, 'max_depth': 13, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:19:03,589]\u001B[0m Trial 13 finished with value: 0.06894579904397373 and parameters: {'n_estimators': 1200, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 7 with value: 0.036544556255277784.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:22:34,745]\u001B[0m Trial 14 finished with value: 0.036429909001016295 and parameters: {'n_estimators': 1000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:25:58,307]\u001B[0m Trial 15 finished with value: 0.038170802754121685 and parameters: {'n_estimators': 1000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:34:23,407]\u001B[0m Trial 16 finished with value: 0.043591305336783015 and parameters: {'n_estimators': 1800, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:36:01,574]\u001B[0m Trial 17 finished with value: 0.07809700236353048 and parameters: {'n_estimators': 1000, 'max_depth': 14, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:44:07,979]\u001B[0m Trial 18 finished with value: 0.07677210143924944 and parameters: {'n_estimators': 4000, 'max_depth': 14, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:46:26,483]\u001B[0m Trial 19 finished with value: 0.09056610522631371 and parameters: {'n_estimators': 700, 'max_depth': 15, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:47:04,472]\u001B[0m Trial 20 finished with value: 0.07264605564090722 and parameters: {'n_estimators': 600, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:50:16,889]\u001B[0m Trial 21 finished with value: 0.06846222200377125 and parameters: {'n_estimators': 1000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:53:44,835]\u001B[0m Trial 22 finished with value: 0.06608573401729588 and parameters: {'n_estimators': 1000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 00:55:36,143]\u001B[0m Trial 23 finished with value: 0.061773037458756175 and parameters: {'n_estimators': 1000, 'max_depth': 15, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:02:28,188]\u001B[0m Trial 24 finished with value: 0.08466009454752874 and parameters: {'n_estimators': 1000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 14 with value: 0.036429909001016295.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:06:22,039]\u001B[0m Trial 25 finished with value: 0.03176321632070084 and parameters: {'n_estimators': 4000, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:10:10,691]\u001B[0m Trial 26 finished with value: 0.0503883430270526 and parameters: {'n_estimators': 4000, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:12:24,011]\u001B[0m Trial 27 finished with value: 0.04397326506057348 and parameters: {'n_estimators': 4000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:15:09,774]\u001B[0m Trial 28 finished with value: 0.10640644878412596 and parameters: {'n_estimators': 1400, 'max_depth': 14, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:15:47,578]\u001B[0m Trial 29 finished with value: 0.05417271887514726 and parameters: {'n_estimators': 700, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:16:15,301]\u001B[0m Trial 30 finished with value: 0.039032532265437646 and parameters: {'n_estimators': 1800, 'max_depth': 11, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:17:58,914]\u001B[0m Trial 31 finished with value: 0.06106074367391951 and parameters: {'n_estimators': 900, 'max_depth': 15, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:19:25,029]\u001B[0m Trial 32 finished with value: 0.07895633456631272 and parameters: {'n_estimators': 500, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:22:20,507]\u001B[0m Trial 33 finished with value: 0.05696677198862364 and parameters: {'n_estimators': 2000, 'max_depth': 14, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:23:00,444]\u001B[0m Trial 34 finished with value: 0.08942267268495797 and parameters: {'n_estimators': 1400, 'max_depth': 12, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:24:03,811]\u001B[0m Trial 35 finished with value: 0.06394867751441602 and parameters: {'n_estimators': 600, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 25 with value: 0.03176321632070084.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:27:51,528]\u001B[0m Trial 36 finished with value: 0.030670633124304028 and parameters: {'n_estimators': 4000, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 36 with value: 0.030670633124304028.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:31:35,773]\u001B[0m Trial 37 finished with value: 0.055651788035655764 and parameters: {'n_estimators': 4000, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 36 with value: 0.030670633124304028.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:33:46,087]\u001B[0m Trial 38 finished with value: 0.06795153418495259 and parameters: {'n_estimators': 4000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 36 with value: 0.030670633124304028.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:33:57,318]\u001B[0m Trial 39 finished with value: 0.03781044539964672 and parameters: {'n_estimators': 800, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 36 with value: 0.030670633124304028.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:34:33,812]\u001B[0m Trial 40 finished with value: 0.0880188955781113 and parameters: {'n_estimators': 4000, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 36 with value: 0.030670633124304028.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:34:46,536]\u001B[0m Trial 41 finished with value: 0.0750299323892019 and parameters: {'n_estimators': 800, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 36 with value: 0.030670633124304028.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:34:53,141]\u001B[0m Trial 42 finished with value: 0.02228076617330138 and parameters: {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:34:59,396]\u001B[0m Trial 43 finished with value: 0.04506227817998561 and parameters: {'n_estimators': 1600, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:35:19,822]\u001B[0m Trial 44 finished with value: 0.043439492923317544 and parameters: {'n_estimators': 800, 'max_depth': 12, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:35:21,095]\u001B[0m Trial 45 finished with value: 0.031000612762114986 and parameters: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:35:27,468]\u001B[0m Trial 46 finished with value: 0.047993822283038584 and parameters: {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:35:28,549]\u001B[0m Trial 47 finished with value: 0.05466185694678033 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:35:30,762]\u001B[0m Trial 48 finished with value: 0.0339410398488721 and parameters: {'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:35:32,911]\u001B[0m Trial 49 finished with value: 0.036968580786227306 and parameters: {'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 42 with value: 0.02228076617330138.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.02228076617330138,\n",
      "params {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def cat(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        # 'objective': 'regression', # 회귀\n",
    "        # 'metric': 'rmse',\n",
    "        \"n_estimators\" : trial.suggest_categorical('n_estimators', [500, 600,700,800,900,1000,1200,1400,1600,1800,2000, 4000]),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05]),\n",
    "        # 'nthread' : -1,\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = CatBoostRegressor(**param)\n",
    "    cat_model = model.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n",
    "    score = mean_squared_error(cat_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : cat(trial, X,  Y, X_test), n_trials=50)\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best trial: score 0.02228076617330138,\n",
    "params {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.8}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 01:55:12,903]\u001B[0m A new study created in memory with name: no-name-618a3711-610d-442b-a1d2-24f39ab1fea4\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:15,419]\u001B[0m Trial 0 finished with value: 0.05914506379597146 and parameters: {'n_estimators': 1200, 'max_depth': 12, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 0 with value: 0.05914506379597146.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:16,592]\u001B[0m Trial 1 finished with value: 0.03949706502543835 and parameters: {'n_estimators': 900, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:19,545]\u001B[0m Trial 2 finished with value: 0.05288881995786198 and parameters: {'n_estimators': 1400, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:21,107]\u001B[0m Trial 3 finished with value: 0.08332525123170709 and parameters: {'n_estimators': 800, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:22,451]\u001B[0m Trial 4 finished with value: 0.08086342589450393 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.01, 'subsample': 0.6}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:23,639]\u001B[0m Trial 5 finished with value: 0.04444132172779475 and parameters: {'n_estimators': 600, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:26,233]\u001B[0m Trial 6 finished with value: 0.048941230385897025 and parameters: {'n_estimators': 1400, 'max_depth': 12, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:27,420]\u001B[0m Trial 7 finished with value: 0.039662877009966 and parameters: {'n_estimators': 900, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 0.7}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:28,874]\u001B[0m Trial 8 finished with value: 0.07965273439230237 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.7}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:30,061]\u001B[0m Trial 9 finished with value: 0.09582547976303117 and parameters: {'n_estimators': 600, 'max_depth': 13, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:33,625]\u001B[0m Trial 10 finished with value: 0.0402805434145357 and parameters: {'n_estimators': 1800, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:34,688]\u001B[0m Trial 11 finished with value: 0.07546690423197654 and parameters: {'n_estimators': 900, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 0.6}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:36,126]\u001B[0m Trial 12 finished with value: 0.0873972713504523 and parameters: {'n_estimators': 900, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 1.0}. Best is trial 1 with value: 0.03949706502543835.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:37,594]\u001B[0m Trial 13 finished with value: 0.030171970803255926 and parameters: {'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:38,313]\u001B[0m Trial 14 finished with value: 0.0895763940029397 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:39,344]\u001B[0m Trial 15 finished with value: 0.04683661314067838 and parameters: {'n_estimators': 700, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:42,714]\u001B[0m Trial 16 finished with value: 0.03875872736410463 and parameters: {'n_estimators': 1600, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:45,960]\u001B[0m Trial 17 finished with value: 0.05234535441375398 and parameters: {'n_estimators': 1600, 'max_depth': 16, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:53,752]\u001B[0m Trial 18 finished with value: 0.08819492990724002 and parameters: {'n_estimators': 4000, 'max_depth': 15, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:55:57,487]\u001B[0m Trial 19 finished with value: 0.04392524365258118 and parameters: {'n_estimators': 1600, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:02,769]\u001B[0m Trial 20 finished with value: 0.05623354058636856 and parameters: {'n_estimators': 2000, 'max_depth': 14, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:04,072]\u001B[0m Trial 21 finished with value: 0.036746374142505214 and parameters: {'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:06,659]\u001B[0m Trial 22 finished with value: 0.051348154330739845 and parameters: {'n_estimators': 1600, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:08,021]\u001B[0m Trial 23 finished with value: 0.05720416007224536 and parameters: {'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:08,746]\u001B[0m Trial 24 finished with value: 0.034375690000220775 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:09,463]\u001B[0m Trial 25 finished with value: 0.05365726750099852 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:10,238]\u001B[0m Trial 26 finished with value: 0.047524229830864836 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:11,312]\u001B[0m Trial 27 finished with value: 0.04205603776895604 and parameters: {'n_estimators': 800, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:13,719]\u001B[0m Trial 28 finished with value: 0.04468139887197624 and parameters: {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 1.0}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:17,916]\u001B[0m Trial 29 finished with value: 0.0360779294543338 and parameters: {'n_estimators': 2000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:22,306]\u001B[0m Trial 30 finished with value: 0.04774475691117383 and parameters: {'n_estimators': 2000, 'max_depth': 13, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:26,563]\u001B[0m Trial 31 finished with value: 0.05367907698939512 and parameters: {'n_estimators': 2000, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:28,317]\u001B[0m Trial 32 finished with value: 0.06320840292455394 and parameters: {'n_estimators': 900, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 13 with value: 0.030171970803255926.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:29,468]\u001B[0m Trial 33 finished with value: 0.02844488766002739 and parameters: {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:30,925]\u001B[0m Trial 34 finished with value: 0.05756410562144422 and parameters: {'n_estimators': 700, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:31,964]\u001B[0m Trial 35 finished with value: 0.0437657649092564 and parameters: {'n_estimators': 700, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:34,928]\u001B[0m Trial 36 finished with value: 0.08274657768507032 and parameters: {'n_estimators': 1800, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:41,500]\u001B[0m Trial 37 finished with value: 0.04383607560262728 and parameters: {'n_estimators': 4000, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:44,225]\u001B[0m Trial 38 finished with value: 0.05325926983778746 and parameters: {'n_estimators': 1400, 'max_depth': 11, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:46,725]\u001B[0m Trial 39 finished with value: 0.03703158147788796 and parameters: {'n_estimators': 1200, 'max_depth': 12, 'learning_rate': 0.05, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:50,377]\u001B[0m Trial 40 finished with value: 0.08706053700940072 and parameters: {'n_estimators': 2000, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 1.0}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:51,698]\u001B[0m Trial 41 finished with value: 0.039319710981017914 and parameters: {'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 0.6}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:52,600]\u001B[0m Trial 42 finished with value: 0.040466961199475696 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:53,708]\u001B[0m Trial 43 finished with value: 0.0455889005325317 and parameters: {'n_estimators': 700, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:55,410]\u001B[0m Trial 44 finished with value: 0.03877275815699256 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.02, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:56,534]\u001B[0m Trial 45 finished with value: 0.08580937602505338 and parameters: {'n_estimators': 900, 'max_depth': 8, 'learning_rate': 0.01, 'subsample': 0.6}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:57,870]\u001B[0m Trial 46 finished with value: 0.04249706726622936 and parameters: {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.02, 'subsample': 0.7}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:56:58,689]\u001B[0m Trial 47 finished with value: 0.048492073798268566 and parameters: {'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.6}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:57:00,119]\u001B[0m Trial 48 finished with value: 0.03800444808850513 and parameters: {'n_estimators': 900, 'max_depth': 11, 'learning_rate': 0.02, 'subsample': 0.6}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:57:03,319]\u001B[0m Trial 49 finished with value: 0.032398642471200896 and parameters: {'n_estimators': 1400, 'max_depth': 13, 'learning_rate': 0.01, 'subsample': 0.8}. Best is trial 33 with value: 0.02844488766002739.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.02844488766002739,\n",
      "params {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def gradi(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        # 'objective': 'regression', # 회귀\n",
    "        # 'metric': 'rmse',\n",
    "        \"n_estimators\" : trial.suggest_categorical('n_estimators', [500, 600,700,800,900,1000,1200,1400,1600,1800,2000, 4000]),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05]),\n",
    "        # 'nthread' : -1,\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = GradientBoostingRegressor(**param)\n",
    "    gradi_model = model.fit(X_train, y_train)\n",
    "    score = mean_squared_error(gradi_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : gradi(trial, X,  Y, X_test), n_trials=50)\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best trial: score 0.02844488766002739,\n",
    "params {'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 01:58:00,537]\u001B[0m A new study created in memory with name: no-name-dd0b8811-9325-4723-8262-e0e3fe5213ca\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:08,097]\u001B[0m Trial 0 finished with value: 0.09096298022115129 and parameters: {'n_estimators': 4000, 'max_depth': 15}. Best is trial 0 with value: 0.09096298022115129.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:09,217]\u001B[0m Trial 1 finished with value: 0.02877347975814291 and parameters: {'n_estimators': 600, 'max_depth': 15}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:15,637]\u001B[0m Trial 2 finished with value: 0.051236962110817054 and parameters: {'n_estimators': 4000, 'max_depth': 13}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:17,146]\u001B[0m Trial 3 finished with value: 0.045068519397612514 and parameters: {'n_estimators': 700, 'max_depth': 15}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:18,451]\u001B[0m Trial 4 finished with value: 0.05819010410208789 and parameters: {'n_estimators': 700, 'max_depth': 13}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:19,676]\u001B[0m Trial 5 finished with value: 0.03464068578319174 and parameters: {'n_estimators': 900, 'max_depth': 10}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:23,236]\u001B[0m Trial 6 finished with value: 0.056605121275910275 and parameters: {'n_estimators': 1800, 'max_depth': 15}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:26,536]\u001B[0m Trial 7 finished with value: 0.033782688589201505 and parameters: {'n_estimators': 1600, 'max_depth': 16}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:29,036]\u001B[0m Trial 8 finished with value: 0.07579863852890008 and parameters: {'n_estimators': 1400, 'max_depth': 13}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:31,526]\u001B[0m Trial 9 finished with value: 0.08314879582777235 and parameters: {'n_estimators': 1400, 'max_depth': 13}. Best is trial 1 with value: 0.02877347975814291.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:32,280]\u001B[0m Trial 10 finished with value: 0.02668045501392634 and parameters: {'n_estimators': 600, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:32,966]\u001B[0m Trial 11 finished with value: 0.04009179098882741 and parameters: {'n_estimators': 600, 'max_depth': 8}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:33,781]\u001B[0m Trial 12 finished with value: 0.05626203336625978 and parameters: {'n_estimators': 600, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:34,461]\u001B[0m Trial 13 finished with value: 0.06773386739737398 and parameters: {'n_estimators': 600, 'max_depth': 8}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:36,286]\u001B[0m Trial 14 finished with value: 0.09093782644092915 and parameters: {'n_estimators': 1200, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:37,515]\u001B[0m Trial 15 finished with value: 0.05776865215959114 and parameters: {'n_estimators': 1000, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:40,565]\u001B[0m Trial 16 finished with value: 0.03357639337650152 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:41,505]\u001B[0m Trial 17 finished with value: 0.08569202952176525 and parameters: {'n_estimators': 500, 'max_depth': 12}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:43,137]\u001B[0m Trial 18 finished with value: 0.04145952784585929 and parameters: {'n_estimators': 800, 'max_depth': 16}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:43,886]\u001B[0m Trial 19 finished with value: 0.05393653754403825 and parameters: {'n_estimators': 600, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:45,008]\u001B[0m Trial 20 finished with value: 0.05684970879561904 and parameters: {'n_estimators': 600, 'max_depth': 14}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:48,005]\u001B[0m Trial 21 finished with value: 0.06018505700039969 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:51,035]\u001B[0m Trial 22 finished with value: 0.06745244535255066 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:53,765]\u001B[0m Trial 23 finished with value: 0.030453660739872927 and parameters: {'n_estimators': 2000, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:55,007]\u001B[0m Trial 24 finished with value: 0.08075855020607264 and parameters: {'n_estimators': 1000, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:57,195]\u001B[0m Trial 25 finished with value: 0.06845405159135323 and parameters: {'n_estimators': 1600, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:58:59,155]\u001B[0m Trial 26 finished with value: 0.04350329217783747 and parameters: {'n_estimators': 1200, 'max_depth': 12}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:00,055]\u001B[0m Trial 27 finished with value: 0.07945492314369956 and parameters: {'n_estimators': 800, 'max_depth': 8}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:01,165]\u001B[0m Trial 28 finished with value: 0.05858294647063893 and parameters: {'n_estimators': 900, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:04,525]\u001B[0m Trial 29 finished with value: 0.03654522005823927 and parameters: {'n_estimators': 1800, 'max_depth': 14}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:05,206]\u001B[0m Trial 30 finished with value: 0.02804432974744047 and parameters: {'n_estimators': 500, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:05,874]\u001B[0m Trial 31 finished with value: 0.03359906282487875 and parameters: {'n_estimators': 500, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:06,701]\u001B[0m Trial 32 finished with value: 0.04866828682843959 and parameters: {'n_estimators': 500, 'max_depth': 12}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:12,208]\u001B[0m Trial 33 finished with value: 0.04632087145867817 and parameters: {'n_estimators': 4000, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:14,664]\u001B[0m Trial 34 finished with value: 0.05339677119737845 and parameters: {'n_estimators': 2000, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:15,405]\u001B[0m Trial 35 finished with value: 0.07658555779995542 and parameters: {'n_estimators': 500, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:16,374]\u001B[0m Trial 36 finished with value: 0.0962042341447073 and parameters: {'n_estimators': 700, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:17,044]\u001B[0m Trial 37 finished with value: 0.0411191895412315 and parameters: {'n_estimators': 600, 'max_depth': 8}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:24,616]\u001B[0m Trial 38 finished with value: 0.034340278592875195 and parameters: {'n_estimators': 4000, 'max_depth': 14}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:25,586]\u001B[0m Trial 39 finished with value: 0.04826700876903228 and parameters: {'n_estimators': 600, 'max_depth': 12}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:26,698]\u001B[0m Trial 40 finished with value: 0.04387202457544281 and parameters: {'n_estimators': 900, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:29,674]\u001B[0m Trial 41 finished with value: 0.05104525015721171 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:32,363]\u001B[0m Trial 42 finished with value: 0.08664973384246091 and parameters: {'n_estimators': 2000, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:35,334]\u001B[0m Trial 43 finished with value: 0.07791819800156831 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:38,133]\u001B[0m Trial 44 finished with value: 0.08816479911523935 and parameters: {'n_estimators': 1400, 'max_depth': 15}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:40,583]\u001B[0m Trial 45 finished with value: 0.05113396452820828 and parameters: {'n_estimators': 1800, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:42,003]\u001B[0m Trial 46 finished with value: 0.041617712367662256 and parameters: {'n_estimators': 700, 'max_depth': 16}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:43,066]\u001B[0m Trial 47 finished with value: 0.07551769127671874 and parameters: {'n_estimators': 600, 'max_depth': 13}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:45,603]\u001B[0m Trial 48 finished with value: 0.038637663439985585 and parameters: {'n_estimators': 2000, 'max_depth': 9}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 01:59:47,933]\u001B[0m Trial 49 finished with value: 0.06411419685090235 and parameters: {'n_estimators': 1600, 'max_depth': 10}. Best is trial 10 with value: 0.02668045501392634.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.02668045501392634,\n",
      "params {'n_estimators': 600, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def etr(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        # 'objective': 'regression', # 회귀\n",
    "        # 'metric': 'rmse',\n",
    "        \"n_estimators\" : trial.suggest_categorical('n_estimators', [500, 600,700,800,900,1000,1200,1400,1600,1800,2000, 4000]),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        # 'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05]),\n",
    "        # 'nthread' : -1,\n",
    "        # 'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = ExtraTreesRegressor(**param)\n",
    "    etr_model = model.fit(X_train, y_train)\n",
    "    score = mean_squared_error(etr_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : etr(trial, X,  Y, X_test), n_trials=50)\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best trial: score 0.02668045501392634,\n",
    "params {'n_estimators': 600, 'max_depth': 9}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-03 02:15:57,377]\u001B[0m A new study created in memory with name: no-name-8870f84b-4218-4298-b11d-01d21a3ace53\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:15:58,548]\u001B[0m Trial 0 finished with value: 0.04131496640430345 and parameters: {'n_estimators': 600, 'max_depth': 8}. Best is trial 0 with value: 0.04131496640430345.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:08,172]\u001B[0m Trial 1 finished with value: 0.03484342822735787 and parameters: {'n_estimators': 4000, 'max_depth': 12}. Best is trial 1 with value: 0.03484342822735787.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:09,348]\u001B[0m Trial 2 finished with value: 0.0805269800774792 and parameters: {'n_estimators': 500, 'max_depth': 12}. Best is trial 1 with value: 0.03484342822735787.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:13,447]\u001B[0m Trial 3 finished with value: 0.0884373574909707 and parameters: {'n_estimators': 1600, 'max_depth': 14}. Best is trial 1 with value: 0.03484342822735787.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:15,792]\u001B[0m Trial 4 finished with value: 0.03472087963963781 and parameters: {'n_estimators': 900, 'max_depth': 15}. Best is trial 4 with value: 0.03472087963963781.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:26,288]\u001B[0m Trial 5 finished with value: 0.07658880599493591 and parameters: {'n_estimators': 4000, 'max_depth': 15}. Best is trial 4 with value: 0.03472087963963781.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:30,426]\u001B[0m Trial 6 finished with value: 0.033730265932558116 and parameters: {'n_estimators': 2000, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:34,146]\u001B[0m Trial 7 finished with value: 0.04207816599432057 and parameters: {'n_estimators': 1800, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:35,686]\u001B[0m Trial 8 finished with value: 0.09283083264207553 and parameters: {'n_estimators': 600, 'max_depth': 15}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:37,263]\u001B[0m Trial 9 finished with value: 0.04861817501663242 and parameters: {'n_estimators': 600, 'max_depth': 16}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:40,921]\u001B[0m Trial 10 finished with value: 0.047619427322566174 and parameters: {'n_estimators': 2000, 'max_depth': 8}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:42,891]\u001B[0m Trial 11 finished with value: 0.06351041294762337 and parameters: {'n_estimators': 900, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:44,756]\u001B[0m Trial 12 finished with value: 0.08163415116564443 and parameters: {'n_estimators': 900, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:48,116]\u001B[0m Trial 13 finished with value: 0.06482651589754881 and parameters: {'n_estimators': 1400, 'max_depth': 13}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:52,276]\u001B[0m Trial 14 finished with value: 0.0942900616457057 and parameters: {'n_estimators': 2000, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:54,685]\u001B[0m Trial 15 finished with value: 0.05659430249565278 and parameters: {'n_estimators': 1000, 'max_depth': 13}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:56,256]\u001B[0m Trial 16 finished with value: 0.08914091935262317 and parameters: {'n_estimators': 800, 'max_depth': 9}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:16:58,135]\u001B[0m Trial 17 finished with value: 0.06059783517943042 and parameters: {'n_estimators': 700, 'max_depth': 16}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:00,772]\u001B[0m Trial 18 finished with value: 0.051927894417220295 and parameters: {'n_estimators': 1200, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:03,020]\u001B[0m Trial 19 finished with value: 0.0726914467643079 and parameters: {'n_estimators': 900, 'max_depth': 14}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:07,360]\u001B[0m Trial 20 finished with value: 0.03554488421463422 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:16,458]\u001B[0m Trial 21 finished with value: 0.06381957093829389 and parameters: {'n_estimators': 4000, 'max_depth': 12}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:26,497]\u001B[0m Trial 22 finished with value: 0.06740123166133268 and parameters: {'n_estimators': 4000, 'max_depth': 13}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:30,157]\u001B[0m Trial 23 finished with value: 0.04962619910940433 and parameters: {'n_estimators': 1600, 'max_depth': 12}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:32,526]\u001B[0m Trial 24 finished with value: 0.057620449199222976 and parameters: {'n_estimators': 1200, 'max_depth': 9}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:35,020]\u001B[0m Trial 25 finished with value: 0.07627860510204265 and parameters: {'n_estimators': 1000, 'max_depth': 14}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:38,489]\u001B[0m Trial 26 finished with value: 0.03778000464038954 and parameters: {'n_estimators': 1800, 'max_depth': 9}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:42,152]\u001B[0m Trial 27 finished with value: 0.045061720783515814 and parameters: {'n_estimators': 1400, 'max_depth': 15}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:43,806]\u001B[0m Trial 28 finished with value: 0.050241887265834624 and parameters: {'n_estimators': 700, 'max_depth': 12}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:44,726]\u001B[0m Trial 29 finished with value: 0.0672804041092025 and parameters: {'n_estimators': 500, 'max_depth': 8}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:53,557]\u001B[0m Trial 30 finished with value: 0.05247148513728021 and parameters: {'n_estimators': 4000, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:17:58,022]\u001B[0m Trial 31 finished with value: 0.07856239819346922 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:02,200]\u001B[0m Trial 32 finished with value: 0.042661423170476206 and parameters: {'n_estimators': 2000, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:06,627]\u001B[0m Trial 33 finished with value: 0.0461338998344829 and parameters: {'n_estimators': 2000, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:08,795]\u001B[0m Trial 34 finished with value: 0.04872438147613251 and parameters: {'n_estimators': 900, 'max_depth': 13}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:10,644]\u001B[0m Trial 35 finished with value: 0.08012375274217823 and parameters: {'n_estimators': 800, 'max_depth': 12}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:14,832]\u001B[0m Trial 36 finished with value: 0.06348850880519172 and parameters: {'n_estimators': 2000, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:15,938]\u001B[0m Trial 37 finished with value: 0.05107536323211793 and parameters: {'n_estimators': 500, 'max_depth': 11}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:19,077]\u001B[0m Trial 38 finished with value: 0.039674884142348515 and parameters: {'n_estimators': 1600, 'max_depth': 9}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:20,587]\u001B[0m Trial 39 finished with value: 0.044969493474744285 and parameters: {'n_estimators': 600, 'max_depth': 14}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:30,148]\u001B[0m Trial 40 finished with value: 0.04832226123628695 and parameters: {'n_estimators': 4000, 'max_depth': 12}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:33,683]\u001B[0m Trial 41 finished with value: 0.04229116926262023 and parameters: {'n_estimators': 1800, 'max_depth': 9}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:37,077]\u001B[0m Trial 42 finished with value: 0.05469015997709446 and parameters: {'n_estimators': 1800, 'max_depth': 8}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:40,844]\u001B[0m Trial 43 finished with value: 0.07332934076585756 and parameters: {'n_estimators': 1800, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:44,607]\u001B[0m Trial 44 finished with value: 0.08299875899528417 and parameters: {'n_estimators': 1800, 'max_depth': 10}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:48,537]\u001B[0m Trial 45 finished with value: 0.06454394522433216 and parameters: {'n_estimators': 2000, 'max_depth': 9}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:50,859]\u001B[0m Trial 46 finished with value: 0.04666091709715947 and parameters: {'n_estimators': 900, 'max_depth': 15}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:18:56,237]\u001B[0m Trial 47 finished with value: 0.03571179282394388 and parameters: {'n_estimators': 2000, 'max_depth': 16}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:19:01,437]\u001B[0m Trial 48 finished with value: 0.07641568395877354 and parameters: {'n_estimators': 2000, 'max_depth': 16}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n",
      "\u001B[32m[I 2022-06-03 02:19:06,716]\u001B[0m Trial 49 finished with value: 0.03558904497062025 and parameters: {'n_estimators': 2000, 'max_depth': 16}. Best is trial 6 with value: 0.033730265932558116.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.033730265932558116,\n",
      "params {'n_estimators': 2000, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def rfr(trial : Trial, X, Y, test):\n",
    "    param = {\n",
    "        # 'objective': 'regression', # 회귀\n",
    "        # 'metric': 'rmse',\n",
    "        \"n_estimators\" : trial.suggest_categorical('n_estimators', [500, 600,700,800,900,1000,1200,1400,1600,1800,2000, 4000]),\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
    "        # 'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05]),\n",
    "        # 'nthread' : -1,\n",
    "        # 'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test  = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = RandomForestRegressor(**param)\n",
    "    rfr_model = model.fit(X_train, y_train)\n",
    "    score = mean_squared_error(rfr_model.predict(X_test), y_test, squared=False)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "study.optimize(lambda trial : rfr(trial, X,  Y, X_test), n_trials=50)\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best trial: score 0.033730265932558116,\n",
    "params {'n_estimators': 2000, 'max_depth': 10}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}